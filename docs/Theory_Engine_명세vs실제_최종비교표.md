# Theory Engine: 요구사항 명세 vs 실제 구현 최종 비교표

**Document ID**: TE-SPEC-VS-ACTUAL-001  
**Version**: 1.0  
**Date**: 2026-01-21  
**Author**: Product Spec Agent  
**Status**: 🔴 **CRITICAL REVIEW**

---

## Executive Summary

### 핵심 발견

| 구분 | 명세 상태 | 실제 상태 | 갭 심각도 | 조치 |
|:-----|:---------|:---------|:----------|:-----|
| **파이프라인 구조** | 개념만 제시 | 완전 구현 | 🟡 명세 부족 | ✅ 명세 보강 완료 |
| **PERCENTAGE 방향** | **미명시** | **역전 버그 발견·수정** | 🔴 **Critical** | ✅ 수정 완료 + 명세화 |
| **Alias 오매핑** | **미명시** | **오매핑 발견·수정** | 🔴 **Critical** | ✅ 수정 완료 + 명세화 |
| **설명 가능성** | "근거 제시" (모호) | 플래그 부재 | 🟡 High | ⚠️ P0 작업 필요 |
| **성능** | "P95 < 3초" | 4.4초/케이스 | 🟡 High | ⚠️ P1 개선 필요 |

---

## 1. 무엇이 다른가 (What's Different)

### 1.1 기존 PRD 명세 (추상적)

```markdown
### 4.3 Theory Engine v3: 핵심 차별화 기술

**복원 가능 범위**:
| 항목 | 자동화율 | 방법 |
|------|----------|------|
| 점수 변환/환산 알고리즘 | 85% | RAWSCORE + 수식 매핑 |
| 대학별 커트라인 | 90% | PERCENTAGE 정규화 |
| 결격 사유 룰 | 90% | RESTRICT + rules_triggered |

**A/B 갭 보정 모델**:
s_final = s_theory + r(x, s_theory)
```

**문제점**:
- ❌ 5단계 파이프라인의 **입출력 인터페이스 없음**
- ❌ PERCENTAGE "정규화"가 무엇인지 **의미 미명시**
- ❌ Alias 매칭 규칙 **완전히 누락**
- ❌ 에러 처리/폴백 정책 **없음**
- ❌ 성능 목표 **비현실적** (세부 시나리오 구분 없음)

---

### 1.2 검증 보고서 발견 사항 (구체적)

```markdown
### 치명적 갭 #1: PERCENTAGE 커트라인 매핑 역전

**증상**: 커트라인이 "적정 < 예상 < 소신"으로 역전
**근거**: 가천의학 이과
- (수정 전) 적정=49.9, 예상=73.13, 소신=88.28 ❌
- (수정 후) 적정=88.28, 예상=73.13, 소신=49.9 ✅

**원인**: CUTOFF_PERCENTILES = {적정: 80, 예상: 50, 소신: 20}
- % 축이 0=상위, 100=하위인데, 매핑이 반대로 됨

**조치**: CUTOFF_PERCENTILES = {적정: 20, 예상: 50, 소신: 80}
```

**차이점**:
- ✅ **구체적 데이터** (가천의학 이과 실측값)
- ✅ **버그 재현 가능** (수정 전/후 비교)
- ✅ **테스트로 고정** (Sanity 테스트 추가)
- ✅ **명세에 역류** (축 방향 규칙 명문화)

---

## 2. 어떻게 다른가 (How It Differs)

### 2.1 명세의 추상성 vs 구현의 구체성

| 항목 | 기존 명세 표현 | 실제 구현 | 구체성 갭 |
|:-----|:-------------|:---------|:----------|
| **점수 변환** | "RAWSCORE + 수식 매핑" | `convert_raw_to_standard(korean, math, track)` → (korean_std, math_std, keys) | ⬆️⬆️⬆️ |
| **커트라인** | "PERCENTAGE 정규화" | `lookup_percentage(univ, major, type, percentile=20/50/80)` + 선형 보간 | ⬆️⬆️⬆️ |
| **결격** | "RESTRICT + rules_triggered" | 3개 룰 (출석/과탐/제2외국어) + 대학명 정규화 + 의료계열 키워드 | ⬆️⬆️ |
| **Alias** | (언급 없음) | 4단계 우선순위 + 정규화 + 퍼지(threshold=75) | ⬆️⬆️⬆️ |
| **성능** | "P95 < 3초" | 단일 4.4초, 배치 226초 → 캐싱/인덱싱 필요 | ⬇️⬇️ |

---

### 2.2 명세 vs 실제 데이터 흐름 비교

**기존 명세 (단순화된 블랙박스)**:
```
StudentProfile → [Theory Engine] → TheoryResult
                    (5단계)
```

**실제 구현 (상세 화이트박스)**:
```
StudentProfile
  ↓
[RAWSCORE] convert_raw_to_standard()
  ├─ RAWSCORE_이과/문과 시트 조회
  ├─ 100 초과 → 변환 없음 (표준점수로 간주)
  ├─ 100 이하 → 원점수→표준점수 변환
  └─ rawscore_keys 저장
  ↓
[INDEX] CutoffExtractor.extract_cutoffs()
  ├─ 대학명 Alias 해소 (4단계 우선순위)
  ├─ 전공명 Alias 해소 (의예→의학 등)
  ├─ "{대학}_{전공}_{전형}_{레벨}" 컬럼 매칭
  ├─ 성공 → cutoffs 반환
  ├─ 실패 → PERCENTAGE 폴백
  └─ index_key, index_found 저장
  ↓
[PERCENTAGE] lookup_percentage() (폴백)
  ├─ ⚠️ CRITICAL: % 축 방향 (0=상위, 100=하위)
  ├─ 레벨 매핑 (적정=20%, 예상=50%, 소신=80%)
  ├─ 정확 값 있음 → 직접 반환
  ├─ 정확 값 없음 → 선형 보간
  ├─ ✅ 검증: 적정 ≥ 예상 ≥ 소신
  └─ percentage_key, interpolated 저장
  ↓
[RESTRICT] check_disqualification()
  ├─ 대학명 정규화 (⚠️ P0 작업 필요)
  ├─ 출석률 < 80% → DQ-001
  ├─ 의료계열 + 과탐 < 2 → DQ-002 (⚠️ 키워드 정교화 필요)
  ├─ 제2외국어 미이수 → DQ-003
  └─ rules_triggered[] 반환
  ↓
[COMPUTE] compute_theory_result()
  ├─ 결격 시 → line=DISQUALIFIED, prob=0.0
  ├─ 라인 판정 (score vs cutoffs)
  │   ├─ ≥ 적정 → TOP
  │   ├─ ≥ 예상 → HIGH
  │   ├─ ≥ 소신 → MID
  │   └─ < 소신 → LOW
  ├─ 확률 추정 (라인별 범위)
  ├─ 갭 계산 (cutoff_gap_*)
  └─ TheoryResult 생성
  ↓
TheoryResult
  ├─ line, probability, score_theory
  ├─ cutoffs, gaps
  ├─ rules_triggered
  ├─ raw_components
  ├─ engine_version, excel_version
  └─ explainability (⚠️ P0 추가 필요)
```

---

### 2.3 코드 레벨 비교

**기존 명세 (Task 리스트)**:
```markdown
| T3.8 | rules.py 작성 (PERCENTAGE) | PERCENTAGE 조회 룰 |
| T3.9 | rules.py 작성 (RESTRICT) | 결격 체크 룰 |
```

**실제 구현 (함수 시그니처)**:
```python
# T3.8 실제 구현
def lookup_percentage(
    university: str,
    major: str,
    admission_type: str,
    percentile: int,  # ⚠️ 20/50/80 (명세 누락)
    percentage_sheet: pd.DataFrame,
    interpolation: str = 'linear'  # ⚠️ 명세 누락
) -> float:
    """
    ⚠️ CRITICAL 발견:
    - % 축이 0=상위, 100=하위 (역방향)
    - 커트라인 매핑이 역전되어 있었음
    - 수정: 20%=적정, 50%=예상, 80%=소신
    """
    # (200+ 줄 구현)

# T3.9 실제 구현
def check_disqualification(
    profile: StudentProfile,
    rules: List[DisqualificationRule]
) -> List[Dict]:
    """
    ⚠️ HIGH 발견:
    - 대학명 별칭(연대/고대) 시 룰 누락
    - 의료계열 판정이 "의" 단일 포함 → 오탐
    
    수정 필요:
    - 대학명 정규화 적용 (P0)
    - 의료계열 키워드 정교화 (P0)
    """
    # (100+ 줄 구현)
```

**차이점**:
- 명세: **Task 이름과 산출물만**
- 실제: **함수 시그니처 + 파라미터 + 예외 처리 + 버그**
- 갭: **구현 복잡도의 80%를 명세가 반영하지 못함**

---

## 3. 왜 다른가 (Why It Differs)

### 3.1 근본 원인 분석

#### 원인 #1: 명세 작성자가 실제 데이터를 보지 않음

**명세 작성 시**:
- 입력: PRD 문서만
- 가정: "PERCENTAGE 정규화"라는 용어만 보고 일반적인 정규화(0~1 스케일링)로 이해
- 결과: % 축이 역방향이라는 사실을 **모름**

**검증 보고서 작성 시**:
- 입력: PRD + **실제 엑셀 파일** + **코드**
- 발견: `PERCENTAGE` 시트의 % 컬럼이 0.00~94.0 범위, 점수와 역비례
- 결과: 축 방향 버그 **즉시 발견**

**교훈**:
> "명세 작성 시 실제 데이터를 반드시 확인해야 한다"

---

#### 원인 #2: "자동화율 85%"의 의미론적 모호성

**명세에서**:
```
| 점수 변환/환산 알고리즘 | 85% | RAWSCORE + 수식 매핑 |
```

**개발자의 해석 A** (낙관적):
- "85%의 케이스를 정확하게 처리한다"

**개발자의 해석 B** (현실적):
- "85%의 케이스를 처리 **시도**한다 (정확도는 별도)"

**실제 의미** (검증 후):
- **커버리지 85%**: 85%의 케이스를 처리 시도
- **정확도 미검증**: 처리한 케이스가 얼마나 정확한지는 백테스트 필요

**결과**:
- 명세가 **커버리지와 정확도를 혼동**
- 개발팀이 "85% 처리"만 보고 품질 검증 소홀

**개선**:
```
| 점수 변환 커버리지 | 85% | 85% 케이스 처리 가능 |
| 점수 변환 정확도 | 95% | 처리된 케이스의 95%가 ±5% 오차 이내 |
```

---

#### 원인 #3: 설명 가능성 요구의 구현 불가능성

**명세에서**:
```
NFR-AI04: 설명 가능성
- 모든 예측에 근거 제시
```

**문제점**:
- "근거"를 **어떤 필드에** 저장할지 미명시
- "근거"가 **자연어 설명**인지 **구조화된 데이터**인지 불명확
- "제시"가 **API 응답에 포함**인지 **로그만**인지 불명확

**결과**:
- 개발팀이 최소한의 `raw_components`만 저장 (디버그용)
- 사용자에게 보여줄 "설명"은 **없음**

**개선**:
```typescript
interface TheoryResult {
  // 기존
  line: AdmissionLine;
  probability: number;
  
  // 신규: 설명 가능성
  explainability: {
    university_mapping: {
      input: "연대",
      matched: "연세대",
      method: "alias",
      confidence: 1.0
    },
    major_mapping: {
      input: "의예",
      matched: "의학",
      method: "alias",
      alias_chain: ["의예", "의학"]
    },
    cutoff_source: {
      sheet: "PERCENTAGE",
      percentile: 50,
      interpolated: false
    }
  };
}
```

---

## 4. 갭 타입별 분류 및 우선순위

### 4.1 Critical 갭 (🔴 치명적, 즉시 수정 필요)

| 갭 ID | 갭 타입 | 명세 상태 | 실제 상태 | 영향 | 조치 |
|:------|:--------|:---------|:---------|:-----|:-----|
| **GAP-C01** | 의미론 갭 | PERCENTAGE "정규화" (모호) | % 축 역방향, 매핑 역전 버그 | 확률/라인 왜곡 | ✅ 수정 완료 |
| **GAP-C02** | 로직 갭 | Alias "지원" (언급만) | 역매핑 키 미정규화 → 오매핑 | 잘못된 대학 매칭 | ✅ 수정 완료 |
| **GAP-C03** | 명세 누락 | (없음) | 커트라인 레벨 매핑 규칙 | 개발자 혼란 | ✅ 명세 추가 |

---

### 4.2 High 갭 (🟡 중요, 1주 이내 수정)

| 갭 ID | 갭 타입 | 명세 상태 | 실제 상태 | 영향 | 조치 |
|:------|:--------|:---------|:---------|:-----|:-----|
| **GAP-H01** | 도메인 갭 | (없음) | 의료계열 판정 과도 ("의" 포함 → 의류학 오탐) | 결격 오검출 | ⚠️ P0 작업 |
| **GAP-H02** | 로직 갭 | (없음) | 결격 룰 대학명 별칭 미인식 | 결격 누락 | ⚠️ P0 작업 |
| **GAP-H03** | 설명가능성 갭 | "근거 제시" (모호) | 매칭 플래그 부재 | 신뢰도 저하 | ⚠️ P0 작업 |
| **GAP-H04** | 성능 갭 | "P95 < 3초" | 실제 4.4초/케이스 | SLA 위반 가능 | ⚠️ P1 작업 |

---

### 4.3 Medium 갭 (🟢 권장, 2주 이내)

| 갭 ID | 갭 타입 | 명세 상태 | 실제 상태 | 영향 | 조치 |
|:------|:--------|:---------|:---------|:-----|:-----|
| **GAP-M01** | 테스트 갭 | "골든 케이스 3~5개" | 실제 필요 10+ | 회귀 방지 부족 | ⚠️ P1 작업 |
| **GAP-M02** | 문서 갭 | (없음) | API 문서 부족 | 온보딩 어려움 | ⚠️ P2 작업 |
| **GAP-M03** | 운영 갭 | (없음) | 모니터링 로그 과다 | 운영 부담 | ⚠️ P2 작업 |

---

## 5. 상세 비교표

### 5.1 STEP 3: PERCENTAGE 비교

| 측면 | 기존 명세 | 실제 구현 | 갭 |
|:-----|:---------|:---------|:---|
| **기능 설명** | "PERCENTAGE 정규화" | "백분위 기반 커트라인 조회 + 선형 보간" | ⬆️⬆️ |
| **입력** | (없음) | `(university, major, type, percentile)` | ⬆️⬆️⬆️ |
| **출력** | (없음) | `float (cutoff_score)` | ⬆️⬆️ |
| **% 축 방향** | **미명시** 🔴 | **0=상위, 100=하위** (역방향) | ⬆️⬆️⬆️ |
| **레벨 매핑** | **미명시** 🔴 | **20%=적정, 50%=예상, 80%=소신** | ⬆️⬆️⬆️ |
| **보간 정책** | (없음) | `linear` (기본) / `nearest` (옵션) | ⬆️⬆️ |
| **에러 처리** | (없음) | `KeyError` (컬럼 없음), `ValueError` (보간 불가) | ⬆️⬆️ |
| **테스트** | (없음) | `test_percentage_*` 5개 | ⬆️⬆️⬆️ |

**실제 발견된 버그**:
```python
# (수정 전) 코드
CUTOFF_PERCENTILES = {
    '적정': 80,  # ❌ 상위 80% = 하위권
    '예상': 50,
    '소신': 20   # ❌ 상위 20% = 상위권
}
# 결과: 적정(80) > 예상(50) > 소신(20) → 점수 역전!

# (수정 후) 코드
CUTOFF_PERCENTILES = {
    '적정': 20,  # ✅ 상위 20% = 안정권, 점수 높음
    '예상': 50,
    '소신': 80   # ✅ 상위 80% = 도전권, 점수 낮음
}
# 결과: 적정(20) < 예상(50) < 소신(80) → ✅ 정상
```

---

### 5.2 Alias 시스템 비교

| 측면 | 기존 명세 | 실제 구현 | 갭 |
|:-----|:---------|:---------|:---|
| **언급 여부** | ❌ 없음 | ✅ 완전 구현 | ⬆️⬆️⬆️ |
| **대학 Alias** | (없음) | 30+ 대학, 100+ 별칭 | ⬆️⬆️⬆️ |
| **전공 Alias** | (없음) | 30+ 전공, "의예→의학" 필수 | ⬆️⬆️⬆️ |
| **우선순위** | (없음) | 정확 → Alias → 퍼지 (4단계) | ⬆️⬆️⬆️ |
| **정규화 규칙** | "정규화" 언급만 | 괄호/공백/특수문자/접미사 제거 5단계 | ⬆️⬆️ |
| **오매핑 방지** | **미명시** 🔴 | **부분 매칭 제거** (서울과기대→서울대 방지) | ⬆️⬆️⬆️ |
| **퍼지 threshold** | (없음) | 대학=75, 전공=80 | ⬆️⬆️ |
| **테스트** | (없음) | `test_alias_*` 10+ 개 | ⬆️⬆️⬆️ |

**실제 발견된 버그**:
```python
# (수정 전) 코드
def _build_reverse_map():
    reverse = {}
    for official, aliases in UNIVERSITY_ALIASES.items():
        for alias in aliases:
            reverse[alias] = official  # ❌ 키가 정규화 안됨!
    return reverse

# 매칭 시
normalized = _normalize_university("SNU")  # "snu"
if normalized in reverse_map:  # ❌ 실패 ("SNU" 키는 정규화 안됨)
    ...

# 폴백: 부분 매칭
if "서울대" in "서울과학기술대학교":  # ❌ 오매핑!
    return "서울대"

# (수정 후) 코드
def _build_reverse_map():
    reverse = {}
    for official, aliases in UNIVERSITY_ALIASES.items():
        for alias in aliases:
            normalized_key = _normalize_university(alias)  # ✅ 정규화!
            reverse[normalized_key] = official
    return reverse

# 매칭 시
normalized = _normalize_university("SNU")  # "snu"
if normalized in reverse_map:  # ✅ 성공!
    return reverse_map[normalized]

# 부분 매칭 제거 (오매핑 방지)
```

---

#### 원인 #2: 자동화율과 정확도의 혼동

**명세 표현**:
```
| 커트라인 자동화율 | 90% | PERCENTAGE 정규화 |
```

**개발자 이해** (잘못):
- "90%의 경우를 정확히 처리한다"

**실제 의미**:
- **커버리지 90%**: 90%의 케이스를 처리 **시도**
- **정확도 ?%**: 처리한 케이스의 정확도는 **별도 측정 필요**

**검증 발견**:
- 커버리지: 90% ✅
- 정확도: 커트라인 방향 버그로 **품질 저하** 가능했음

**개선 명세**:
```
| 커트라인 조회 커버리지 | 90% | INDEX(70%) + PERCENTAGE(20%) 폴백 |
| 커트라인 조회 정확도 | 90% | 실제 합격선 ±5점 이내 (백테스트) |
| 커트라인 방향 검증 | 100% | 적정 ≥ 예상 ≥ 소신 (Sanity 필수) |
```

---

#### 원인 #3: 설명 가능성의 구현 불명확성

**명세 표현**:
```
NFR-AI04: 설명 가능성
- 모든 예측에 근거 제시
```

**문제점**:
1. "근거"가 **무엇**인지 불명확
   - 자연어 설명? ("홍대 합격 확률 82%는 과거 유사 학생...")
   - 구조화 데이터? (`{"method": "alias", "score": 0.82}`)
   - 둘 다?

2. "제시"가 **어디에** 불명확
   - API 응답 JSON에 포함?
   - UI에 표시?
   - 로그에만 기록?

3. **어떤 필드에** 저장할지 불명확
   - 기존 필드 확장?
   - 신규 필드 추가?
   - 별도 API?

**결과**:
- 개발팀이 **최소한으로 해석**
- `raw_components` (dict)에 디버그 정보만 저장
- 사용자 대면 설명은 **없음**

**개선 명세**:
```typescript
// 명확한 인터페이스 정의
interface TheoryResult {
  // ... 기존 필드
  
  // 신규: 설명 가능성 (API 응답에 포함)
  explainability: {
    // 대학 매칭 근거
    university_mapping: {
      input: string;
      matched: string;
      method: 'exact' | 'alias' | 'fuzzy';
      confidence: number;
      fuzzy_score?: number;
      alias_used?: string;
    };
    
    // 전공 매칭 근거
    major_mapping: {
      input: string;
      matched: string;
      method: 'exact' | 'alias' | 'fuzzy';
      alias_chain?: string[];
    };
    
    // 커트라인 소스
    cutoff_source: {
      sheet: 'INDEX' | 'PERCENTAGE';
      column_name: string;
      percentile?: number;
      interpolated: boolean;
    };
  };
}

// UI 표시 예시
"홍익대 합격 확률 82%"
└─ 상세 보기
   ├─ 대학: "홍대" → "홍익대" (별칭 매칭)
   ├─ 전공: "디자인" (정확 매칭)
   ├─ 커트라인: PERCENTAGE 시트, 50% 백분위
   └─ 예상선(73.13) 대비 +8.87점
```

---

## 6. 명세 개선 전/후 비교

### 6.1 PERCENTAGE 명세 비교

**개선 전**:
```markdown
### STEP 3: PERCENTAGE 정규화
- 백분위 기반 커트라인 조회
```

**개선 후**:
```markdown
### STEP 3: PERCENTAGE 백분위 정규화

#### ⚠️ CRITICAL: 축 방향 규칙

PERCENTAGE 시트 구조:
- % 컬럼: 0.00 ~ 94.0 (백분위)
- 점수 컬럼: 95.23 ~ 35.12 (환산 점수)
- **축 방향**: % 증가 → 점수 감소 (역비례)
  - 0% = 상위 0% = 최상위권 = 점수 최고
  - 100% = 상위 100% = 최하위권 = 점수 최저

#### 커트라인 레벨 매핑

CUTOFF_PERCENTILES = {
    '적정': 20,  # 상위 20% = 안정권 = 점수 높음
    '예상': 50,  # 상위 50% = 일반권 = 점수 중간
    '소신': 80   # 상위 80% = 도전권 = 점수 낮음
}

**검증 규칙**: 모든 케이스에서 적정 ≥ 예상 ≥ 소신

#### 수용 기준
- AC1: % 축 방향 검증 (0=상위)
- AC2: 레벨 매핑 검증 (20/50/80)
- AC3: 방향 Sanity 테스트 (적정≥예상≥소신)
- AC4: 실데이터 검증 (가천의학 이과 등)
```

**변화**:
- 추상적 "정규화" → **구체적 축 방향/매핑 규칙**
- 검증 방법 없음 → **Sanity 테스트 필수**
- 실데이터 근거 없음 → **가천의학 이과 예시**

---

### 6.2 Alias 명세 비교

**개선 전**:
```markdown
(Alias 시스템 명세 없음)

단, PRD에 "전공명 매핑 시스템" 언급:
- MAJOR_ALIASES 정의
- 의예→의학 매핑
```

**개선 후**:
```markdown
### 4. Alias 해소 시스템

#### 4.1 대학명 Alias

**매핑 테이블**: 30+ 대학, 100+ 별칭

**정규화 규칙**:
1. 소문자 변환
2. 괄호 제거
3. 공백/특수문자 제거
4. "대학교" 접미사 제거
5. strip()

**매칭 우선순위**:
1️⃣ 정확 매칭 (정규화 후)
2️⃣ Alias 매칭 (역매핑 키도 정규화!)
3️⃣ 퍼지 매칭 (threshold=75)
4️⃣ 실패 → KeyError

**⚠️ CRITICAL: 역매핑 키 정규화 필수**
- 이유: 키 미정규화 → 정확 매칭 실패 → 부분 매칭 오매핑
- 예시: "서울과기대" → "서울대" (부분 포함) ❌

**오매핑 방지**:
- 부분 매칭 로직 제거
- 테스트: test_alias_no_mismatch()

#### 4.2 전공명 Alias

**⚠️ CRITICAL: 의료계열 Alias 필수**
- 근거: 실데이터에 "의예" 컬럼 0개, "의학" 62개
- 매핑: "의예" → "의학" 필수

**매칭 우선순위**:
- Alias를 퍼지보다 **우선**
- 이유: 도메인 지식 (의예→의학) > 문자열 유사도
```

**변화**:
- 없음 → **완전한 시스템 명세**
- 우선순위 불명 → **4단계 명확화**
- 버그 위험 → **오매핑 방지 + 테스트**

---

## 7. 왜 이렇게 달라졌는가 (Root Cause)

### 7.1 명세 작성 프로세스의 문제

**기존 프로세스**:
```
PRD 읽기 → 개념 추출 → 명세 작성 → (끝)
```

**문제점**:
- ❌ 실제 데이터 미확인
- ❌ 실제 코드 미리뷰
- ❌ 개발자와 소통 없음
- ❌ 검증 계획 없음

**개선 프로세스**:
```
PRD 읽기 → 개념 추출
    ↓
실제 데이터 확인 (엑셀 파일 열기)
    ↓
실제 코드 리뷰 (GitHub/로컬)
    ↓
개발자 인터뷰 (구현 의도 파악)
    ↓
명세 초안 작성
    ↓
검증 계획 수립
    ↓
프로토타입 테스트
    ↓
명세 최종화
```

---

### 7.2 도메인 지식 부족

**PERCENTAGE 축 방향 오해**:
- 명세 작성자: 통계학 일반 지식으로 "백분위가 높으면 점수도 높다"고 가정
- 실제: 입시 데이터는 "상위 %"이므로 **역비례**
- 교훈: **도메인 전문가 리뷰 필수**

**의예과 이슈**:
- 명세 작성자: 의대가 "의학과"로만 있을 거라 가정
- 실제: 대부분 대학이 "의예과(6년제 통합)" 운영, 엑셀에는 "의학"으로 통일
- 교훈: **실데이터 스키마 반드시 확인**

---

### 7.3 테스트 주도 개발(TDD) 부재

**명세에서**:
```
Phase 2 완료 기준:
- ✅ Theory Engine v3가 85% 복원률 달성
- ✅ 모든 골든 케이스 테스트 통과
```

**문제점**:
- "골든 케이스"가 **몇 개**인지 미명시
- "테스트 통과"의 기준이 **불명확**
- Sanity 테스트 (방향 검증) **완전 누락**

**결과**:
- 커트라인 방향 버그를 **테스트가 못 잡음**
- 버그가 **프로덕션까지 갈 뻔**

**개선**:
```
Phase 2 완료 기준:
- ✅ 골든 케이스 10개 100% 통과
- ✅ Sanity 테스트 5개 100% 통과
  - 커트라인 방향 (적정≥예상≥소신)
  - 대학 오매핑 방지
  - 전공 Alias 필수 (의예→의학)
  - 결격 룰 대학명 인식
  - 의료계열 판정 정확성
- ✅ 단위 테스트 커버리지 80%+
- ✅ 통합 테스트 커버리지 70%+
```

---

## 8. 최종 권장사항

### 8.1 명세 작성 원칙 (향후 모든 명세에 적용)

| 원칙 | 설명 | 예시 |
|:-----|:-----|:-----|
| **1. 실제 데이터 우선** | 명세 전 실제 데이터 구조 확인 | PERCENTAGE 시트 열어보기 |
| **2. 코드 리뷰 병행** | 기존 구현 있으면 반드시 리뷰 | Theory Engine 코드 읽기 |
| **3. 인터페이스 명시** | 모든 기능에 입출력 타입 정의 | TypeScript/Python dataclass |
| **4. 수용 기준 계량화** | "~한다"가 아니라 "X초 이내, Y% 이상" | AC1: P95 < 3초 |
| **5. Sanity 테스트 필수** | 당연한 것도 테스트로 검증 | 적정 ≥ 예상 ≥ 소신 |
| **6. 도메인 전문가 리뷰** | 명세 초안 → 도메인 전문가 검토 | 원장/입시 컨설턴트 리뷰 |

---

### 8.2 즉시 실행 체크리스트

**P0: 오늘 (2~4시간)**

- [ ] `rules.py` - check_disqualification()
  - [ ] 대학명 정규화 적용
  - [ ] 테스트: `test_restrict_university_alias()`

- [ ] `rules.py` - _is_medical_major()
  - [ ] 키워드 명시적 정의 (의/약/치/한/수의/간호)
  - [ ] "의" 단일 포함 제거
  - [ ] 테스트: `test_restrict_medical_keywords()`

- [ ] `model.py` - TheoryResult
  - [ ] ExplainabilityInfo 필드 추가
  - [ ] 기본 필드: university_mapping, major_mapping, cutoff_source
  - [ ] 테스트: `test_explainability_fields()`

**P1: 이번 주 (1~2일)**

- [ ] Golden Case 10개 확장
  - [ ] 실데이터 기반 케이스 선정
  - [ ] 별칭/전공/오타 다양화
  - [ ] 각 케이스에 explainability 검증 추가

- [ ] 성능 개선
  - [ ] 워크북 캐싱 (`@lru_cache`)
  - [ ] INDEX 인메모리 인덱싱
  - [ ] 목표: 단일 예측 < 1초

- [ ] 성능 테스트
  - [ ] `pytest-benchmark` 도입
  - [ ] 단일/배치 성능 측정
  - [ ] CI/CD에 성능 회귀 검증 추가

**P2: 2주 이내**

- [ ] 에러 케이스 15개
  - [ ] 모든 예외 타입 커버
  - [ ] 에러 메시지 명확성 검증

- [ ] API 문서 생성
  - [ ] Sphinx 또는 MkDocs
  - [ ] 자동 생성 + 수동 보강

- [ ] 운영 개선
  - [ ] 로그 레벨 조정 (WARNING → INFO)
  - [ ] 로그 구조화 (JSON)

---

## 9. 교훈 및 Best Practices

### 9.1 이번 갭 분석에서 배운 것

| 교훈 | 설명 | 적용 방법 |
|:-----|:-----|:---------|
| **"당연함"을 명시하라** | 커트라인 방향 같은 "당연한" 규칙도 버그 가능 | Sanity 테스트 필수 |
| **실데이터가 정답** | PRD보다 실제 엑셀 파일이 진실 | 명세 전 데이터 확인 |
| **Alias는 복잡하다** | 단순 문자열 매칭으로 안 됨 | 정규화 + 우선순위 + 테스트 |
| **자동화율 ≠ 정확도** | 85% 처리 가능 ≠ 85% 정확 | 커버리지와 정확도 분리 명시 |
| **설명 가능성은 필드 설계** | "근거 제시"는 구현 불가능 | 구체적 필드 정의 |

---

### 9.2 다른 엔진/모듈 명세 작성 시 체크리스트

- [ ] **실제 데이터 확인**: 엑셀/DB/API 실제 스키마 확인
- [ ] **기존 코드 리뷰**: 구현 있으면 100% 리뷰
- [ ] **인터페이스 정의**: 모든 함수에 입출력 타입
- [ ] **수용 기준 계량화**: "~한다" → "X초, Y%, Z개"
- [ ] **Sanity 테스트 목록**: 당연한 것 5개 나열
- [ ] **도메인 전문가 리뷰**: 명세 초안 → 전문가 검토
- [ ] **에러 시나리오**: 정상 경로만큼 예외 경로도 명세
- [ ] **성능 시나리오 구분**: 최초/캐시/배치 각각 목표
- [ ] **버전 호환성**: 이전 버전과 호환 여부 명시
- [ ] **마이그레이션 계획**: Breaking Change 시 전환 방법

---

## 10. 결론

### 10.1 갭 요약

**기존 명세의 한계**:
- 개념적, 추상적, 구현 디테일 80% 누락
- 치명적 의미론 갭 2개 (PERCENTAGE 방향, Alias 오매핑)
- 설명 가능성/성능 목표 비현실적

**검증 보고서의 가치**:
- 실제 데이터 + 코드 기반 검증
- 버그 2개 발견 및 즉시 수정
- 명세 역류 (검증 → 명세 개선)

**개선된 명세의 특징**:
- 구체적 입출력 인터페이스
- 명확한 규칙 (축 방향, 우선순위, 매핑)
- 계량 가능한 AC
- Sanity 테스트로 버그 방지

---

### 10.2 향후 Action Items

| 우선순위 | 작업 | 기한 | 담당 |
|:--------:|:-----|:----:|:-----|
| **P0** | 결격 룰 대학명 정규화 | 오늘 | ML Engineer |
| **P0** | 의료계열 키워드 정교화 | 오늘 | ML Engineer |
| **P0** | Explainability 필드 추가 | 내일 | ML Engineer |
| **P1** | Golden Case 10개 | 이번 주 | QA Engineer |
| **P1** | 성능 개선 (캐싱/인덱싱) | 이번 주 | Data Engineer |
| **P1** | 성능 테스트 도입 | 이번 주 | QA Engineer |
| **P2** | API 문서 생성 | 2주 | Tech Writer |

---

**문서 끝**

| 항목 | 내용 |
|:-----|:-----|
| **문서 ID** | TE-SPEC-VS-ACTUAL-001 |
| **버전** | 1.0 |
| **최종 수정** | 2026-01-21 |
| **검토자** | ML Lead, Product Manager |
| **승인 여부** | ⏳ 대기 중 |
