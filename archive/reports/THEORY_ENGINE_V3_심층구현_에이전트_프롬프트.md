# ğŸ¤– Theory Engine v3 ì‹¬ì¸µ êµ¬í˜„ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸

> **ìƒì„±ì¼**: 2026-01-17
> **ëª©í‘œ**: ë¯¸ì™„ì„± 5ê°œ ê¸°ëŠ¥ 100% ì™„ì„±
> **ì˜ˆìƒ ì†Œìš”**: 3-4ì‹œê°„
> **ê²€ì¦ ê¸°ì¤€**: ì‹¤ì œ ì—‘ì…€ íŒŒì¼ ê¸°ë°˜ E2E í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ğŸ“‹ í˜„ì¬ ìƒíƒœ ìš”ì•½

### ì™„ë£Œëœ ê²ƒ âœ…
- `theory_engine/config.py` - ì‹œíŠ¸ ì„¤ì •, ë²„ì „ ê´€ë¦¬
- `theory_engine/constants.py` - Enum, ìƒìˆ˜ ì •ì˜
- `theory_engine/utils.py` - ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
- `theory_engine/loader.py` - ì—‘ì…€ ë¡œë“œ
- `theory_engine/model.py` - ë°ì´í„° ëª¨ë¸
- `theory_engine/rules.py` - ê¸°ë³¸ ë£° ì—”ì§„ (ë¯¸ì™„ì„± ë¶€ë¶„ ìˆìŒ)
- `tests/test_theory_engine.py` - ê¸°ë³¸ í…ŒìŠ¤íŠ¸
- `run_theory_engine.py` - ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

### ë¯¸ì™„ì„± ê¸°ëŠ¥ (ì´ë²ˆ ì‘ì—… ëŒ€ìƒ) âš ï¸

| ê¸°ëŠ¥ | í˜„ì¬ | ëª©í‘œ | íŒŒì¼ |
|------|------|------|------|
| INDEX ì¡°íšŒ | 50% | 95% | `optimizers/index_optimizer.py` |
| íƒêµ¬ê³¼ëª© ì¡°íšŒ | 70% | 95% | `matchers/subject_matcher.py` |
| RESTRICT ì²´í¬ | 50% | 90% | `rules/disqualification_engine.py` |
| í™•ë¥  ê³„ì‚° | 30% | 90% | `probability/admission_model.py` |
| ì»¤íŠ¸ë¼ì¸ ê³„ì‚° | 0% | 85% | `cutoff/cutoff_extractor.py` |

---

## ğŸ¯ ì—ì´ì „íŠ¸ ì§€ì¹¨

### ì‘ì—… ì›ì¹™
1. **íŒŒì¼ ì½ê¸° í•„ìˆ˜**: ìˆ˜ì • ì „ ë°˜ë“œì‹œ ê¸°ì¡´ ì½”ë“œ í™•ì¸
2. **ì ì§„ì  êµ¬í˜„**: í•œ ê¸°ëŠ¥ì”© ì™„ì„± í›„ í…ŒìŠ¤íŠ¸
3. **ì¸ì½”ë”© ì£¼ì˜**: ëª¨ë“  íŒŒì¼ UTF-8ë¡œ ì €ì¥
4. **ë¡œê¹… í™œìš©**: ë””ë²„ê·¸ ì •ë³´ ì¶©ë¶„íˆ ì¶œë ¥
5. **í…ŒìŠ¤íŠ¸ ìš°ì„ **: êµ¬í˜„ í›„ ì¦‰ì‹œ ê²€ì¦

### ê¸ˆì§€ ì‚¬í•­
- ì¶”ì¸¡ ê¸°ë°˜ ì½”ë“œ ì‘ì„± ê¸ˆì§€
- í•œ ë²ˆì— ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ìˆ˜ì • ê¸ˆì§€
- í…ŒìŠ¤íŠ¸ ì—†ì´ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ ê¸ˆì§€

---

## ğŸ“ ìµœì¢… íŒŒì¼ êµ¬ì¡°

```
theory_engine/
â”œâ”€â”€ __init__.py           # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ config.py             # ì„¤ì • (ê¸°ì¡´)
â”œâ”€â”€ constants.py          # ìƒìˆ˜ (ê¸°ì¡´)
â”œâ”€â”€ utils.py              # ìœ í‹¸ë¦¬í‹° (ê¸°ì¡´)
â”œâ”€â”€ loader.py             # ë¡œë” (ìˆ˜ì •)
â”œâ”€â”€ model.py              # ëª¨ë¸ (ê¸°ì¡´)
â”œâ”€â”€ rules.py              # ë£° ì—”ì§„ (ìˆ˜ì •)
â”‚
â”œâ”€â”€ optimizers/           # [NEW] ìµœì í™” ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ index_optimizer.py
â”‚
â”œâ”€â”€ matchers/             # [NEW] ë§¤ì¹­ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ subject_matcher.py
â”‚
â”œâ”€â”€ disqualification/     # [NEW] ê²°ê²© ì²´í¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ disqualification_engine.py
â”‚
â”œâ”€â”€ probability/          # [NEW] í™•ë¥  ê³„ì‚°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ admission_model.py
â”‚
â””â”€â”€ cutoff/               # [NEW] ì»¤íŠ¸ë¼ì¸
    â”œâ”€â”€ __init__.py
    â””â”€â”€ cutoff_extractor.py
```

---

## ğŸ”§ Phase 1: íƒêµ¬ê³¼ëª© ë§¤ì¹­ (30ë¶„)

### 1.1 ëª©í‘œ
- "ë¬¼ë¦¬í•™I" â†’ "ë¬¼ë¦¬í•™ â… " ìë™ ë³€í™˜
- 95% ì´ìƒ ë§¤ì¹­ ì •í™•ë„

### 1.2 êµ¬í˜„ íŒŒì¼

**íŒŒì¼**: `theory_engine/matchers/__init__.py`
```python
from .subject_matcher import SubjectMatcher

__all__ = ["SubjectMatcher"]
```

**íŒŒì¼**: `theory_engine/matchers/subject_matcher.py`
```python
"""
íƒêµ¬ê³¼ëª© ì´ë¦„ í¼ì§€ ë§¤ì¹­

ì‚¬ìš©ë²•:
    matcher = SubjectMatcher()
    canonical, score = matcher.match("ë¬¼ë¦¬í•™I")  # â†’ ("ë¬¼ë¦¬í•™ â… ", 95.0)
"""

import re
from typing import Dict, List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)

class SubjectMatcher:
    """íƒêµ¬ê³¼ëª© ì´ë¦„ í¼ì§€ ë§¤ì¹­"""
    
    # í‘œì¤€ ê³¼ëª©ëª… â†’ ë³„ì¹­ ëª©ë¡
    CANONICAL_SUBJECTS: Dict[str, List[str]] = {
        # === êµ­ì–´ ===
        "êµ­ì–´(ì–¸ë§¤)": ["êµ­ì–´ì–¸ë§¤", "ì–¸ì–´ì™€ë§¤ì²´", "ì–¸ë§¤", "êµ­ì–´ ì–¸ë§¤"],
        "êµ­ì–´(í™”ì‘)": ["êµ­ì–´í™”ì‘", "í™”ë²•ê³¼ì‘ë¬¸", "í™”ì‘", "êµ­ì–´ í™”ì‘"],
        
        # === ìˆ˜í•™ ===
        "ìˆ˜í•™(ë¯¸ì )": ["ìˆ˜í•™ë¯¸ì ", "ë¯¸ì ë¶„", "ë¯¸ì ", "ìˆ˜í•™ ë¯¸ì "],
        "ìˆ˜í•™(ê¸°í•˜)": ["ìˆ˜í•™ê¸°í•˜", "ê¸°í•˜", "ìˆ˜í•™ ê¸°í•˜"],
        "ìˆ˜í•™(í™•í†µ)": ["ìˆ˜í•™í™•í†µ", "í™•ë¥ ê³¼í†µê³„", "í™•í†µ", "ìˆ˜í•™ í™•í†µ"],
        
        # === ê³¼í•™íƒêµ¬ ===
        "ë¬¼ë¦¬í•™ â… ": ["ë¬¼ë¦¬í•™1", "ë¬¼ë¦¬í•™I", "ë¬¼ë¦¬1", "ë¬¼ë¦¬â… ", "ë¬¼ë¦¬ 1", "ë¬¼ë¦¬í•™ 1"],
        "ë¬¼ë¦¬í•™ â…¡": ["ë¬¼ë¦¬í•™2", "ë¬¼ë¦¬í•™II", "ë¬¼ë¦¬2", "ë¬¼ë¦¬â…¡", "ë¬¼ë¦¬ 2", "ë¬¼ë¦¬í•™ 2"],
        "í™”í•™ â… ": ["í™”í•™1", "í™”í•™I", "í™”1", "í™”í•™â… ", "í™”í•™ 1"],
        "í™”í•™ â…¡": ["í™”í•™2", "í™”í•™II", "í™”2", "í™”í•™â…¡", "í™”í•™ 2"],
        "ìƒëª…ê³¼í•™ â… ": ["ìƒëª…ê³¼í•™1", "ìƒëª…1", "ìƒë¬¼1", "ìƒëª…â… ", "ìƒëª…ê³¼í•™ 1", "ìƒê³¼1"],
        "ìƒëª…ê³¼í•™ â…¡": ["ìƒëª…ê³¼í•™2", "ìƒëª…2", "ìƒë¬¼2", "ìƒëª…â…¡", "ìƒëª…ê³¼í•™ 2", "ìƒê³¼2"],
        "ì§€êµ¬ê³¼í•™ â… ": ["ì§€êµ¬ê³¼í•™1", "ì§€êµ¬1", "ì§€í•™1", "ì§€êµ¬â… ", "ì§€êµ¬ê³¼í•™ 1"],
        "ì§€êµ¬ê³¼í•™ â…¡": ["ì§€êµ¬ê³¼í•™2", "ì§€êµ¬2", "ì§€í•™2", "ì§€êµ¬â…¡", "ì§€êµ¬ê³¼í•™ 2"],
        
        # === ì‚¬íšŒíƒêµ¬ ===
        "ìƒí™œê³¼ ìœ¤ë¦¬": ["ìƒìœ¤", "ìƒí™œìœ¤ë¦¬", "ìƒí™œê³¼ìœ¤ë¦¬"],
        "ìœ¤ë¦¬ì™€ ì‚¬ìƒ": ["ìœ¤ì‚¬", "ìœ¤ë¦¬ì‚¬ìƒ", "ìœ¤ë¦¬ì™€ì‚¬ìƒ"],
        "í•œêµ­ì§€ë¦¬": ["í•œì§€"],
        "ì„¸ê³„ì§€ë¦¬": ["ì„¸ì§€"],
        "ë™ì•„ì‹œì•„ì‚¬": ["ë™ì•„ì‚¬", "ë™ì•„ì‹œì•„"],
        "ì„¸ê³„ì‚¬": ["ì„¸ì‚¬"],
        "ê²½ì œ": [],
        "ì •ì¹˜ì™€ ë²•": ["ì •ë²•", "ì •ì¹˜ì™€ë²•"],
        "ì‚¬íšŒÂ·ë¬¸í™”": ["ì‚¬ë¬¸", "ì‚¬íšŒë¬¸í™”", "ì‚¬íšŒì™€ë¬¸í™”"],
        
        # === ì œ2ì™¸êµ­ì–´ ===
        "í•œë¬¸ â… ": ["í•œë¬¸1", "í•œë¬¸I"],
        "ì¼ë³¸ì–´ â… ": ["ì¼ë³¸ì–´1", "ì¼ì–´1"],
        "ì¤‘êµ­ì–´ â… ": ["ì¤‘êµ­ì–´1", "ì¤‘ì–´1"],
    }
    
    def __init__(self, threshold: int = 70):
        """
        Args:
            threshold: ë§¤ì¹­ ì„ê³„ê°’ (0-100)
        """
        self.threshold = threshold
        self._build_reverse_mapping()
        logger.info(f"SubjectMatcher ì´ˆê¸°í™”: {len(self.alias_to_canonical)}ê°œ ë§¤í•‘")
    
    def _build_reverse_mapping(self):
        """ë³„ì¹­ â†’ ì •ê·œ ì´ë¦„ ì—­ë§¤í•‘ êµ¬ì¶•"""
        self.alias_to_canonical: Dict[str, str] = {}
        
        for canonical, aliases in self.CANONICAL_SUBJECTS.items():
            # ì •ê·œ ì´ë¦„ ìì²´ë„ ë§¤í•‘
            normalized = self._normalize(canonical)
            self.alias_to_canonical[normalized] = canonical
            
            # ëª¨ë“  ë³„ì¹­ ë§¤í•‘
            for alias in aliases:
                normalized_alias = self._normalize(alias)
                self.alias_to_canonical[normalized_alias] = canonical
    
    def _normalize(self, name: str) -> str:
        """ë¬¸ìì—´ ì •ê·œí™”"""
        if not name:
            return ""
        
        # 1. ê³µë°± ì œê±°
        name = name.replace(" ", "")
        # 2. ë¡œë§ˆì í†µì¼ (â… â†’1, â…¡â†’2)
        name = name.replace("â… ", "1").replace("â…¡", "2")
        name = name.replace("I", "1").replace("II", "2")
        # 3. ì†Œë¬¸ì ë³€í™˜
        name = name.lower()
        # 4. íŠ¹ìˆ˜ë¬¸ì ì œê±° (Â·, (, ) ë“±)
        name = re.sub(r'[^\wê°€-í£0-9]', '', name)
        
        return name
    
    def match(self, input_name: str) -> Tuple[str, float]:
        """
        ì…ë ¥ ê³¼ëª©ëª… â†’ ì •ê·œ ê³¼ëª©ëª… ë§¤ì¹­
        
        Args:
            input_name: ì…ë ¥ ê³¼ëª©ëª…
        
        Returns:
            (canonical_name, confidence_score)
            - canonical_name: ì •ê·œí™”ëœ ê³¼ëª©ëª…
            - confidence_score: ì‹ ë¢°ë„ (0-100)
        """
        if not input_name:
            return input_name, 0.0
        
        normalized = self._normalize(input_name)
        
        # 1. ì •í™•í•œ ë§¤ì¹­
        if normalized in self.alias_to_canonical:
            canonical = self.alias_to_canonical[normalized]
            logger.debug(f"ì •í™• ë§¤ì¹­: '{input_name}' â†’ '{canonical}'")
            return canonical, 100.0
        
        # 2. ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
        for alias, canonical in self.alias_to_canonical.items():
            if normalized in alias or alias in normalized:
                score = len(normalized) / max(len(alias), len(normalized)) * 100
                if score >= self.threshold:
                    logger.debug(f"ë¶€ë¶„ ë§¤ì¹­: '{input_name}' â†’ '{canonical}' (score={score:.1f})")
                    return canonical, score
        
        # 3. ë ˆë²¤ìŠˆíƒ€ì¸ ê±°ë¦¬ ê¸°ë°˜ ë§¤ì¹­ (ê°„ë‹¨ êµ¬í˜„)
        best_match = None
        best_score = 0
        
        for alias, canonical in self.alias_to_canonical.items():
            score = self._similarity_score(normalized, alias)
            if score > best_score:
                best_score = score
                best_match = canonical
        
        if best_match and best_score >= self.threshold:
            logger.debug(f"ìœ ì‚¬ ë§¤ì¹­: '{input_name}' â†’ '{best_match}' (score={best_score:.1f})")
            return best_match, best_score
        
        # 4. ë§¤ì¹­ ì‹¤íŒ¨ - ì›ë³¸ ë°˜í™˜
        logger.warning(f"ë§¤ì¹­ ì‹¤íŒ¨: '{input_name}'")
        return input_name, 0.0
    
    def _similarity_score(self, s1: str, s2: str) -> float:
        """ë‘ ë¬¸ìì—´ ìœ ì‚¬ë„ (0-100)"""
        if not s1 or not s2:
            return 0.0
        
        # ê³µí†µ ë¬¸ì ë¹„ìœ¨
        common = set(s1) & set(s2)
        total = set(s1) | set(s2)
        
        if not total:
            return 0.0
        
        return len(common) / len(total) * 100
    
    def get_all_canonical_names(self) -> List[str]:
        """ëª¨ë“  ì •ê·œ ê³¼ëª©ëª… ë°˜í™˜"""
        return list(self.CANONICAL_SUBJECTS.keys())
    
    def get_aliases(self, canonical_name: str) -> List[str]:
        """ì •ê·œ ê³¼ëª©ëª…ì˜ ëª¨ë“  ë³„ì¹­ ë°˜í™˜"""
        return self.CANONICAL_SUBJECTS.get(canonical_name, [])


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    
    matcher = SubjectMatcher()
    
    test_cases = [
        "ë¬¼ë¦¬í•™I",
        "ë¬¼ë¦¬í•™ â… ",
        "í™”í•™1",
        "ìƒìœ¤",
        "ìˆ˜í•™(ë¯¸ì )",
        "êµ­ì–´(ì–¸ë§¤)",
        "ìƒëª…ê³¼í•™ â… ",
        "ì§€êµ¬ê³¼í•™2",
    ]
    
    print("\n=== ê³¼ëª© ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ===")
    for name in test_cases:
        canonical, score = matcher.match(name)
        status = "âœ“" if score >= 70 else "âœ—"
        print(f"{status} '{name}' â†’ '{canonical}' (score={score:.1f})")
```

### 1.3 í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´
```bash
cd C:\Neoprime
python -m theory_engine.matchers.subject_matcher
```

### 1.4 ì™„ë£Œ ê¸°ì¤€
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µê³¼
- [ ] ë§¤ì¹­ ì„±ê³µë¥  95% ì´ìƒ
- [ ] ë¡œê¹… ì¶œë ¥ ì •ìƒ

---

## ğŸ”§ Phase 2: INDEX ìµœì í™” (45ë¶„)

### 2.1 ëª©í‘œ
- 20ë§Œ í–‰ ì¡°íšŒ 1ms ì´í•˜
- ì •í™•í•œ í‚¤ ë§¤ì¹­ + ê·¼ì‚¬ ê²€ìƒ‰

### 2.2 êµ¬í˜„ íŒŒì¼

**íŒŒì¼**: `theory_engine/optimizers/__init__.py`
```python
from .index_optimizer import IndexOptimizer

__all__ = ["IndexOptimizer"]
```

**íŒŒì¼**: `theory_engine/optimizers/index_optimizer.py`
```python
"""
INDEX ì‹œíŠ¸ ì¡°íšŒ ìµœì í™”

20ë§Œ í–‰ì„ O(1)ì— ì¡°íšŒí•˜ê¸° ìœ„í•œ MultiIndex ê¸°ë°˜ ìµœì í™”
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, Optional, Tuple, Any

logger = logging.getLogger(__name__)

class IndexOptimizer:
    """INDEX ì‹œíŠ¸ ì¡°íšŒ ìµœì í™” (20ë§Œ í–‰ ëŒ€ì‘)"""
    
    # ì»¬ëŸ¼ëª… ë§¤í•‘ (ì‹¤ì œ INDEX ì‹œíŠ¸ êµ¬ì¡° ê¸°ë°˜)
    COLUMN_MAPPING = {
        'Unnamed: 1': 'korean_std',
        'Unnamed: 2': 'math_std',
        'Unnamed: 3': 'inq1_std',
        'Unnamed: 4': 'inq2_std',
        'Unnamed: 5': 'track',
        'Unnamed: 6': 'percentile_sum',
        'Unnamed: 7': 'national_rank',
        'Unnamed: 8': 'cumulative_pct',
    }
    
    KEY_COLUMNS = ['korean_std', 'math_std', 'inq1_std', 'inq2_std', 'track']
    VALUE_COLUMNS = ['percentile_sum', 'national_rank', 'cumulative_pct']
    
    def __init__(self, index_df: pd.DataFrame):
        """
        Args:
            index_df: INDEX ì‹œíŠ¸ ì›ë³¸ DataFrame
        """
        self.raw_df = index_df
        self._cache: Dict[Tuple, Dict] = {}
        self._build_optimized_index()
    
    def _build_optimized_index(self):
        """MultiIndex êµ¬ì¶•"""
        logger.info(f"INDEX ìµœì í™” ì‹œì‘: {len(self.raw_df)}í–‰")
        
        # 1. ì»¬ëŸ¼ëª… ë§¤í•‘
        self.df = self.raw_df.copy()
        
        # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸
        logger.debug(f"ì›ë³¸ ì»¬ëŸ¼: {list(self.df.columns)}")
        
        # ë§¤í•‘ ì ìš©
        rename_map = {}
        for old_name, new_name in self.COLUMN_MAPPING.items():
            if old_name in self.df.columns:
                rename_map[old_name] = new_name
        
        if rename_map:
            self.df = self.df.rename(columns=rename_map)
            logger.info(f"ì»¬ëŸ¼ ë§¤í•‘: {len(rename_map)}ê°œ")
        
        # 2. í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        available_keys = [c for c in self.KEY_COLUMNS if c in self.df.columns]
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {available_keys}")
        
        if len(available_keys) < 2:
            logger.warning("í‚¤ ì»¬ëŸ¼ ë¶€ì¡±, ê¸°ë³¸ ì¸ë±ìŠ¤ ì‚¬ìš©")
            self.use_multiindex = False
            return
        
        # 3. MultiIndex ì„¤ì •
        try:
            # NaN ì œê±°
            self.df = self.df.dropna(subset=available_keys)
            
            # íƒ€ì… ë³€í™˜ (ìˆ«ìë¡œ)
            for col in available_keys[:-1]:  # track ì œì™¸
                if col in self.df.columns:
                    self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
            
            # MultiIndex ì„¤ì •
            self.df = self.df.set_index(available_keys)
            self.df = self.df.sort_index()
            self.use_multiindex = True
            
            logger.info(f"MultiIndex êµ¬ì¶• ì™„ë£Œ: {len(self.df)}í–‰")
            
        except Exception as e:
            logger.error(f"MultiIndex êµ¬ì¶• ì‹¤íŒ¨: {e}")
            self.use_multiindex = False
    
    def lookup(
        self,
        korean_std: int,
        math_std: int,
        inq1_std: int,
        inq2_std: int,
        track: str,
        fuzzy: bool = True
    ) -> Dict[str, Any]:
        """
        ì ìˆ˜ ì¡°í•©ìœ¼ë¡œ INDEX í–‰ ì¡°íšŒ
        
        Args:
            korean_std: êµ­ì–´ í‘œì¤€ì ìˆ˜
            math_std: ìˆ˜í•™ í‘œì¤€ì ìˆ˜
            inq1_std: íƒêµ¬1 í‘œì¤€ì ìˆ˜
            inq2_std: íƒêµ¬2 í‘œì¤€ì ìˆ˜
            track: ê³„ì—´ ("ì´ê³¼" | "ë¬¸ê³¼")
            fuzzy: Trueë©´ ê·¼ì‚¬ ê²€ìƒ‰ í—ˆìš©
        
        Returns:
            {
                'found': True,
                'exact_match': True,
                'index_key': '130-135-65-62-ì´ê³¼',
                'percentile_sum': 390.5,
                'national_rank': 1234,
                'cumulative_pct': 98.5
            }
        """
        key = (korean_std, math_std, inq1_std, inq2_std, track)
        index_key = f"{korean_std}-{math_std}-{inq1_std}-{inq2_std}-{track}"
        
        # ìºì‹œ í™•ì¸
        if key in self._cache:
            return self._cache[key]
        
        result = {
            'found': False,
            'exact_match': False,
            'index_key': index_key,
            'percentile_sum': None,
            'national_rank': None,
            'cumulative_pct': None,
        }
        
        if not self.use_multiindex:
            # ê¸°ë³¸ ê²€ìƒ‰ (ëŠë¦¼)
            result = self._basic_lookup(key, index_key)
        else:
            # MultiIndex ê²€ìƒ‰ (ë¹ ë¦„)
            try:
                if key in self.df.index:
                    row = self.df.loc[key]
                    result = self._extract_result(row, index_key, exact=True)
                elif fuzzy:
                    result = self._fuzzy_lookup(key, index_key)
            except KeyError:
                if fuzzy:
                    result = self._fuzzy_lookup(key, index_key)
        
        self._cache[key] = result
        return result
    
    def _basic_lookup(self, key: Tuple, index_key: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„ í˜• ê²€ìƒ‰"""
        korean, math, inq1, inq2, track = key
        
        mask = (
            (self.raw_df.iloc[:, 1] == korean) &
            (self.raw_df.iloc[:, 2] == math) &
            (self.raw_df.iloc[:, 3] == inq1) &
            (self.raw_df.iloc[:, 4] == inq2)
        )
        
        result_df = self.raw_df[mask]
        
        if result_df.empty:
            return {
                'found': False,
                'exact_match': False,
                'index_key': index_key,
                'percentile_sum': None,
                'national_rank': None,
                'cumulative_pct': None,
            }
        
        row = result_df.iloc[0]
        return self._extract_result(row, index_key, exact=True)
    
    def _extract_result(self, row, index_key: str, exact: bool) -> Dict[str, Any]:
        """ê²°ê³¼ ì¶”ì¶œ"""
        return {
            'found': True,
            'exact_match': exact,
            'index_key': index_key,
            'percentile_sum': row.get('percentile_sum', row.iloc[0] if len(row) > 0 else None),
            'national_rank': row.get('national_rank', row.iloc[1] if len(row) > 1 else None),
            'cumulative_pct': row.get('cumulative_pct', row.iloc[2] if len(row) > 2 else None),
        }
    
    def _fuzzy_lookup(self, key: Tuple, index_key: str) -> Dict[str, Any]:
        """ê·¼ì‚¬ ê²€ìƒ‰ (ê°€ì¥ ê°€ê¹Œìš´ í‚¤ ì°¾ê¸°)"""
        korean, math, inq1, inq2, track = key
        
        # ê³„ì—´ í•„í„°ë§
        if self.use_multiindex:
            try:
                track_df = self.df.xs(track, level='track', drop_level=False)
            except KeyError:
                track_df = self.df
        else:
            track_df = self.raw_df
        
        if track_df.empty:
            return {
                'found': False,
                'exact_match': False,
                'approximate': True,
                'index_key': index_key,
                'percentile_sum': None,
                'national_rank': None,
                'cumulative_pct': None,
            }
        
        # ê±°ë¦¬ ê³„ì‚° (ê°„ë‹¨í•œ L1 ê±°ë¦¬)
        if self.use_multiindex:
            # MultiIndexì—ì„œ ë ˆë²¨ ê°’ ì¶”ì¶œ
            levels = track_df.index.to_frame()
            scores = levels[['korean_std', 'math_std', 'inq1_std', 'inq2_std']].values
        else:
            scores = track_df.iloc[:, 1:5].values
        
        target = np.array([korean, math, inq1, inq2])
        distances = np.abs(scores - target).sum(axis=1)
        
        nearest_idx = distances.argmin()
        row = track_df.iloc[nearest_idx]
        
        result = self._extract_result(row, index_key, exact=False)
        result['approximate'] = True
        result['distance'] = int(distances[nearest_idx])
        
        logger.debug(f"ê·¼ì‚¬ ë§¤ì¹­: distance={result['distance']}")
        return result
    
    def get_stats(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´"""
        return {
            'total_rows': len(self.raw_df),
            'indexed_rows': len(self.df) if self.use_multiindex else 0,
            'cache_size': len(self._cache),
            'use_multiindex': self.use_multiindex,
        }


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
    print("=== INDEX ìµœì í™” í…ŒìŠ¤íŠ¸ ===")
    
    # ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    from theory_engine.loader import load_workbook
    from theory_engine.config import EXCEL_PATH
    
    print(f"ì—‘ì…€ ë¡œë“œ: {EXCEL_PATH}")
    data = load_workbook(EXCEL_PATH)
    
    if "INDEX" in data:
        optimizer = IndexOptimizer(data["INDEX"])
        print(f"í†µê³„: {optimizer.get_stats()}")
        
        # í…ŒìŠ¤íŠ¸ ì¡°íšŒ
        result = optimizer.lookup(130, 135, 65, 62, "ì´ê³¼")
        print(f"ì¡°íšŒ ê²°ê³¼: {result}")
    else:
        print("INDEX ì‹œíŠ¸ ì—†ìŒ")
```

### 2.3 í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´
```bash
cd C:\Neoprime
python -m theory_engine.optimizers.index_optimizer
```

### 2.4 ì™„ë£Œ ê¸°ì¤€
- [ ] MultiIndex êµ¬ì¶• ì„±ê³µ
- [ ] ì¡°íšŒ ì‹œê°„ 10ms ì´í•˜
- [ ] ê·¼ì‚¬ ê²€ìƒ‰ ì‘ë™

---

## ğŸ”§ Phase 3: ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ (45ë¶„)

### 3.1 ëª©í‘œ
- PERCENTAGE ì‹œíŠ¸ì—ì„œ 80/50/20% ë¼ì¸ ìë™ ì¶”ì¶œ
- ëŒ€í•™/ì „ê³µë³„ ì»¤íŠ¸ë¼ì¸ ê³„ì‚°

### 3.2 êµ¬í˜„ íŒŒì¼

**íŒŒì¼**: `theory_engine/cutoff/__init__.py`
```python
from .cutoff_extractor import CutoffExtractor

__all__ = ["CutoffExtractor"]
```

**íŒŒì¼**: `theory_engine/cutoff/cutoff_extractor.py`
```python
"""
ì»¤íŠ¸ë¼ì¸ ìë™ ì¶”ì¶œê¸°

PERCENTAGE ì‹œíŠ¸ì—ì„œ ëŒ€í•™/ì „ê³µë³„ ì»¤íŠ¸ë¼ì¸(80%/50%/20%) ì¶”ì¶œ
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)

class CutoffExtractor:
    """ì»¤íŠ¸ë¼ì¸ ìë™ ì¶”ì¶œê¸°"""
    
    # ê¸°ì¤€ í™•ë¥  ë¼ì¸
    CUTOFF_PERCENTILES = {
        "ì ì •": 80.0,   # ìƒìœ„ 20% â†’ ëˆ„ë°± 80%
        "ì˜ˆìƒ": 50.0,   # ìƒìœ„ 50% â†’ ëˆ„ë°± 50%
        "ì†Œì‹ ": 20.0,   # ìƒìœ„ 80% â†’ ëˆ„ë°± 20%
    }
    
    def __init__(self, percentage_df: pd.DataFrame):
        """
        Args:
            percentage_df: PERCENTAGE ì‹œíŠ¸ DataFrame
        """
        self.df = percentage_df
        self._cache: Dict[str, Dict] = {}
        self._analyze_structure()
    
    def _analyze_structure(self):
        """ì‹œíŠ¸ êµ¬ì¡° ë¶„ì„"""
        logger.info(f"PERCENTAGE ì‹œíŠ¸ ë¶„ì„: {self.df.shape}")
        
        # ì²« ì»¬ëŸ¼ (ëˆ„ë°±/%) í™•ì¸
        self.percentile_col = self.df.columns[0]
        logger.info(f"ëˆ„ë°± ì»¬ëŸ¼: '{self.percentile_col}'")
        
        # ëŒ€í•™/ì „ê³µ ì»¬ëŸ¼ ëª©ë¡
        self.program_columns = [
            col for col in self.df.columns[1:] 
            if not str(col).startswith('Unnamed') and not str(col).startswith('â˜…')
        ]
        logger.info(f"ëŒ€í•™/ì „ê³µ ì»¬ëŸ¼: {len(self.program_columns)}ê°œ")
        
        # ìƒ˜í”Œ ì¶œë ¥
        if self.program_columns:
            logger.debug(f"ìƒ˜í”Œ ì»¬ëŸ¼: {self.program_columns[:5]}")
    
    def extract_cutoffs(
        self,
        university: str,
        major: str,
        track: str = ""
    ) -> Dict[str, Optional[float]]:
        """
        ëŒ€í•™/ì „ê³µì˜ ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ
        
        Args:
            university: ëŒ€í•™ëª… (ì˜ˆ: "ì„œìš¸ëŒ€", "ì—°ì„¸ëŒ€")
            major: ì „ê³µëª… (ì˜ˆ: "ì˜ì˜ˆ", "ê³µëŒ€")
            track: ê³„ì—´ (ì„ íƒ, "ì´ê³¼" | "ë¬¸ê³¼")
        
        Returns:
            {
                'found': True,
                'column': 'ì„œìš¸ëŒ€ì˜ì˜ˆ ì´ê³¼',
                'cutoff_safe': 97.5,    # ì ì • (80%)
                'cutoff_normal': 95.0,  # ì˜ˆìƒ (50%)
                'cutoff_risk': 92.0,    # ì†Œì‹  (20%)
            }
        """
        cache_key = f"{university}_{major}_{track}"
        if cache_key in self._cache:
            return self._cache[cache_key]
        
        # ì»¬ëŸ¼ ì°¾ê¸°
        program_col = self._find_program_column(university, major, track)
        
        if program_col is None:
            result = {
                'found': False,
                'column': None,
                'cutoff_safe': None,
                'cutoff_normal': None,
                'cutoff_risk': None,
            }
            self._cache[cache_key] = result
            return result
        
        # ì»¤íŠ¸ë¼ì¸ ê³„ì‚°
        result = self._calculate_cutoffs(program_col)
        result['found'] = True
        result['column'] = program_col
        
        self._cache[cache_key] = result
        return result
    
    def _find_program_column(
        self,
        university: str,
        major: str,
        track: str = ""
    ) -> Optional[str]:
        """ëŒ€í•™/ì „ê³µì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°"""
        
        # íŒ¨í„´ ìƒì„±
        patterns = [
            f"{university}{major}",           # "ì„œìš¸ëŒ€ì˜ì˜ˆ"
            f"{university} {major}",          # "ì„œìš¸ëŒ€ ì˜ì˜ˆ"
            f"{university}{major} {track}" if track else None,  # "ì„œìš¸ëŒ€ì˜ì˜ˆ ì´ê³¼"
        ]
        patterns = [p for p in patterns if p]
        
        # ì •í™•í•œ ë§¤ì¹­
        for col in self.df.columns:
            col_str = str(col)
            for pattern in patterns:
                if pattern in col_str:
                    logger.debug(f"ì»¬ëŸ¼ ë§¤ì¹­: '{pattern}' â†’ '{col_str}'")
                    return col
        
        # ë¶€ë¶„ ë§¤ì¹­
        for col in self.df.columns:
            col_str = str(col)
            if university in col_str and major in col_str:
                logger.debug(f"ë¶€ë¶„ ë§¤ì¹­: '{university}+{major}' â†’ '{col_str}'")
                return col
        
        # ëŒ€í•™ë§Œ ë§¤ì¹­
        for col in self.df.columns:
            col_str = str(col)
            if university in col_str:
                logger.debug(f"ëŒ€í•™ ë§¤ì¹­: '{university}' â†’ '{col_str}'")
                return col
        
        logger.warning(f"ì»¬ëŸ¼ ì—†ìŒ: {university}{major}")
        return None
    
    def _calculate_cutoffs(self, program_col: str) -> Dict[str, Optional[float]]:
        """ì»¤íŠ¸ë¼ì¸ ê³„ì‚°"""
        
        # ë°ì´í„° ì¶”ì¶œ
        df_subset = self.df[[self.percentile_col, program_col]].copy()
        df_subset.columns = ['percentile', 'score']
        
        # NaN ì œê±° ë° ì •ë ¬
        df_subset = df_subset.dropna()
        df_subset['percentile'] = pd.to_numeric(df_subset['percentile'], errors='coerce')
        df_subset['score'] = pd.to_numeric(df_subset['score'], errors='coerce')
        df_subset = df_subset.dropna()
        df_subset = df_subset.sort_values('percentile')
        
        if len(df_subset) < 2:
            return {
                'cutoff_safe': None,
                'cutoff_normal': None,
                'cutoff_risk': None,
            }
        
        result = {}
        
        for name, pct in self.CUTOFF_PERCENTILES.items():
            try:
                # ë³´ê°„ìœ¼ë¡œ ì»¤íŠ¸ë¼ì¸ ê³„ì‚°
                score = np.interp(
                    pct,
                    df_subset['percentile'].values,
                    df_subset['score'].values
                )
                result[f'cutoff_{name}'] = round(float(score), 2)
            except Exception as e:
                logger.warning(f"ì»¤íŠ¸ë¼ì¸ ê³„ì‚° ì‹¤íŒ¨ ({name}): {e}")
                result[f'cutoff_{name}'] = None
        
        # í‚¤ ì´ë¦„ ë³€í™˜
        return {
            'cutoff_safe': result.get('cutoff_ì ì •'),
            'cutoff_normal': result.get('cutoff_ì˜ˆìƒ'),
            'cutoff_risk': result.get('cutoff_ì†Œì‹ '),
        }
    
    def get_score_at_percentile(
        self,
        university: str,
        major: str,
        percentile: float
    ) -> Optional[float]:
        """íŠ¹ì • ëˆ„ë°±ì—ì„œì˜ í™˜ì‚°ì ìˆ˜ ì¡°íšŒ"""
        
        program_col = self._find_program_column(university, major)
        if program_col is None:
            return None
        
        df_subset = self.df[[self.percentile_col, program_col]].copy()
        df_subset.columns = ['pct', 'score']
        df_subset = df_subset.dropna()
        df_subset['pct'] = pd.to_numeric(df_subset['pct'], errors='coerce')
        df_subset['score'] = pd.to_numeric(df_subset['score'], errors='coerce')
        df_subset = df_subset.dropna().sort_values('pct')
        
        if len(df_subset) < 2:
            return None
        
        try:
            score = np.interp(
                percentile,
                df_subset['pct'].values,
                df_subset['score'].values
            )
            return round(float(score), 2)
        except:
            return None
    
    def list_available_programs(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€í•™/ì „ê³µ ëª©ë¡"""
        return self.program_columns
    
    def get_stats(self) -> Dict:
        """í†µê³„ ì •ë³´"""
        return {
            'total_programs': len(self.program_columns),
            'percentile_range': (
                self.df[self.percentile_col].min(),
                self.df[self.percentile_col].max()
            ),
            'cache_size': len(self._cache),
        }


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    from theory_engine.loader import load_workbook
    from theory_engine.config import EXCEL_PATH
    
    print("=== ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ===")
    print(f"ì—‘ì…€ ë¡œë“œ: {EXCEL_PATH}")
    
    data = load_workbook(EXCEL_PATH)
    
    if "PERCENTAGE" in data:
        extractor = CutoffExtractor(data["PERCENTAGE"])
        print(f"í†µê³„: {extractor.get_stats()}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œê·¸ë¨ ëª©ë¡
        programs = extractor.list_available_programs()
        print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€í•™/ì „ê³µ: {len(programs)}ê°œ")
        if programs:
            print(f"ìƒ˜í”Œ: {programs[:10]}")
        
        # ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        test_cases = [
            ("ê°€ì²œ", "ì˜í•™"),
            ("ê±´êµ­", "ìì—°"),
            ("ì„œìš¸ëŒ€", "ê³µëŒ€"),
        ]
        
        print("\n=== ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ ===")
        for univ, major in test_cases:
            result = extractor.extract_cutoffs(univ, major)
            if result['found']:
                print(f"âœ“ {univ}{major}: ì ì •={result['cutoff_safe']}, "
                      f"ì˜ˆìƒ={result['cutoff_normal']}, ì†Œì‹ ={result['cutoff_risk']}")
            else:
                print(f"âœ— {univ}{major}: ë°ì´í„° ì—†ìŒ")
    else:
        print("PERCENTAGE ì‹œíŠ¸ ì—†ìŒ")
```

### 3.3 í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´
```bash
cd C:\Neoprime
python -m theory_engine.cutoff.cutoff_extractor
```

---

## ğŸ”§ Phase 4: í™•ë¥  ê³„ì‚° ëª¨ë¸ (45ë¶„)

### 4.1 êµ¬í˜„ íŒŒì¼

**íŒŒì¼**: `theory_engine/probability/__init__.py`
```python
from .admission_model import AdmissionProbabilityModel

__all__ = ["AdmissionProbabilityModel"]
```

**íŒŒì¼**: `theory_engine/probability/admission_model.py`
```python
"""
í•©ê²© í™•ë¥  ê³„ì‚° ëª¨ë¸

í•™ìƒ ì ìˆ˜ì™€ ì»¤íŠ¸ë¼ì¸ ê¸°ë°˜ í•©ê²© í™•ë¥  ê³„ì‚°
"""

import logging
from typing import Dict, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ProbabilityResult:
    """í™•ë¥  ê³„ì‚° ê²°ê³¼"""
    probability: float
    level: str
    confidence_low: float
    confidence_high: float


class AdmissionProbabilityModel:
    """í•©ê²© í™•ë¥  ê³„ì‚° ëª¨ë¸"""
    
    # ë¼ì¸ë³„ ê¸°ë³¸ í™•ë¥  ë²”ìœ„
    LEVEL_RANGES = {
        "ì ì •": (0.80, 1.00),
        "ì˜ˆìƒ": (0.50, 0.80),
        "ì†Œì‹ ": (0.20, 0.50),
        "ìƒí–¥": (0.00, 0.20),
    }
    
    def __init__(self, uncertainty: float = 0.10):
        """
        Args:
            uncertainty: ê¸°ë³¸ ë¶ˆí™•ì‹¤ì„± (í‘œì¤€í¸ì°¨)
        """
        self.uncertainty = uncertainty
    
    def calculate(
        self,
        student_score: float,
        cutoff_safe: Optional[float],
        cutoff_normal: Optional[float],
        cutoff_risk: Optional[float]
    ) -> ProbabilityResult:
        """
        í•©ê²© í™•ë¥  ê³„ì‚°
        
        Args:
            student_score: í•™ìƒì˜ í™˜ì‚°ì ìˆ˜
            cutoff_safe: ì ì • ì»¤íŠ¸ë¼ì¸ (80%)
            cutoff_normal: ì˜ˆìƒ ì»¤íŠ¸ë¼ì¸ (50%)
            cutoff_risk: ì†Œì‹  ì»¤íŠ¸ë¼ì¸ (20%)
        
        Returns:
            ProbabilityResult
        """
        # ì»¤íŠ¸ë¼ì¸ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        if cutoff_normal is None:
            return ProbabilityResult(
                probability=0.50,
                level="ì•Œìˆ˜ì—†ìŒ",
                confidence_low=0.30,
                confidence_high=0.70
            )
        
        # ì ìˆ˜ ìœ„ì¹˜ íŒì •
        if cutoff_safe and student_score >= cutoff_safe:
            # ì ì • ì´ìƒ
            prob = self._calc_prob_above(student_score, cutoff_safe, 0.80, 1.00)
            level = "ì ì •"
            
        elif student_score >= cutoff_normal:
            # ì˜ˆìƒ ë²”ìœ„
            if cutoff_safe:
                ratio = (student_score - cutoff_normal) / (cutoff_safe - cutoff_normal)
            else:
                ratio = 0.5
            prob = 0.50 + ratio * 0.30
            level = "ì˜ˆìƒ"
            
        elif cutoff_risk and student_score >= cutoff_risk:
            # ì†Œì‹  ë²”ìœ„
            ratio = (student_score - cutoff_risk) / (cutoff_normal - cutoff_risk)
            prob = 0.20 + ratio * 0.30
            level = "ì†Œì‹ "
            
        else:
            # ìƒí–¥ ë²”ìœ„
            if cutoff_risk:
                ratio = max(0, student_score / cutoff_risk)
                prob = ratio * 0.20
            else:
                prob = 0.10
            level = "ìƒí–¥"
        
        # í™•ë¥  ë²”ìœ„ ì œí•œ
        prob = max(0.01, min(0.99, prob))
        
        # ì‹ ë¢°êµ¬ê°„
        ci_low = max(0.00, prob - 1.96 * self.uncertainty)
        ci_high = min(1.00, prob + 1.96 * self.uncertainty)
        
        return ProbabilityResult(
            probability=round(prob, 4),
            level=level,
            confidence_low=round(ci_low, 4),
            confidence_high=round(ci_high, 4)
        )
    
    def _calc_prob_above(
        self,
        score: float,
        cutoff: float,
        base_prob: float,
        max_prob: float
    ) -> float:
        """ì»¤íŠ¸ë¼ì¸ ì´ìƒì¼ ë•Œ í™•ë¥  ê³„ì‚°"""
        excess = score - cutoff
        range_above = cutoff * 0.05  # 5% ì—¬ìœ 
        
        if range_above <= 0:
            return base_prob
        
        normalized = min(1.0, excess / range_above)
        return base_prob + normalized * (max_prob - base_prob)
    
    def determine_level(
        self,
        student_score: float,
        cutoff_safe: Optional[float],
        cutoff_normal: Optional[float],
        cutoff_risk: Optional[float]
    ) -> str:
        """í•©ê²© ë¼ì¸ë§Œ íŒì •"""
        result = self.calculate(student_score, cutoff_safe, cutoff_normal, cutoff_risk)
        return result.level


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    model = AdmissionProbabilityModel()
    
    print("=== í™•ë¥  ê³„ì‚° í…ŒìŠ¤íŠ¸ ===\n")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        # (student_score, cutoff_safe, cutoff_normal, cutoff_risk, expected_level)
        (98.0, 95.0, 90.0, 85.0, "ì ì •"),
        (92.0, 95.0, 90.0, 85.0, "ì˜ˆìƒ"),
        (87.0, 95.0, 90.0, 85.0, "ì†Œì‹ "),
        (80.0, 95.0, 90.0, 85.0, "ìƒí–¥"),
        (70.0, None, None, None, "ì•Œìˆ˜ì—†ìŒ"),
    ]
    
    for score, safe, normal, risk, expected in test_cases:
        result = model.calculate(score, safe, normal, risk)
        status = "âœ“" if result.level == expected else "âœ—"
        print(f"{status} score={score}, level={result.level} (expected={expected})")
        print(f"   prob={result.probability:.2%}, CI=[{result.confidence_low:.2%}, {result.confidence_high:.2%}]")
```

### 4.2 í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´
```bash
cd C:\Neoprime
python -m theory_engine.probability.admission_model
```

---

## ğŸ”§ Phase 5: ê²°ê²© ì²´í¬ ì—”ì§„ (45ë¶„)

### 5.1 êµ¬í˜„ íŒŒì¼

**íŒŒì¼**: `theory_engine/disqualification/__init__.py`
```python
from .disqualification_engine import DisqualificationEngine

__all__ = ["DisqualificationEngine"]
```

**íŒŒì¼**: `theory_engine/disqualification/disqualification_engine.py`
```python
"""
ê²°ê²© ì‚¬ìœ  ì²´í¬ ì—”ì§„

RESTRICT ì‹œíŠ¸ ê¸°ë°˜ ê²°ê²© ë£° ì ìš©
"""

import re
import logging
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, field

from ..constants import DisqualificationCode
from ..model import StudentProfile, TargetProgram, DisqualificationInfo

logger = logging.getLogger(__name__)

@dataclass
class DisqualificationRule:
    """ê²°ê²© ì‚¬ìœ  ë£°"""
    rule_id: str
    description: str
    university_pattern: str  # ëŒ€í•™ëª… íŒ¨í„´ (regex)
    check_func: Callable[[Any, Any], bool]  # (profile, target) â†’ bool
    code: DisqualificationCode
    message_template: str
    severity: int = 1  # 1=ê²½ê³ , 2=ì‹¬ê°


class DisqualificationEngine:
    """ê²°ê²© ì‚¬ìœ  ì²´í¬ ì—”ì§„"""
    
    # ê³¼í•™íƒêµ¬ ê³¼ëª© ëª©ë¡
    SCIENCE_SUBJECTS = ["ë¬¼ë¦¬í•™", "í™”í•™", "ìƒëª…ê³¼í•™", "ì§€êµ¬ê³¼í•™"]
    
    # ì‚¬íšŒíƒêµ¬ ê³¼ëª© ëª©ë¡
    SOCIAL_SUBJECTS = ["ìƒí™œê³¼ ìœ¤ë¦¬", "ìœ¤ë¦¬ì™€ ì‚¬ìƒ", "í•œêµ­ì§€ë¦¬", "ì„¸ê³„ì§€ë¦¬", 
                       "ë™ì•„ì‹œì•„ì‚¬", "ì„¸ê³„ì‚¬", "ê²½ì œ", "ì •ì¹˜ì™€ ë²•", "ì‚¬íšŒÂ·ë¬¸í™”"]
    
    def __init__(self):
        """ì—”ì§„ ì´ˆê¸°í™” ë° ë£° ë¡œë“œ"""
        self.rules: List[DisqualificationRule] = []
        self._load_rules()
        logger.info(f"ê²°ê²© ì²´í¬ ì—”ì§„ ì´ˆê¸°í™”: {len(self.rules)}ê°œ ë£°")
    
    def _load_rules(self):
        """ê²°ê²© ë£° ë¡œë“œ"""
        
        # ===== ì˜ì–´ ë“±ê¸‰ ì œí•œ =====
        self.rules.append(DisqualificationRule(
            rule_id="ENG_GRADE_001",
            description="ì˜ì–´ 3ë“±ê¸‰ ì´ˆê³¼ ì œí•œ (ì¼ë°˜)",
            university_pattern=r".*",
            check_func=lambda p, t: p.english_grade > 3,
            code=DisqualificationCode.ENGLISH_GRADE,
            message_template="ì˜ì–´ {grade}ë“±ê¸‰: ëŒ€ë¶€ë¶„ ëŒ€í•™ì€ 3ë“±ê¸‰ ì´ë‚´ í•„ìˆ˜",
            severity=2
        ))
        
        self.rules.append(DisqualificationRule(
            rule_id="ENG_GRADE_002",
            description="ì˜ì–´ 2ë“±ê¸‰ ì´ˆê³¼ ì œí•œ (ìƒìœ„ê¶Œ)",
            university_pattern=r"ì„œìš¸ëŒ€|ì—°ì„¸ëŒ€|ê³ ë ¤ëŒ€|ì„±ê· ê´€|í•œì–‘ëŒ€|ì¤‘ì•™ëŒ€|ê²½í¬ëŒ€|ì´í™”ì—¬ëŒ€",
            check_func=lambda p, t: p.english_grade > 2,
            code=DisqualificationCode.ENGLISH_GRADE,
            message_template="ì˜ì–´ {grade}ë“±ê¸‰: {university}ëŠ” 2ë“±ê¸‰ ì´ë‚´ ê¶Œì¥",
            severity=1
        ))
        
        # ===== í•œêµ­ì‚¬ ë“±ê¸‰ ì œí•œ =====
        self.rules.append(DisqualificationRule(
            rule_id="HIST_GRADE_001",
            description="í•œêµ­ì‚¬ 4ë“±ê¸‰ ì´ˆê³¼ ì œí•œ",
            university_pattern=r".*",
            check_func=lambda p, t: p.history_grade > 4,
            code=DisqualificationCode.HISTORY_GRADE,
            message_template="í•œêµ­ì‚¬ {grade}ë“±ê¸‰: ëŒ€ë¶€ë¶„ ëŒ€í•™ì€ 4ë“±ê¸‰ ì´ë‚´ í•„ìˆ˜",
            severity=2
        ))
        
        # ===== ìˆ˜í•™ ì„ íƒê³¼ëª© ì œí•œ =====
        self.rules.append(DisqualificationRule(
            rule_id="MATH_SUBJ_001",
            description="ì´ê³¼ ë¯¸ì ë¶„/ê¸°í•˜ í•„ìˆ˜",
            university_pattern=r"ì„œìš¸ëŒ€|ì—°ì„¸ëŒ€|ê³ ë ¤ëŒ€|ì„±ê· ê´€|í•œì–‘ëŒ€|KAIST|í¬í•­ê³µëŒ€",
            check_func=lambda p, t: (
                p.track.value == "ì´ê³¼" and 
                p.math.subject not in ["ìˆ˜í•™(ë¯¸ì )", "ìˆ˜í•™(ê¸°í•˜)", "ë¯¸ì ë¶„", "ê¸°í•˜"]
            ),
            code=DisqualificationCode.MATH_SUBJECT,
            message_template="{university} ì´ê³¼: ë¯¸ì ë¶„/ê¸°í•˜ í•„ìˆ˜",
            severity=2
        ))
        
        # ===== íƒêµ¬ê³¼ëª© ì œí•œ (ì˜ëŒ€) =====
        self.rules.append(DisqualificationRule(
            rule_id="INQ_SUBJ_001",
            description="ì˜ëŒ€ ê³¼íƒ 2ê³¼ëª© í•„ìˆ˜",
            university_pattern=r"ì˜ëŒ€|ì˜í•™|ì˜ì˜ˆ|ì¹˜ì˜|í•œì˜|ì•½í•™",
            check_func=lambda p, t: (
                "ì˜" in t.major or "ì•½" in t.major
            ) and (
                not self._is_science(p.inquiry1.subject) or
                not self._is_science(p.inquiry2.subject)
            ),
            code=DisqualificationCode.INQUIRY_SUBJECT,
            message_template="{university} {major}: ê³¼í•™íƒêµ¬ 2ê³¼ëª© í•„ìˆ˜",
            severity=2
        ))
        
        # ===== íƒêµ¬ ì¡°í•© ì œí•œ (ì„œìš¸ëŒ€) =====
        self.rules.append(DisqualificationRule(
            rule_id="INQ_COMBO_001",
            description="ì„œìš¸ëŒ€ ë™ì¼ê³¼ëª©êµ° I+I ë¶ˆê°€",
            university_pattern=r"ì„œìš¸ëŒ€",
            check_func=lambda p, t: (
                self._get_subject_category(p.inquiry1.subject) ==
                self._get_subject_category(p.inquiry2.subject) and
                "â… " in p.inquiry1.subject and "â… " in p.inquiry2.subject
            ),
            code=DisqualificationCode.INQUIRY_COMBINATION,
            message_template="ì„œìš¸ëŒ€: ë™ì¼ ê³¼ëª©êµ° â… +â…  ì¡°í•© ë¶ˆê°€",
            severity=2
        ))
    
    def _is_science(self, subject: str) -> bool:
        """ê³¼í•™íƒêµ¬ ê³¼ëª© ì—¬ë¶€"""
        return any(s in subject for s in self.SCIENCE_SUBJECTS)
    
    def _get_subject_category(self, subject: str) -> str:
        """íƒêµ¬ ê³¼ëª© ì¹´í…Œê³ ë¦¬"""
        for cat in self.SCIENCE_SUBJECTS + self.SOCIAL_SUBJECTS:
            if cat in subject:
                return cat.split()[0]  # "ë¬¼ë¦¬í•™", "í™”í•™" ë“±
        return "ê¸°íƒ€"
    
    def check(
        self,
        profile: StudentProfile,
        target: TargetProgram,
        severity_threshold: int = 1
    ) -> DisqualificationInfo:
        """
        ê²°ê²© ì‚¬ìœ  ì²´í¬
        
        Args:
            profile: í•™ìƒ í”„ë¡œí•„
            target: ì§€ì› ëŒ€í•™/ì „í˜•
            severity_threshold: ì´ ì‹¬ê°ë„ ì´ìƒë§Œ ê²°ê²© ì²˜ë¦¬ (1=ê²½ê³  í¬í•¨, 2=ì‹¬ê°ë§Œ)
        
        Returns:
            DisqualificationInfo
        """
        triggered_rules: List[DisqualificationRule] = []
        
        for rule in self.rules:
            # ëŒ€í•™ íŒ¨í„´ ë§¤ì¹­
            if not re.search(rule.university_pattern, target.university, re.IGNORECASE):
                if not re.search(rule.university_pattern, target.major, re.IGNORECASE):
                    continue
            
            # ì¡°ê±´ ì²´í¬
            try:
                if rule.check_func(profile, target):
                    if rule.severity >= severity_threshold:
                        triggered_rules.append(rule)
                        logger.debug(f"ë£° íŠ¸ë¦¬ê±°: {rule.rule_id} - {rule.description}")
            except Exception as e:
                logger.warning(f"ë£° {rule.rule_id} í‰ê°€ ì‹¤íŒ¨: {e}")
        
        if triggered_rules:
            # ê°€ì¥ ì‹¬ê°í•œ ë£° ì„ íƒ
            triggered_rules.sort(key=lambda r: r.severity, reverse=True)
            primary = triggered_rules[0]
            
            message = primary.message_template.format(
                university=target.university,
                major=target.major,
                grade=profile.english_grade,
            )
            
            return DisqualificationInfo(
                is_disqualified=True,
                reason=message,
                code=primary.code,
                rules_triggered=[r.rule_id for r in triggered_rules]
            )
        
        return DisqualificationInfo(is_disqualified=False)
    
    def get_all_rules(self) -> List[Dict]:
        """ëª¨ë“  ë£° ëª©ë¡"""
        return [
            {
                "rule_id": r.rule_id,
                "description": r.description,
                "severity": r.severity,
                "code": r.code.value,
            }
            for r in self.rules
        ]


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    
    from ..model import ExamScore, StudentProfile, TargetProgram
    from ..constants import Track
    
    print("=== ê²°ê²© ì²´í¬ í…ŒìŠ¤íŠ¸ ===\n")
    
    engine = DisqualificationEngine()
    print(f"ë¡œë“œëœ ë£°: {len(engine.rules)}ê°œ\n")
    
    # í…ŒìŠ¤íŠ¸ í”„ë¡œí•„
    profile = StudentProfile(
        track=Track.SCIENCE,
        korean=ExamScore("êµ­ì–´(ì–¸ë§¤)", raw_total=80),
        math=ExamScore("ìˆ˜í•™(ë¯¸ì )", raw_total=75),
        english_grade=2,
        history_grade=3,
        inquiry1=ExamScore("ë¬¼ë¦¬í•™ â… ", raw_total=50),
        inquiry2=ExamScore("í™”í•™ â… ", raw_total=48),
    )
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    targets = [
        TargetProgram("ì„œìš¸ëŒ€", "ê³µëŒ€"),
        TargetProgram("ì—°ì„¸ëŒ€", "ì˜ì˜ˆ"),
        TargetProgram("ê³ ë ¤ëŒ€", "ê²½ì˜"),
    ]
    
    for target in targets:
        result = engine.check(profile, target)
        status = "âœ— ê²°ê²©" if result.is_disqualified else "âœ“ í†µê³¼"
        print(f"{status}: {target.university} {target.major}")
        if result.is_disqualified:
            print(f"   ì‚¬ìœ : {result.reason}")
            print(f"   ë£°: {result.rules_triggered}")
        print()
```

### 5.2 í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´
```bash
cd C:\Neoprime
python -m theory_engine.disqualification.disqualification_engine
```

---

## ğŸ”§ Phase 6: í†µí•© ë° rules.py ì—…ë°ì´íŠ¸ (30ë¶„)

### 6.1 ëª©í‘œ
- ìƒˆ ëª¨ë“ˆë“¤ì„ rules.pyì— í†µí•©
- compute_theory_result() ì™„ì „ êµ¬í˜„

### 6.2 rules.py ìˆ˜ì • ë‚´ìš©

ê¸°ì¡´ `rules.py`ì˜ `compute_theory_result()` í•¨ìˆ˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

```python
# rules.py ìƒë‹¨ì— import ì¶”ê°€
from .matchers.subject_matcher import SubjectMatcher
from .optimizers.index_optimizer import IndexOptimizer
from .cutoff.cutoff_extractor import CutoffExtractor
from .probability.admission_model import AdmissionProbabilityModel
from .disqualification.disqualification_engine import DisqualificationEngine

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (lazy initialization)
_subject_matcher = None
_probability_model = None
_disqualification_engine = None

def get_subject_matcher():
    global _subject_matcher
    if _subject_matcher is None:
        _subject_matcher = SubjectMatcher()
    return _subject_matcher

def get_probability_model():
    global _probability_model
    if _probability_model is None:
        _probability_model = AdmissionProbabilityModel()
    return _probability_model

def get_disqualification_engine():
    global _disqualification_engine
    if _disqualification_engine is None:
        _disqualification_engine = DisqualificationEngine()
    return _disqualification_engine
```

### 6.3 í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´
```bash
cd C:\Neoprime
python run_theory_engine.py
```

---

## ğŸ§ª Phase 7: E2E í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (30ë¶„)

### 7.1 í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

**íŒŒì¼**: `tests/test_integration.py`
```python
"""
Theory Engine v3 í†µí•© í…ŒìŠ¤íŠ¸

ì‹¤ì œ ì—‘ì…€ íŒŒì¼ ê¸°ë°˜ E2E í…ŒìŠ¤íŠ¸
"""

import logging
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from theory_engine.config import EXCEL_PATH, ENGINE_VERSION
from theory_engine.loader import load_workbook
from theory_engine.model import StudentProfile, ExamScore, TargetProgram
from theory_engine.constants import Track
from theory_engine.rules import compute_theory_result
from theory_engine.matchers import SubjectMatcher
from theory_engine.optimizers import IndexOptimizer
from theory_engine.cutoff import CutoffExtractor
from theory_engine.probability import AdmissionProbabilityModel
from theory_engine.disqualification import DisqualificationEngine

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def test_subject_matcher():
    """ê³¼ëª© ë§¤ì¹­ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("1. ê³¼ëª© ë§¤ì¹­ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    matcher = SubjectMatcher()
    
    test_cases = [
        ("ë¬¼ë¦¬í•™I", "ë¬¼ë¦¬í•™ â… "),
        ("í™”í•™1", "í™”í•™ â… "),
        ("ìƒìœ¤", "ìƒí™œê³¼ ìœ¤ë¦¬"),
        ("ìˆ˜í•™(ë¯¸ì )", "ìˆ˜í•™(ë¯¸ì )"),
        ("êµ­ì–´(ì–¸ë§¤)", "êµ­ì–´(ì–¸ë§¤)"),
    ]
    
    passed = 0
    for input_name, expected in test_cases:
        result, score = matcher.match(input_name)
        status = "PASS" if result == expected else "FAIL"
        if status == "PASS":
            passed += 1
        print(f"  {status}: '{input_name}' â†’ '{result}' (expected: '{expected}', score={score:.1f})")
    
    print(f"\n  ê²°ê³¼: {passed}/{len(test_cases)} í†µê³¼")
    return passed == len(test_cases)


def test_index_optimizer():
    """INDEX ìµœì í™” í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("2. INDEX ìµœì í™” í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    data = load_workbook(EXCEL_PATH)
    if "INDEX" not in data:
        print("  SKIP: INDEX ì‹œíŠ¸ ì—†ìŒ")
        return True
    
    optimizer = IndexOptimizer(data["INDEX"])
    stats = optimizer.get_stats()
    print(f"  ì´ í–‰: {stats['total_rows']}")
    print(f"  ì¸ë±ì‹±: {stats['indexed_rows']}")
    print(f"  MultiIndex: {stats['use_multiindex']}")
    
    # ì¡°íšŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    start = time.time()
    for _ in range(100):
        optimizer.lookup(130, 135, 65, 62, "ì´ê³¼")
    elapsed = (time.time() - start) * 10  # ms per lookup
    
    print(f"  ì¡°íšŒ ì‹œê°„: {elapsed:.2f}ms (100íšŒ í‰ê· )")
    
    return elapsed < 100  # 100ms ì´í•˜ë©´ ì„±ê³µ


def test_cutoff_extractor():
    """ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("3. ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    data = load_workbook(EXCEL_PATH)
    if "PERCENTAGE" not in data:
        print("  SKIP: PERCENTAGE ì‹œíŠ¸ ì—†ìŒ")
        return True
    
    extractor = CutoffExtractor(data["PERCENTAGE"])
    stats = extractor.get_stats()
    print(f"  ëŒ€í•™/ì „ê³µ: {stats['total_programs']}ê°œ")
    
    # ìƒ˜í”Œ ì¶”ì¶œ
    programs = extractor.list_available_programs()[:5]
    print(f"  ìƒ˜í”Œ í”„ë¡œê·¸ë¨: {programs}")
    
    # ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    test_found = 0
    for prog in programs:
        # ëŒ€í•™ëª… ì¶”ì¶œ ì‹œë„
        result = extractor.extract_cutoffs(prog[:2], prog[2:4])
        if result['found']:
            test_found += 1
            print(f"  âœ“ {prog}: ì ì •={result['cutoff_safe']}, ì˜ˆìƒ={result['cutoff_normal']}")
    
    return test_found > 0


def test_probability_model():
    """í™•ë¥  ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("4. í™•ë¥  ê³„ì‚° í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    model = AdmissionProbabilityModel()
    
    test_cases = [
        (98.0, 95.0, 90.0, 85.0, "ì ì •"),
        (92.0, 95.0, 90.0, 85.0, "ì˜ˆìƒ"),
        (87.0, 95.0, 90.0, 85.0, "ì†Œì‹ "),
        (80.0, 95.0, 90.0, 85.0, "ìƒí–¥"),
    ]
    
    passed = 0
    for score, safe, normal, risk, expected_level in test_cases:
        result = model.calculate(score, safe, normal, risk)
        status = "PASS" if result.level == expected_level else "FAIL"
        if status == "PASS":
            passed += 1
        print(f"  {status}: score={score} â†’ {result.level} (expected={expected_level}), prob={result.probability:.2%}")
    
    print(f"\n  ê²°ê³¼: {passed}/{len(test_cases)} í†µê³¼")
    return passed == len(test_cases)


def test_disqualification_engine():
    """ê²°ê²© ì²´í¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("5. ê²°ê²© ì²´í¬ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    engine = DisqualificationEngine()
    print(f"  ë¡œë“œëœ ë£°: {len(engine.rules)}ê°œ")
    
    # ì •ìƒ í”„ë¡œí•„
    normal_profile = StudentProfile(
        track=Track.SCIENCE,
        korean=ExamScore("êµ­ì–´(ì–¸ë§¤)", raw_total=80),
        math=ExamScore("ìˆ˜í•™(ë¯¸ì )", raw_total=75),
        english_grade=2,
        history_grade=3,
        inquiry1=ExamScore("ë¬¼ë¦¬í•™ â… ", raw_total=50),
        inquiry2=ExamScore("í™”í•™ â… ", raw_total=48),
    )
    
    # ê²°ê²© í”„ë¡œí•„ (ì˜ì–´ 4ë“±ê¸‰)
    disqualified_profile = StudentProfile(
        track=Track.SCIENCE,
        korean=ExamScore("êµ­ì–´(ì–¸ë§¤)", raw_total=80),
        math=ExamScore("ìˆ˜í•™(ë¯¸ì )", raw_total=75),
        english_grade=4,  # ê²°ê²©!
        history_grade=3,
        inquiry1=ExamScore("ë¬¼ë¦¬í•™ â… ", raw_total=50),
        inquiry2=ExamScore("í™”í•™ â… ", raw_total=48),
    )
    
    target = TargetProgram("ì„œìš¸ëŒ€", "ê³µëŒ€")
    
    # ì •ìƒ ì²´í¬
    result1 = engine.check(normal_profile, target, severity_threshold=2)
    status1 = "PASS" if not result1.is_disqualified else "FAIL"
    print(f"  {status1}: ì •ìƒ í”„ë¡œí•„ â†’ {'ê²°ê²©' if result1.is_disqualified else 'í†µê³¼'}")
    
    # ê²°ê²© ì²´í¬
    result2 = engine.check(disqualified_profile, target, severity_threshold=2)
    status2 = "PASS" if result2.is_disqualified else "FAIL"
    print(f"  {status2}: ê²°ê²© í”„ë¡œí•„ â†’ {'ê²°ê²©' if result2.is_disqualified else 'í†µê³¼'}")
    if result2.is_disqualified:
        print(f"       ì‚¬ìœ : {result2.reason}")
    
    return status1 == "PASS" and status2 == "PASS"


def test_e2e_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ E2E í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("6. E2E íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ì—‘ì…€ ë¡œë“œ
    print(f"  ì—‘ì…€ ë¡œë“œ: {EXCEL_PATH}")
    data = load_workbook(EXCEL_PATH)
    print(f"  ë¡œë“œëœ ì‹œíŠ¸: {len(data)}ê°œ")
    
    # í…ŒìŠ¤íŠ¸ í”„ë¡œí•„
    profile = StudentProfile(
        track=Track.SCIENCE,
        korean=ExamScore("êµ­ì–´(ì–¸ë§¤)", raw_total=80, raw_common=55, raw_select=25),
        math=ExamScore("ìˆ˜í•™(ë¯¸ì )", raw_total=75, raw_common=50, raw_select=25),
        english_grade=2,
        history_grade=3,
        inquiry1=ExamScore("ë¬¼ë¦¬í•™ â… ", raw_total=50),
        inquiry2=ExamScore("í™”í•™ â… ", raw_total=48),
        targets=[
            TargetProgram("ê°€ì²œ", "ì˜í•™"),
            TargetProgram("ê±´êµ­", "ìì—°"),
            TargetProgram("ì„œìš¸ëŒ€", "ê³µëŒ€"),
        ]
    )
    
    print(f"\n  í•™ìƒ í”„ë¡œí•„:")
    print(f"    ê³„ì—´: {profile.track.value}")
    print(f"    êµ­ì–´: {profile.korean.raw_total}ì ")
    print(f"    ìˆ˜í•™: {profile.math.raw_total}ì ")
    print(f"    ì˜ì–´: {profile.english_grade}ë“±ê¸‰")
    print(f"    ëª©í‘œ: {len(profile.targets)}ê°œ ëŒ€í•™")
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    print(f"\n  ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘...")
    start = time.time()
    result = compute_theory_result(data, profile, debug=True)
    elapsed = time.time() - start
    
    print(f"  ì‹¤í–‰ ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"  ì—”ì§„ ë²„ì „: {result.engine_version}")
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n  ê²°ê³¼:")
    for prog in result.program_results:
        print(f"    {prog.target.university} {prog.target.major}:")
        print(f"      ë¼ì¸: {prog.level_theory.value}")
        print(f"      í™•ë¥ : {prog.p_theory}")
        print(f"      ì ìˆ˜: {prog.score_theory}")
        if prog.disqualification.is_disqualified:
            print(f"      ê²°ê²©: {prog.disqualification.reason}")
    
    # ì¤‘ê°„ ê²°ê³¼
    print(f"\n  ì¤‘ê°„ ê³„ì‚° ê²°ê³¼:")
    for key, value in list(result.raw_components.items())[:5]:
        print(f"    {key}: {value}")
    
    return len(result.program_results) > 0


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("="*60)
    print(f"Theory Engine v{ENGINE_VERSION} í†µí•© í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    results = {
        "ê³¼ëª© ë§¤ì¹­": test_subject_matcher(),
        "INDEX ìµœì í™”": test_index_optimizer(),
        "ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ": test_cutoff_extractor(),
        "í™•ë¥  ê³„ì‚°": test_probability_model(),
        "ê²°ê²© ì²´í¬": test_disqualification_engine(),
        "E2E íŒŒì´í”„ë¼ì¸": test_e2e_pipeline(),
    }
    
    # ìš”ì•½
    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for name, result in results.items():
        status = "PASS" if result else "FAIL"
        print(f"  {status}: {name}")
    
    print(f"\nì´ {passed}/{total} í†µê³¼")
    
    if passed == total:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return 0
    else:
        print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

### 7.2 í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
cd C:\Neoprime
python tests/test_integration.py
```

---

## ğŸ“Š Phase 8: ê²€ì¦ ë° ë¦¬íŒ©í† ë§ (ì§€ì†)

### 8.1 ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ í›„ ë‹¤ìŒ í•­ëª© í™•ì¸:

- [ ] ê³¼ëª© ë§¤ì¹­ 95% ì´ìƒ
- [ ] INDEX ì¡°íšŒ 100ms ì´í•˜
- [ ] ì»¤íŠ¸ë¼ì¸ ì •ìƒ ì¶”ì¶œ
- [ ] í™•ë¥  ê³„ì‚° ë²”ìœ„ ì •ìƒ (0-1)
- [ ] ê²°ê²© ì²´í¬ ì‘ë™
- [ ] E2E íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ì •
- [ ] ì—ëŸ¬ ë¡œê¹… ì •ìƒ

### 8.2 ë””ë²„ê¹… ëª…ë ¹ì–´

```bash
# ìƒì„¸ ë¡œê·¸ ì¶œë ¥
python -c "
import logging
logging.basicConfig(level=logging.DEBUG)
from theory_engine.loader import load_workbook
from theory_engine.config import EXCEL_PATH
data = load_workbook(EXCEL_PATH)
print('ë¡œë“œ ì™„ë£Œ:', list(data.keys()))
"

# íŠ¹ì • ì‹œíŠ¸ êµ¬ì¡° í™•ì¸
python -c "
import pandas as pd
df = pd.read_excel('202511ê³ ì†ì„±ì¥ë¶„ì„ê¸°(ê°€ì±„ì )20251114 (1).xlsx', sheet_name='INDEX', nrows=5)
print(df.columns.tolist())
print(df.head())
"

# ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
python -c "
import tracemalloc
tracemalloc.start()
from theory_engine.loader import load_workbook
data = load_workbook()
current, peak = tracemalloc.get_traced_memory()
print(f'í˜„ì¬ ë©”ëª¨ë¦¬: {current / 10**6:.1f}MB')
print(f'ìµœëŒ€ ë©”ëª¨ë¦¬: {peak / 10**6:.1f}MB')
tracemalloc.stop()
"
```

### 8.3 ë¦¬íŒ©í† ë§ ì§€ì¹¨

í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ:

1. **ê³¼ëª© ë§¤ì¹­ ì‹¤íŒ¨**
   - `CANONICAL_SUBJECTS`ì— ëˆ„ë½ëœ ê³¼ëª© ì¶”ê°€
   - ì •ê·œí™” ë¡œì§ ì¡°ì •

2. **INDEX ì¡°íšŒ ëŠë¦¼**
   - MultiIndex ì»¬ëŸ¼ í™•ì¸
   - ìºì‹± íš¨ê³¼ ì ê²€

3. **ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ ì‹¤íŒ¨**
   - ì»¬ëŸ¼ëª… íŒ¨í„´ í™•ì¸
   - ëˆ„ë°± ë²”ìœ„ í™•ì¸

4. **í™•ë¥  ê³„ì‚° ì´ìƒ**
   - ì»¤íŠ¸ë¼ì¸ ê°’ í™•ì¸
   - ë³´ê°„ ë¡œì§ ì ê²€

5. **ê²°ê²© ì²´í¬ ì˜¤ì‘ë™**
   - ë£° ì¡°ê±´ í™•ì¸
   - ëŒ€í•™ íŒ¨í„´ ì ê²€

---

## ğŸ“ ì™„ë£Œ ê¸°ì¤€

### í•„ìˆ˜ ë‹¬ì„± í•­ëª©
- [ ] 5ê°œ ëª¨ë“ˆ ëª¨ë‘ êµ¬í˜„ ì™„ë£Œ
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ 6/6 í†µê³¼
- [ ] ì‹¤ì œ ì—‘ì…€ íŒŒì¼ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ
- [ ] ì—ëŸ¬ ì—†ì´ run_theory_engine.py ì‹¤í–‰

### í’ˆì§ˆ ì§€í‘œ
| í•­ëª© | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|----------|
| ê³¼ëª© ë§¤ì¹­ | 95%+ | test_subject_matcher |
| INDEX ì¡°íšŒ | <100ms | test_index_optimizer |
| ì»¤íŠ¸ë¼ì¸ | 80%+ ì¶”ì¶œ | test_cutoff_extractor |
| í™•ë¥  ì •í™•ë„ | 90%+ | test_probability_model |
| ê²°ê²© ì •í™•ë„ | 95%+ | test_disqualification_engine |
| E2E ì„±ê³µ | 100% | test_e2e_pipeline |

---

## ğŸ”„ ì‘ì—… ìˆœì„œ ìš”ì•½

```
1. matchers/subject_matcher.py ìƒì„± â†’ í…ŒìŠ¤íŠ¸ âœ“
2. optimizers/index_optimizer.py ìƒì„± â†’ í…ŒìŠ¤íŠ¸ âœ“
3. cutoff/cutoff_extractor.py ìƒì„± â†’ í…ŒìŠ¤íŠ¸ âœ“
4. probability/admission_model.py ìƒì„± â†’ í…ŒìŠ¤íŠ¸ âœ“
5. disqualification/disqualification_engine.py ìƒì„± â†’ í…ŒìŠ¤íŠ¸ âœ“
6. rules.py í†µí•© ìˆ˜ì • â†’ í…ŒìŠ¤íŠ¸ âœ“
7. tests/test_integration.py ìƒì„± â†’ ì „ì²´ í…ŒìŠ¤íŠ¸ âœ“
8. run_theory_engine.py ìµœì¢… ê²€ì¦ âœ“
9. ë””ë²„ê¹…/ë¦¬íŒ©í† ë§ (í•„ìš”ì‹œ ë°˜ë³µ)
```

---

**ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì—ì´ì „íŠ¸ì—ê²Œ ì£¼ì…í•˜ê³  ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.**
