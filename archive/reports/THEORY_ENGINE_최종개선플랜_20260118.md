# Theory Engine v3.0 ìµœì¢… ê°œì„  í”Œëœ

**ì‘ì„±ì¼**: 2026-01-18  
**ê¸°ë°˜ ë¬¸ì„œ**: í”„ë¡œì íŠ¸_ì¢…í•©ì ê²€_ìµœì¢…ë³´ê³ ì„œ_v2_20260118.md  
**ëª©í‘œ**: ì‹¤ì œ ì‘ë™ë¥  58% â†’ 95%+ ë‹¬ì„±  
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 6ì‹œê°„ (P0 ì¦‰ì‹œ ì¡°ì¹˜)

---

## ğŸ“‹ Executive Summary

ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼, **ì½”ë“œ ì™„ì„±ë„ 100% vs ì‹¤ì œ ì‘ë™ë¥  58% (42% ê°­)** ë¬¸ì œê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ë³¸ ë¬¸ì„œëŠ” **3ê°œ Critical ì´ìŠˆ**ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•˜ë©°, **GitHub/HuggingFace ì˜ˆì œ ì½”ë“œ**ì™€ **ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ê°€ì´ë“œ**ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

### í•µì‹¬ ì´ìŠˆ ë° í•´ê²° ì „ëµ

| # | ì´ìŠˆ | í˜„ì¬ | ëª©í‘œ | í•´ê²° ì „ëµ | ì†Œìš” |
|---|------|------|------|----------|------|
| 1 | RAWSCORE íƒêµ¬ê³¼ëª© ì¡°íšŒ ì‹¤íŒ¨ | 40% | 90%+ | Fuzzy ë¬¸ìì—´ ë§¤ì¹­ + ë‹¤ë‹¨ê³„ ê²€ìƒ‰ | 2ì‹œê°„ |
| 2 | INDEX ì¡°íšŒ ì „ì²´ ì‹¤íŒ¨ | 0% | 95%+ | RAWSCORE ëˆ„ì % ìš°íšŒ + ì¸ì½”ë”© ì—­ê³µí•™ | 1ì‹œê°„ |
| 3 | ëŒ€í•™ ì»¤íŠ¸ë¼ì¸ ë¯¸ë°œê²¬ | 67% | 95%+ | Alias ì‹œìŠ¤í…œ + í¼ì§€ ë§¤ì¹­ | 3ì‹œê°„ |

---

## ğŸ”´ Issue #1: RAWSCORE íƒêµ¬ê³¼ëª© ì¡°íšŒ ì‹¤íŒ¨

### ë¬¸ì œ ìƒì„¸

**í˜„ìƒ**:
```
[âœ… OK] êµ­ì–´ 80ì  â†’ í‘œì¤€: 125.0, ë°±ë¶„ìœ„: 89.0
[âœ… OK] ìˆ˜í•™ 75ì  â†’ í‘œì¤€: 121.0, ë°±ë¶„ìœ„: 82.0
[âŒ FAIL] ë¬¼ë¦¬í•™ â…  45ì  â†’ í‘œì¤€: None, ë°±ë¶„ìœ„: None
[âŒ FAIL] í™”í•™ â…  42ì  â†’ í‘œì¤€: None, ë°±ë¶„ìœ„: None
```

**ì›ì¸**:
- í˜„ì¬ ì½”ë“œ: `ì˜ì—­` ì»¬ëŸ¼ë§Œ ê²€ìƒ‰
- ì‹¤ì œ ì—‘ì…€: íƒêµ¬ê³¼ëª©ì€ `ê³¼ëª©ëª…` ì»¬ëŸ¼ ì‚¬ìš©
- ì´ë¦„ ë¶ˆì¼ì¹˜: "ë¬¼ë¦¬í•™I" vs "ë¬¼ë¦¬í•™ â… " (ë¡œë§ˆìˆ«ì)

### í•´ê²° ì „ëµ: Multi-Stage Fuzzy Matching

#### ì°¸ê³  ë¼ì´ë¸ŒëŸ¬ë¦¬

**rapidfuzz** (GitHub: 17.8k stars)
- URL: https://github.com/rapidfuzz/rapidfuzz
- ì¥ì : fuzzywuzzyë³´ë‹¤ 10-100ë°° ë¹ ë¦„, MIT ë¼ì´ì„ ìŠ¤

**thefuzz** (GitHub: 12.5k stars)
- URL: https://github.com/seatgeek/thefuzz
- ì¥ì : ê²€ì¦ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬, ë‹¤ì–‘í•œ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜

#### êµ¬í˜„ ì½”ë“œ

```python
# theory_engine/matchers/subject_matcher_v2.py

from rapidfuzz import fuzz, process
from typing import Optional, Tuple, Dict, List
import re
import unicodedata

class SubjectMatcherV2:
    """íƒêµ¬ê³¼ëª© Fuzzy ë§¤ì¹­ v2.0"""
    
    # ë¡œë§ˆìˆ«ì â†” ì˜ë¬¸ I ë§¤í•‘
    ROMAN_NUMERAL_MAP = {
        'â… ': 'I', 'â…¡': 'II', 'â…¢': 'III', 'â…£': 'IV', 'â…¤': 'V',
        'I': 'â… ', 'II': 'â…¡', 'III': 'â…¢', 'IV': 'â…£', 'V': 'â…¤',
    }
    
    # ê³¼ëª© ì•½ì–´ í™•ì¥
    SUBJECT_ALIASES = {
        "ë¬¼ë¦¬": ["ë¬¼ë¦¬í•™", "ë¬¼ë¦¬í•™â… ", "ë¬¼ë¦¬í•™â…¡", "ë¬¼ë¦¬ â… ", "ë¬¼ë¦¬ â…¡"],
        "í™”í•™": ["í™”í•™", "í™”í•™â… ", "í™”í•™â…¡", "í™”í•™ â… ", "í™”í•™ â…¡"],
        "ìƒëª…": ["ìƒëª…ê³¼í•™", "ìƒëª…ê³¼í•™â… ", "ìƒëª…ê³¼í•™â…¡", "ìƒëª… â… "],
        "ì§€êµ¬": ["ì§€êµ¬ê³¼í•™", "ì§€êµ¬ê³¼í•™â… ", "ì§€êµ¬ê³¼í•™â…¡"],
        "ìƒìœ¤": ["ìƒí™œê³¼ ìœ¤ë¦¬", "ìƒí™œê³¼ìœ¤ë¦¬"],
        "ì‚¬ë¬¸": ["ì‚¬íšŒÂ·ë¬¸í™”", "ì‚¬íšŒë¬¸í™”", "ì‚¬íšŒÂ·ë¬¸í™”"],
        "ìœ¤ì‚¬": ["ìœ¤ë¦¬ì™€ ì‚¬ìƒ", "ìœ¤ë¦¬ì™€ì‚¬ìƒ"],
        "í•œì§€": ["í•œêµ­ì§€ë¦¬"],
        "ì„¸ì§€": ["ì„¸ê³„ì§€ë¦¬"],
        "ë™ì•„": ["ë™ì•„ì‹œì•„ì‚¬", "ë™ì•„ì‹œì•„ ì—­ì‚¬"],
        "ì„¸ì‚¬": ["ì„¸ê³„ì‚¬"],
        "ê²½ì œ": ["ê²½ì œ"],
        "ì •ë²•": ["ì •ì¹˜ì™€ ë²•", "ì •ì¹˜ì™€ë²•"],
    }
    
    def normalize_subject(self, subject: str) -> str:
        """ê³¼ëª©ëª… ì •ê·œí™”"""
        if not subject:
            return ""
        
        # 1. Unicode ì •ê·œí™” (NFKC)
        normalized = unicodedata.normalize('NFKC', subject)
        
        # 2. ê³µë°± ì œê±°
        normalized = normalized.replace(" ", "")
        
        # 3. ë¡œë§ˆìˆ«ì í†µì¼ (ëª¨ë‘ ì˜ë¬¸ Ië¡œ)
        for roman, eng in self.ROMAN_NUMERAL_MAP.items():
            if len(roman) == 1 and roman in 'â… â…¡â…¢â…£â…¤':  # ë¡œë§ˆìˆ«ìë§Œ
                normalized = normalized.replace(roman, eng)
        
        return normalized.lower()
    
    def fuzzy_match(
        self, 
        query: str, 
        candidates: List[str], 
        threshold: int = 80
    ) -> Optional[Tuple[str, int]]:
        """
        Fuzzy ë¬¸ìì—´ ë§¤ì¹­
        
        Args:
            query: ê²€ìƒ‰í•  ê³¼ëª©ëª…
            candidates: í›„ë³´ ê³¼ëª©ëª… ë¦¬ìŠ¤íŠ¸
            threshold: ìµœì†Œ ë§¤ì¹­ ì ìˆ˜ (0-100)
            
        Returns:
            (ë§¤ì¹­ëœ ê³¼ëª©ëª…, ì ìˆ˜) ë˜ëŠ” None
        """
        if not candidates:
            return None
        
        # rapidfuzzì˜ process.extractOne ì‚¬ìš©
        result = process.extractOne(
            query=self.normalize_subject(query),
            choices=[self.normalize_subject(c) for c in candidates],
            scorer=fuzz.WRatio,  # ê°€ì¤‘ì¹˜ ì ìš© ë¹„ìœ¨ ë§¤ì¹­
            score_cutoff=threshold
        )
        
        if result:
            matched_normalized, score, idx = result
            return (candidates[idx], score)
        
        return None
    
    def find_subject_in_rawscore(
        self, 
        df, 
        subject: str, 
        raw_score: int
    ) -> Optional[Dict]:
        """
        RAWSCORE DataFrameì—ì„œ ê³¼ëª© ì¡°íšŒ (ë‹¤ë‹¨ê³„)
        
        Stage 1: ì˜ì—­ ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­
        Stage 2: ê³¼ëª©ëª… ì»¬ëŸ¼ Fuzzy ë§¤ì¹­
        Stage 3: íƒêµ¬ ì˜ì—­ + ê³¼ëª©ëª… ë¶€ë¶„ ë§¤ì¹­
        Stage 4: Alias í™•ì¥ ë§¤ì¹­
        """
        import pandas as pd
        
        # Stage 1: ì˜ì—­ ì§ì ‘ ë§¤ì¹­
        mask = df["ì˜ì—­"] == subject
        filtered = df[mask]
        if not filtered.empty:
            return self._extract_score_data(filtered, raw_score, "direct_ì˜ì—­")
        
        # Stage 2: ê³¼ëª©ëª… Fuzzy ë§¤ì¹­
        if "ê³¼ëª©ëª…" in df.columns:
            subject_col = df["ê³¼ëª©ëª…"].dropna().unique().tolist()
            match_result = self.fuzzy_match(subject, subject_col)
            if match_result:
                matched_subject, score = match_result
                mask = df["ê³¼ëª©ëª…"] == matched_subject
                filtered = df[mask]
                if not filtered.empty:
                    return self._extract_score_data(
                        filtered, raw_score, f"fuzzy_ê³¼ëª©ëª…(score={score})"
                    )
        
        # Stage 3: íƒêµ¬ ì˜ì—­ + ê³¼ëª©ëª… ë¶€ë¶„ ë§¤ì¹­
        if "ì˜ì—­" in df.columns and "ê³¼ëª©ëª…" in df.columns:
            # íƒêµ¬ ì˜ì—­ë§Œ í•„í„°
            íƒêµ¬_df = df[df["ì˜ì—­"] == "íƒêµ¬"]
            if not íƒêµ¬_df.empty:
                subject_col = íƒêµ¬_df["ê³¼ëª©ëª…"].dropna().unique().tolist()
                match_result = self.fuzzy_match(subject, subject_col, threshold=70)
                if match_result:
                    matched_subject, score = match_result
                    mask = íƒêµ¬_df["ê³¼ëª©ëª…"] == matched_subject
                    filtered = íƒêµ¬_df[mask]
                    if not filtered.empty:
                        return self._extract_score_data(
                            filtered, raw_score, f"íƒêµ¬+fuzzy(score={score})"
                        )
        
        # Stage 4: Alias í™•ì¥ ë§¤ì¹­
        for alias_key, alias_values in self.SUBJECT_ALIASES.items():
            if alias_key in subject.lower() or subject in alias_values:
                for alias in alias_values:
                    result = self.find_subject_in_rawscore_simple(df, alias, raw_score)
                    if result and result.get("found"):
                        result["match_type"] = f"alias({alias_key}â†’{alias})"
                        return result
        
        return {"found": False, "subject": subject, "raw_score": raw_score}
    
    def find_subject_in_rawscore_simple(self, df, subject, raw_score):
        """ë‹¨ìˆœ ë§¤ì¹­ (ë‚´ë¶€ìš©)"""
        mask = (df["ê³¼ëª©ëª…"] == subject) if "ê³¼ëª©ëª…" in df.columns else (df["ì˜ì—­"] == subject)
        filtered = df[mask]
        if not filtered.empty:
            return self._extract_score_data(filtered, raw_score, "simple")
        return None
    
    def _extract_score_data(self, df, raw_score, match_type):
        """ì ìˆ˜ ë°ì´í„° ì¶”ì¶œ"""
        # ì›ì ìˆ˜ë¡œ í•„í„°
        score_mask = df["ì›ì ìˆ˜"] == raw_score
        row = df[score_mask]
        
        if row.empty:
            # ê°€ì¥ ê°€ê¹Œìš´ ì ìˆ˜ ì°¾ê¸°
            df_copy = df.copy()
            df_copy["diff"] = abs(df_copy["ì›ì ìˆ˜"] - raw_score)
            row = df_copy.nsmallest(1, "diff")
        
        if not row.empty:
            return {
                "found": True,
                "match_type": match_type,
                "subject": row.iloc[0].get("ê³¼ëª©ëª…", row.iloc[0].get("ì˜ì—­")),
                "raw_score": raw_score,
                "standard_score": row.iloc[0].get("202511(ê°€ì±„ì )") or row.iloc[0].iloc[6],
                "percentile": row.iloc[0].get("Unnamed: 7") or row.iloc[0].iloc[7],
                "grade": row.iloc[0].get("Unnamed: 8") or row.iloc[0].iloc[8],
                "cumulative_pct": row.iloc[0].get("Unnamed: 9") or row.iloc[0].iloc[9],
            }
        
        return {"found": False}


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    matcher = SubjectMatcherV2()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        "ë¬¼ë¦¬í•™I",      # â†’ "ë¬¼ë¦¬í•™ â… "
        "í™”í•™II",       # â†’ "í™”í•™ â…¡"
        "ìƒìœ¤",         # â†’ "ìƒí™œê³¼ ìœ¤ë¦¬"
        "ì‚¬ë¬¸",         # â†’ "ì‚¬íšŒÂ·ë¬¸í™”"
        "ì§€êµ¬ê³¼í•™1",    # â†’ "ì§€êµ¬ê³¼í•™ â… "
    ]
    
    for case in test_cases:
        normalized = matcher.normalize_subject(case)
        print(f"'{case}' â†’ '{normalized}'")
```

#### í…ŒìŠ¤íŠ¸ ì½”ë“œ

```python
# tests/test_subject_matcher_v2.py

import pytest
from theory_engine.matchers.subject_matcher_v2 import SubjectMatcherV2

@pytest.fixture
def matcher():
    return SubjectMatcherV2()

class TestSubjectMatcherV2:
    """SubjectMatcherV2 í…ŒìŠ¤íŠ¸"""
    
    def test_normalize_roman_numerals(self, matcher):
        """ë¡œë§ˆìˆ«ì ì •ê·œí™” í…ŒìŠ¤íŠ¸"""
        assert matcher.normalize_subject("ë¬¼ë¦¬í•™â… ") == matcher.normalize_subject("ë¬¼ë¦¬í•™I")
        assert matcher.normalize_subject("í™”í•™ â…¡") == matcher.normalize_subject("í™”í•™II")
    
    def test_fuzzy_match_high_similarity(self, matcher):
        """ë†’ì€ ìœ ì‚¬ë„ ë§¤ì¹­ í…ŒìŠ¤íŠ¸"""
        candidates = ["ë¬¼ë¦¬í•™ â… ", "í™”í•™ â… ", "ìƒëª…ê³¼í•™ â… ", "ì§€êµ¬ê³¼í•™ â… "]
        
        result = matcher.fuzzy_match("ë¬¼ë¦¬í•™I", candidates)
        assert result is not None
        assert "ë¬¼ë¦¬í•™" in result[0]
        assert result[1] >= 80
    
    def test_alias_expansion(self, matcher):
        """ì•½ì–´ í™•ì¥ í…ŒìŠ¤íŠ¸"""
        assert "ìƒìœ¤" in str(matcher.SUBJECT_ALIASES.keys())
        assert "ìƒí™œê³¼ ìœ¤ë¦¬" in matcher.SUBJECT_ALIASES["ìƒìœ¤"]
    
    def test_normalize_whitespace(self, matcher):
        """ê³µë°± ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        assert matcher.normalize_subject("ë¬¼ë¦¬í•™ â… ") == matcher.normalize_subject("ë¬¼ë¦¬í•™â… ")
```

---

## ğŸ”´ Issue #2: INDEX ì¡°íšŒ ì „ì²´ ì‹¤íŒ¨

### ë¬¸ì œ ìƒì„¸

**í˜„ìƒ**:
```
[INDEX ì¡°íšŒ ê²°ê³¼]
  found: False
  match_type: None
  cumulative_pct: None
```

**ì›ì¸**:
- INDEX ì‹œíŠ¸ ì²« ì»¬ëŸ¼: ì¸ì½”ë”©ëœ í‚¤ (ì˜ˆ: "510gs0t20509")
- í˜„ì¬ ì½”ë“œ: í‘œì¤€ì ìˆ˜ ì§ì ‘ ë§¤ì¹­ ì‹œë„ â†’ ì‹¤íŒ¨

### í•´ê²° ì „ëµ A: RAWSCORE ëˆ„ì % ìš°íšŒ (1ì‹œê°„)

#### êµ¬í˜„ ì½”ë“œ

```python
# theory_engine/optimizers/index_fallback.py

import logging
from typing import Dict, Optional, List
import pandas as pd

logger = logging.getLogger(__name__)

class IndexFallbackCalculator:
    """
    INDEX ì¡°íšŒ ì‹¤íŒ¨ ì‹œ RAWSCORE ëˆ„ì % í•©ì‚°ìœ¼ë¡œ ëŒ€ì²´
    
    ì°¸ê³ : 
    - ì´ ë°©ì‹ì€ INDEX ì‹œíŠ¸ì˜ ì •í™•í•œ ì¡°í•© ì¡°íšŒë¥¼ ëŒ€ì²´
    - ê°œë³„ ê³¼ëª©ì˜ ëˆ„ì ë°±ë¶„ìœ„ë¥¼ í•©ì‚°í•˜ì—¬ ì¢…í•© ë°±ë¶„ìœ„ ì¶”ì •
    """
    
    def __init__(self):
        self.weights = {
            "korean": 0.30,    # êµ­ì–´ 30%
            "math": 0.30,      # ìˆ˜í•™ 30%
            "inquiry1": 0.20,  # íƒêµ¬1 20%
            "inquiry2": 0.20,  # íƒêµ¬2 20%
        }
    
    def calculate_cumulative_pct_fallback(
        self,
        korean_conv: Dict,
        math_conv: Dict,
        inquiry1_conv: Dict,
        inquiry2_conv: Dict,
        method: str = "weighted_average"
    ) -> Optional[float]:
        """
        RAWSCORE ëˆ„ì % í•©ì‚°ìœ¼ë¡œ cumulative_pct ê³„ì‚°
        
        Args:
            korean_conv: êµ­ì–´ ë³€í™˜ ê²°ê³¼ {"found": True, "cumulative_pct": 0.15, ...}
            math_conv: ìˆ˜í•™ ë³€í™˜ ê²°ê³¼
            inquiry1_conv: íƒêµ¬1 ë³€í™˜ ê²°ê³¼
            inquiry2_conv: íƒêµ¬2 ë³€í™˜ ê²°ê³¼
            method: "simple_average" | "weighted_average" | "geometric_mean"
            
        Returns:
            ì¢…í•© ëˆ„ì ë°±ë¶„ìœ„ (0.0 ~ 100.0)
        """
        conversions = {
            "korean": korean_conv,
            "math": math_conv,
            "inquiry1": inquiry1_conv,
            "inquiry2": inquiry2_conv,
        }
        
        # ìœ íš¨í•œ ëˆ„ì % ì¶”ì¶œ
        valid_pcts = {}
        for key, conv in conversions.items():
            if conv and conv.get("found"):
                pct = conv.get("cumulative_pct")
                if pct is not None and pct > 0:
                    valid_pcts[key] = float(pct)
        
        if not valid_pcts:
            logger.warning("ìœ íš¨í•œ ëˆ„ì ë°±ë¶„ìœ„ ë°ì´í„° ì—†ìŒ")
            return None
        
        logger.info(f"ìœ íš¨í•œ ëˆ„ì %: {valid_pcts}")
        
        if method == "simple_average":
            return sum(valid_pcts.values()) / len(valid_pcts)
        
        elif method == "weighted_average":
            total_weight = sum(self.weights[k] for k in valid_pcts.keys())
            weighted_sum = sum(
                valid_pcts[k] * self.weights[k] 
                for k in valid_pcts.keys()
            )
            return weighted_sum / total_weight if total_weight > 0 else None
        
        elif method == "geometric_mean":
            import math
            product = 1.0
            for pct in valid_pcts.values():
                product *= (pct / 100.0)  # 0-1 ë²”ìœ„ë¡œ ë³€í™˜
            return (product ** (1 / len(valid_pcts))) * 100  # ë‹¤ì‹œ 0-100ìœ¼ë¡œ
        
        return None
    
    def estimate_national_rank(
        self,
        cumulative_pct: float,
        total_students: int = 500000
    ) -> int:
        """
        ëˆ„ì ë°±ë¶„ìœ„ë¡œ ì „êµ­ ë“±ìˆ˜ ì¶”ì •
        
        Args:
            cumulative_pct: ëˆ„ì ë°±ë¶„ìœ„ (0.0 ~ 100.0)
            total_students: ì „ì²´ ìˆ˜í—˜ìƒ ìˆ˜ (ê¸°ë³¸ 50ë§Œëª…)
        """
        # cumulative_pctê°€ ë‚®ì„ìˆ˜ë¡ ìƒìœ„ê¶Œ
        # ì˜ˆ: 5%ëŠ” ìƒìœ„ 5% â†’ 25,000ë“±
        rank = int((cumulative_pct / 100.0) * total_students)
        return max(1, rank)


# í†µí•©: rules.pyì—ì„œ ì‚¬ìš©
def compute_theory_result_with_fallback(excel_data, profile, debug=False):
    """
    INDEX ìš°íšŒ ë¡œì§ì´ í¬í•¨ëœ Theory ê²°ê³¼ ê³„ì‚°
    """
    from theory_engine.rules import (
        convert_raw_to_standard,
        lookup_index,
        lookup_percentage,
        check_disqualification,
    )
    from theory_engine.optimizers.index_fallback import IndexFallbackCalculator
    
    fallback_calc = IndexFallbackCalculator()
    
    # 1. RAWSCORE ë³€í™˜
    korean_conv = convert_raw_to_standard(
        excel_data["RAWSCORE"], "êµ­ì–´", profile.korean.raw_total
    )
    math_conv = convert_raw_to_standard(
        excel_data["RAWSCORE"], "ìˆ˜í•™", profile.math.raw_total
    )
    inquiry1_conv = convert_raw_to_standard(
        excel_data["RAWSCORE"], profile.inquiry1.subject, profile.inquiry1.raw_total
    )
    inquiry2_conv = convert_raw_to_standard(
        excel_data["RAWSCORE"], profile.inquiry2.subject, profile.inquiry2.raw_total
    )
    
    # 2. INDEX ì¡°íšŒ ì‹œë„
    index_result = lookup_index(
        excel_data["INDEX"],
        korean_conv.get("standard_score"),
        math_conv.get("standard_score"),
        inquiry1_conv.get("standard_score"),
        inquiry2_conv.get("standard_score"),
        profile.track.value
    )
    
    # 3. INDEX ì‹¤íŒ¨ ì‹œ ìš°íšŒ ë¡œì§
    if not index_result.get("found"):
        logger.warning("INDEX ì¡°íšŒ ì‹¤íŒ¨, ìš°íšŒ ë¡œì§ ì‚¬ìš©")
        
        cumulative_pct = fallback_calc.calculate_cumulative_pct_fallback(
            korean_conv, math_conv, inquiry1_conv, inquiry2_conv,
            method="weighted_average"
        )
        
        national_rank = fallback_calc.estimate_national_rank(cumulative_pct) if cumulative_pct else None
        
        index_result = {
            "found": True,
            "match_type": "fallback_rawscore",
            "cumulative_pct": cumulative_pct,
            "national_rank": national_rank,
            "percentile_sum": cumulative_pct,  # í˜¸í™˜ì„±
        }
    
    # 4. ë‚˜ë¨¸ì§€ íŒŒì´í”„ë¼ì¸ ê³„ì†...
    # (lookup_percentage, check_disqualification ë“±)
    
    return index_result  # ì‹¤ì œë¡œëŠ” TheoryResult ë°˜í™˜
```

### í•´ê²° ì „ëµ B: INDEX ì¸ì½”ë”© ì—­ê³µí•™ (ì¥ê¸°)

#### íŒ¨í„´ ë¶„ì„

```python
# tools/index_decoder.py

import re
from typing import Dict, Optional

class IndexKeyDecoder:
    """
    INDEX ì‹œíŠ¸ í‚¤ ì¸ì½”ë”© ì—­ê³µí•™
    
    ìƒ˜í”Œ í‚¤: "510gs0t20509"
    ê°€ì„¤:
    - ì²« 3ìë¦¬ (510): êµ­ì–´ í‘œì¤€ì ìˆ˜?
    - ë‹¤ìŒ 2ìë¦¬ (gs): ê³„ì—´ ì½”ë“œ? (g=ì´ê³¼, s=something?)
    - ë‹¤ìŒ 1ìë¦¬ (0): êµ¬ë¶„ì?
    - ë‹¤ìŒ 1ìë¦¬ (t): íƒêµ¬ í‘œì‹œ?
    - ë§ˆì§€ë§‰ 5ìë¦¬ (20509): ê¸°íƒ€ ì ìˆ˜ ì¡°í•©?
    """
    
    def analyze_pattern(self, key: str) -> Dict:
        """í‚¤ íŒ¨í„´ ë¶„ì„"""
        result = {
            "original": key,
            "length": len(key),
            "is_alphanumeric": key.isalnum(),
        }
        
        # ìˆ«ì/ë¬¸ì ë¶„ë¦¬
        numbers = re.findall(r'\d+', key)
        letters = re.findall(r'[a-zA-Z]+', key)
        
        result["numbers"] = numbers
        result["letters"] = letters
        
        # íŒ¨í„´ ì¶”ì¸¡
        if len(key) == 12:
            result["pattern_guess"] = {
                "part1_numeric": key[0:3],   # êµ­ì–´?
                "part2_alpha": key[3:5],     # ê³„ì—´?
                "part3_numeric": key[5:7],   # ìˆ˜í•™?
                "part4_alpha": key[7],       # íƒêµ¬?
                "part5_numeric": key[8:12],  # íƒêµ¬ì ìˆ˜?
            }
        
        return result
    
    def build_key(
        self,
        korean_std: int,
        math_std: int,
        inq1_std: int,
        inq2_std: int,
        track: str
    ) -> Optional[str]:
        """
        í‘œì¤€ì ìˆ˜ë¡œ INDEX í‚¤ ìƒì„± ì‹œë„
        
        ì£¼ì˜: ì´ê²ƒì€ ê°€ì„¤ ê¸°ë°˜ êµ¬í˜„ì´ë©°, ì‹¤ì œ ì¸ì½”ë”©ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        """
        # íŒ¨í„´ ê°€ì„¤ ì ìš©
        track_code = "gs" if track == "ì´ê³¼" else "gm"
        
        key = f"{korean_std:03d}{track_code}{math_std:03d}t{inq1_std:02d}{inq2_std:02d}"
        
        return key[:12]  # 12ìë¦¬ë¡œ ìë¦„


# ë¶„ì„ ì‹¤í–‰
if __name__ == "__main__":
    decoder = IndexKeyDecoder()
    
    # ì‹¤ì œ INDEX í‚¤ ìƒ˜í”Œ ë¶„ì„
    samples = [
        "510gs0t20509",
        "515gs0t21508",
        "505gm0t19510",
    ]
    
    for sample in samples:
        result = decoder.analyze_pattern(sample)
        print(f"\n{sample}:")
        for k, v in result.items():
            print(f"  {k}: {v}")
```

---

## ğŸ”´ Issue #3: ëŒ€í•™ ì»¤íŠ¸ë¼ì¸ ë¯¸ë°œê²¬

### ë¬¸ì œ ìƒì„¸

**í˜„ìƒ**:
```
[âœ… OK] ê°€ì²œì˜í•™: ì ì •=49.9, ì˜ˆìƒ=73.13
[âŒ FAIL] ì—°ì„¸ëŒ€ì˜ì˜ˆ: ì»¬ëŸ¼ ì—†ìŒ
[âŒ FAIL] ê³ ë ¤ëŒ€ê²½ì˜: ì»¬ëŸ¼ ì—†ìŒ
```

**ì›ì¸**:
- PERCENTAGE ì‹œíŠ¸ ì»¬ëŸ¼ í˜•ì‹: "ê°€ì²œì˜í•™ ì´ê³¼"
- ì‚¬ìš©ì ì…ë ¥: "ì—°ì„¸ëŒ€", "ê³ ë ¤ëŒ€" (ì•½ì–´/ë‹¤ë¥¸ í‘œê¸°)

### í•´ê²° ì „ëµ: University Alias + Fuzzy Matching

#### ì°¸ê³  ë¼ì´ë¸ŒëŸ¬ë¦¬

**korean-name-normalizer** (í•œêµ­ì–´ ì´ë¦„ ì •ê·œí™”)
- í•œê¸€ ì²˜ë¦¬ì— íŠ¹í™”ëœ ì •ê·œí™”

**KoNLPy** (í•œêµ­ì–´ NLP)
- URL: https://konlpy.org/
- í˜•íƒœì†Œ ë¶„ì„, ëª…ì‚¬ ì¶”ì¶œ

#### êµ¬í˜„ ì½”ë“œ

```python
# theory_engine/cutoff/university_matcher.py

from rapidfuzz import fuzz, process
from typing import Dict, List, Optional, Tuple
import re

class UniversityMatcher:
    """
    ëŒ€í•™ëª… Alias + Fuzzy ë§¤ì¹­ ì‹œìŠ¤í…œ
    
    ì°¸ê³ :
    - GitHub: seatgeek/thefuzz (12.5k stars)
    - GitHub: rapidfuzz/rapidfuzz (17.8k stars)
    """
    
    # ëŒ€í•™ëª… Alias ë§¤í•‘ (ê³µì‹ â†’ ë³„ì¹­ë“¤)
    UNIVERSITY_ALIASES: Dict[str, List[str]] = {
        # SKY
        "ì„œìš¸ëŒ€": ["ì„œëŒ€", "ì„œìš¸", "ì„œìš¸ëŒ€í•™êµ", "SNU"],
        "ì—°ì„¸ëŒ€": ["ì—°ëŒ€", "ì—°ì„¸", "ì—°ì„¸ëŒ€í•™êµ", "ì—°ì„¸ëŒ€ ì˜", "ì—°ëŒ€ì˜", "Yonsei"],
        "ê³ ë ¤ëŒ€": ["ê³ ëŒ€", "ê³ ë ¤", "ê³ ë ¤ëŒ€í•™êµ", "ê³ ëŒ€ê²½", "KU"],
        
        # ì˜ëŒ€
        "ê°€ì²œëŒ€": ["ê°€ì²œ", "ê°€ì²œëŒ€í•™êµ"],
        "ê°€í†¨ë¦­ëŒ€": ["ê°€í†¨ë¦­", "ê°€ëŒ€"],
        "ê²½ë¶ëŒ€": ["ê²½ë¶", "ê²½ëŒ€"],
        "ê²½í¬ëŒ€": ["ê²½í¬", "ê²½ëŒ€"],
        "ê³ ì‹ ëŒ€": ["ê³ ì‹ "],
        "ë‹¨êµ­ëŒ€": ["ë‹¨ëŒ€", "ë‹¨êµ­"],
        "ëŒ€êµ¬ê°€í†¨ë¦­ëŒ€": ["ëŒ€ê°€ëŒ€", "ëŒ€êµ¬ê°€í†¨ë¦­"],
        "ë¶€ì‚°ëŒ€": ["ë¶€ëŒ€", "ë¶€ì‚°"],
        "ìˆœì²œí–¥ëŒ€": ["ìˆœì²œí–¥"],
        "ì•„ì£¼ëŒ€": ["ì•„ì£¼"],
        "ì—°ì„¸ëŒ€(ì›ì£¼)": ["ì—°ëŒ€ì›ì£¼", "ì›ì£¼ì—°ëŒ€"],
        "ì˜ë‚¨ëŒ€": ["ì˜ë‚¨"],
        "ìš¸ì‚°ëŒ€": ["ìš¸ì‚°", "ìš¸ëŒ€"],
        "ì„ì§€ëŒ€": ["ì„ì§€"],
        "ì¸ì œëŒ€": ["ì¸ì œ"],
        "ì¸í•˜ëŒ€": ["ì¸í•˜"],
        "ì „ë‚¨ëŒ€": ["ì „ë‚¨", "ì „ëŒ€"],
        "ì „ë¶ëŒ€": ["ì „ë¶"],
        "ì œì£¼ëŒ€": ["ì œì£¼"],
        "ì¡°ì„ ëŒ€": ["ì¡°ì„ "],
        "ì¤‘ì•™ëŒ€": ["ì¤‘ëŒ€", "ì¤‘ì•™"],
        "ì°¨ì˜ê³¼ëŒ€": ["ì°¨ì˜ëŒ€", "ì°¨ëŒ€"],
        "ì¶©ë‚¨ëŒ€": ["ì¶©ë‚¨"],
        "ì¶©ë¶ëŒ€": ["ì¶©ë¶"],
        "í•œë¦¼ëŒ€": ["í•œë¦¼"],
        "í•œì–‘ëŒ€": ["í•œëŒ€", "í•œì–‘"],
        
        # ì£¼ìš” ëŒ€í•™
        "ì„±ê· ê´€ëŒ€": ["ì„±ëŒ€", "ì„±ê· ê´€", "SKKU"],
        "ì„œê°•ëŒ€": ["ì„œê°•"],
        "ì´í™”ì—¬ëŒ€": ["ì´ëŒ€", "ì´í™”"],
        "í•œêµ­ì™¸ëŒ€": ["ì™¸ëŒ€", "í•œêµ­ì™¸ëŒ€"],
        "ê±´êµ­ëŒ€": ["ê±´ëŒ€", "ê±´êµ­"],
        "ë™êµ­ëŒ€": ["ë™ëŒ€", "ë™êµ­"],
        "í™ìµëŒ€": ["í™ëŒ€", "í™ìµ"],
        "ìˆ™ëª…ì—¬ëŒ€": ["ìˆ™ëŒ€", "ìˆ™ëª…"],
        "ê²½ê¸°ëŒ€": ["ê²½ê¸°"],
        "êµ­ë¯¼ëŒ€": ["êµ­ë¯¼", "êµ­ëŒ€"],
        "ì„¸ì¢…ëŒ€": ["ì„¸ì¢…"],
        "ìˆ­ì‹¤ëŒ€": ["ìˆ­ì‹¤"],
        "ê´‘ìš´ëŒ€": ["ê´‘ìš´"],
        "ëª…ì§€ëŒ€": ["ëª…ì§€"],
        "ìƒëª…ëŒ€": ["ìƒëª…"],
        "ì„œìš¸ì‹œë¦½ëŒ€": ["ì‹œë¦½ëŒ€", "ì„œìš¸ì‹œë¦½"],
    }
    
    # ì—­ë§¤í•‘ (ë³„ì¹­ â†’ ê³µì‹)
    ALIAS_TO_OFFICIAL: Dict[str, str] = {}
    
    def __init__(self):
        # ì—­ë§¤í•‘ êµ¬ì¶•
        for official, aliases in self.UNIVERSITY_ALIASES.items():
            self.ALIAS_TO_OFFICIAL[official] = official  # ìê¸° ìì‹ ë„ í¬í•¨
            for alias in aliases:
                self.ALIAS_TO_OFFICIAL[alias] = official
    
    def normalize_university(self, name: str) -> str:
        """ëŒ€í•™ëª… ì •ê·œí™”"""
        if not name:
            return ""
        
        # ê³µë°± ì œê±°
        normalized = name.replace(" ", "")
        
        # 'ëŒ€í•™êµ' â†’ 'ëŒ€' ì¶•ì•½
        normalized = re.sub(r'ëŒ€í•™êµ$', 'ëŒ€', normalized)
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        normalized = re.sub(r'[Â·\-_]', '', normalized)
        
        return normalized
    
    def get_official_name(self, name: str) -> str:
        """ë³„ì¹­ â†’ ê³µì‹ ëŒ€í•™ëª… ë³€í™˜"""
        normalized = self.normalize_university(name)
        
        # ì •í™• ë§¤ì¹­ ì‹œë„
        if normalized in self.ALIAS_TO_OFFICIAL:
            return self.ALIAS_TO_OFFICIAL[normalized]
        
        # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„
        for alias, official in self.ALIAS_TO_OFFICIAL.items():
            if alias in normalized or normalized in alias:
                return official
        
        return name  # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
    
    def find_column_in_percentage(
        self,
        df_columns: List[str],
        university: str,
        major: str,
        track: str,
        threshold: int = 70
    ) -> Optional[Tuple[str, int]]:
        """
        PERCENTAGE DataFrameì—ì„œ ëŒ€í•™/ì „ê³µ ì»¬ëŸ¼ ì°¾ê¸°
        
        Args:
            df_columns: DataFrame ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
            university: ëŒ€í•™ëª…
            major: ì „ê³µëª…
            track: ê³„ì—´ (ì´ê³¼/ë¬¸ê³¼)
            threshold: Fuzzy ë§¤ì¹­ ì„ê³„ê°’
            
        Returns:
            (ë§¤ì¹­ëœ ì»¬ëŸ¼ëª…, ì ìˆ˜) ë˜ëŠ” None
        """
        # 1. ê³µì‹ ëŒ€í•™ëª… ë³€í™˜
        official_univ = self.get_official_name(university)
        
        # 2. ê²€ìƒ‰ íŒ¨í„´ ìƒì„±
        patterns = [
            f"{official_univ}{major} {track}",  # "ì„œìš¸ëŒ€ê³µëŒ€ ì´ê³¼"
            f"{official_univ}{major}",          # "ì„œìš¸ëŒ€ê³µëŒ€"
            f"{official_univ} {major}",         # "ì„œìš¸ëŒ€ ê³µëŒ€"
        ]
        
        # ë³„ì¹­ë„ ì¶”ê°€
        if official_univ in self.UNIVERSITY_ALIASES:
            for alias in self.UNIVERSITY_ALIASES[official_univ]:
                patterns.append(f"{alias}{major} {track}")
                patterns.append(f"{alias}{major}")
        
        # 3. ì •í™• ë§¤ì¹­ ì‹œë„
        for pattern in patterns:
            if pattern in df_columns:
                return (pattern, 100)
        
        # 4. Fuzzy ë§¤ì¹­ ì‹œë„
        # ëŒ€í•™ëª… í¬í•¨ ì»¬ëŸ¼ë§Œ í•„í„°
        filtered_columns = [
            col for col in df_columns 
            if any(alias in col for alias in [official_univ] + self.UNIVERSITY_ALIASES.get(official_univ, []))
        ]
        
        if filtered_columns:
            for pattern in patterns:
                result = process.extractOne(
                    query=pattern,
                    choices=filtered_columns,
                    scorer=fuzz.WRatio,
                    score_cutoff=threshold
                )
                if result:
                    return (result[0], result[1])
        
        # 5. ì „ì²´ ì»¬ëŸ¼ì—ì„œ Fuzzy ë§¤ì¹­
        best_pattern = f"{official_univ}{major}"
        result = process.extractOne(
            query=best_pattern,
            choices=df_columns,
            scorer=fuzz.WRatio,
            score_cutoff=threshold - 10  # ì„ê³„ê°’ ë‚®ì¶¤
        )
        
        if result:
            return (result[0], result[1])
        
        return None


# CutoffExtractor í†µí•©
class CutoffExtractorV2:
    """ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œê¸° v2.0 (University Matcher í†µí•©)"""
    
    def __init__(self, percentage_df):
        self.df = percentage_df
        self.matcher = UniversityMatcher()
        self._build_cache()
    
    def _build_cache(self):
        """ì»¬ëŸ¼ ìºì‹œ êµ¬ì¶•"""
        self.columns = list(self.df.columns)
        self.column_set = set(self.columns)
    
    def get_cutoffs(
        self,
        university: str,
        major: str,
        track: str
    ) -> Dict:
        """
        ì»¤íŠ¸ë¼ì¸ ì¡°íšŒ
        
        Returns:
            {
                "found": True/False,
                "column": "ê°€ì²œì˜í•™ ì´ê³¼",
                "match_score": 95,
                "cutoff_safe": 49.9,   # 80%
                "cutoff_normal": 73.13, # 50%
                "cutoff_risk": 88.28,   # 20%
            }
        """
        # ì»¬ëŸ¼ ì°¾ê¸°
        match_result = self.matcher.find_column_in_percentage(
            self.columns, university, major, track
        )
        
        if not match_result:
            return {
                "found": False,
                "university": university,
                "major": major,
                "track": track,
                "error": "ì»¬ëŸ¼ ë¯¸ë°œê²¬"
            }
        
        column, score = match_result
        
        # ì»¤íŠ¸ë¼ì¸ ì¶”ì¶œ (80%, 50%, 20%)
        col_data = self.df[column].dropna()
        
        # % ì»¬ëŸ¼ ì°¾ê¸°
        pct_col = self.df.columns[0]  # ë³´í†µ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ %
        
        # ë°±ë¶„ìœ„ë³„ ì ìˆ˜ ì¡°íšŒ
        cutoffs = self._extract_cutoff_values(column, pct_col)
        
        return {
            "found": True,
            "column": column,
            "match_score": score,
            **cutoffs
        }
    
    def _extract_cutoff_values(self, score_col: str, pct_col: str) -> Dict:
        """ë°±ë¶„ìœ„ë³„ ì»¤íŠ¸ë¼ì¸ ê°’ ì¶”ì¶œ"""
        result = {}
        
        for pct, label in [(80, "safe"), (50, "normal"), (20, "risk")]:
            try:
                # í•´ë‹¹ ë°±ë¶„ìœ„ì— ê°€ì¥ ê°€ê¹Œìš´ í–‰ ì°¾ê¸°
                idx = (self.df[pct_col] - pct / 100).abs().idxmin()
                value = self.df.loc[idx, score_col]
                result[f"cutoff_{label}"] = float(value) if pd.notna(value) else None
            except:
                result[f"cutoff_{label}"] = None
        
        return result


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    matcher = UniversityMatcher()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        ("ì—°ëŒ€", "ì˜ì˜ˆ", "ì´ê³¼"),
        ("ê³ ëŒ€", "ê²½ì˜", "ë¬¸ê³¼"),
        ("ì„œìš¸ëŒ€í•™êµ", "ê³µëŒ€", "ì´ê³¼"),
        ("ê°€ì²œ", "ì˜í•™", "ì´ê³¼"),
    ]
    
    # ìƒ˜í”Œ ì»¬ëŸ¼ (ì‹¤ì œ PERCENTAGE ì‹œíŠ¸ì—ì„œ ì¶”ì¶œ)
    sample_columns = [
        "ê°€ì²œì˜í•™ ì´ê³¼", "ê±´êµ­ìì—° ë¬¸ê³¼", "ê²½ê¸°ì¸ë¬¸ ë¬¸ê³¼",
        "ì—°ì„¸ì˜ì˜ˆ ì´ê³¼", "ê³ ë ¤ê²½ì˜ ë¬¸ê³¼", "ì„œìš¸ëŒ€ê³µëŒ€ ì´ê³¼",
    ]
    
    for univ, major, track in test_cases:
        result = matcher.find_column_in_percentage(
            sample_columns, univ, major, track
        )
        print(f"{univ} {major}: {result}")
```

---

## ğŸ“Š í†µí•© í…ŒìŠ¤íŠ¸ ê³„íš

### Golden Case í…ŒìŠ¤íŠ¸

```python
# tests/test_golden_cases.py

import pytest
from theory_engine import loader, rules
from theory_engine.model import StudentProfile, ExamScore, TargetProgram
from theory_engine.constants import Track

GOLDEN_CASES = [
    {
        "name": "ì´ê³¼_ìƒìœ„ê¶Œ_í•™ìƒ_A",
        "input": {
            "track": Track.SCIENCE,
            "korean": ExamScore("êµ­ì–´", raw_total=85),
            "math": ExamScore("ìˆ˜í•™", raw_total=82),
            "english_grade": 1,
            "history_grade": 2,
            "inquiry1": ExamScore("ë¬¼ë¦¬í•™ â… ", raw_total=47),
            "inquiry2": ExamScore("í™”í•™ â… ", raw_total=45),
            "targets": [
                TargetProgram("ì„œìš¸ëŒ€", "ê³µëŒ€"),
                TargetProgram("ì—°ì„¸ëŒ€", "ê³µëŒ€"),
                TargetProgram("ê³ ë ¤ëŒ€", "ê³µëŒ€"),
            ],
        },
        "expected": {
            "korean_standard_min": 130,
            "korean_standard_max": 140,
            "ì„œìš¸ëŒ€ê³µëŒ€": {"level_options": ["ì†Œì‹ ", "ì˜ˆìƒ"]},
            "ì—°ì„¸ëŒ€ê³µëŒ€": {"level_options": ["ì˜ˆìƒ", "ì ì •"]},
            "ê³ ë ¤ëŒ€ê³µëŒ€": {"level_options": ["ì ì •"]},
        },
    },
    {
        "name": "ì´ê³¼_ì¤‘ìœ„ê¶Œ_í•™ìƒ_B",
        "input": {
            "track": Track.SCIENCE,
            "korean": ExamScore("êµ­ì–´", raw_total=75),
            "math": ExamScore("ìˆ˜í•™", raw_total=70),
            "english_grade": 2,
            "history_grade": 3,
            "inquiry1": ExamScore("ìƒëª…ê³¼í•™ â… ", raw_total=42),
            "inquiry2": ExamScore("ì§€êµ¬ê³¼í•™ â… ", raw_total=40),
            "targets": [
                TargetProgram("í•œì–‘ëŒ€", "ìì—°"),
                TargetProgram("ê±´êµ­ëŒ€", "ìì—°"),
                TargetProgram("ê²½ê¸°ëŒ€", "ì¸ë¬¸"),
            ],
        },
        "expected": {
            "í•œì–‘ëŒ€ìì—°": {"level_options": ["ì†Œì‹ ", "ìƒí–¥"]},
            "ê±´êµ­ëŒ€ìì—°": {"level_options": ["ì˜ˆìƒ", "ì ì •"]},
        },
    },
    # ì¶”ê°€ ì¼€ì´ìŠ¤...
]


class TestGoldenCases:
    """Golden Case í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture(scope="class")
    def excel_data(self):
        """ì—‘ì…€ ë°ì´í„° ë¡œë“œ (í´ë˜ìŠ¤ ë‹¨ìœ„ ìºì‹±)"""
        return loader.load_workbook()
    
    @pytest.mark.parametrize("case", GOLDEN_CASES, ids=lambda c: c["name"])
    def test_golden_case(self, excel_data, case):
        """Golden Case í…ŒìŠ¤íŠ¸"""
        # í”„ë¡œí•„ ìƒì„±
        profile = StudentProfile(
            track=case["input"]["track"],
            korean=case["input"]["korean"],
            math=case["input"]["math"],
            english_grade=case["input"]["english_grade"],
            history_grade=case["input"]["history_grade"],
            inquiry1=case["input"]["inquiry1"],
            inquiry2=case["input"]["inquiry2"],
            targets=case["input"]["targets"],
        )
        
        # ê²°ê³¼ ê³„ì‚°
        result = rules.compute_theory_result(excel_data, profile)
        
        # ê²€ì¦: êµ­ì–´ í‘œì¤€ì ìˆ˜ ë²”ìœ„
        if "korean_standard_min" in case["expected"]:
            assert case["expected"]["korean_standard_min"] <= \
                   result.raw_components["korean_standard"] <= \
                   case["expected"]["korean_standard_max"]
        
        # ê²€ì¦: ëŒ€í•™ë³„ ë ˆë²¨
        for prog_result in result.program_results:
            key = f"{prog_result.target.university}{prog_result.target.major}"
            if key in case["expected"]:
                expected_levels = case["expected"][key]["level_options"]
                assert prog_result.level_theory.value in expected_levels, \
                    f"{key}: ì˜ˆìƒ {expected_levels}, ì‹¤ì œ {prog_result.level_theory.value}"
```

---

## ğŸ—“ï¸ ì‹¤í–‰ ì¼ì •

### P0: ì¦‰ì‹œ ì¡°ì¹˜ (6ì‹œê°„)

| ì‹œê°„ | ì‘ì—… | íŒŒì¼ | ê²€ì¦ |
|------|------|------|------|
| **0-1h** | INDEX ìš°íšŒ ë¡œì§ | `optimizers/index_fallback.py` | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ |
| **1-3h** | RAWSCORE íƒêµ¬ê³¼ëª© | `matchers/subject_matcher_v2.py` | íƒêµ¬ê³¼ëª© í…ŒìŠ¤íŠ¸ |
| **3-5h** | ëŒ€í•™ëª… Alias | `cutoff/university_matcher.py` | ìƒìœ„ê¶Œ ëŒ€í•™ í…ŒìŠ¤íŠ¸ |
| **5-6h** | í†µí•© í…ŒìŠ¤íŠ¸ | `tests/test_golden_cases.py` | Golden Case 5ê±´ |

### P1: ë‹¨ê¸° ì¡°ì¹˜ (1ì£¼)

| ì‘ì—… | ì†Œìš” | ë‹´ë‹¹ |
|------|------|------|
| INDEX ì¸ì½”ë”© ì—­ê³µí•™ ë¶„ì„ | 4ì‹œê°„ | ì•Œê³ ë¦¬ì¦˜íŒ€ |
| Golden Case 20ê±´ ì¶”ê°€ | 1ì¼ | QAíŒ€ |
| CI/CD ìë™ í…ŒìŠ¤íŠ¸ | 4ì‹œê°„ | DevOps |
| ë¬¸ì„œí™” | 2ì‹œê°„ | ê¸°ìˆ ë¬¸ì„œíŒ€ |

### P2: ì¤‘ê¸° ì¡°ì¹˜ (1ê°œì›”)

| ì‘ì—… | ì†Œìš” | ë‹´ë‹¹ |
|------|------|------|
| Vertex AI ì—°ë™ (A/B ê°­ ë³´ì •) | 2ì£¼ | MLíŒ€ |
| LLM í”¼ë“œë°± ìƒì„± | 1ì£¼ | AIíŒ€ |
| ì›¹ ëŒ€ì‹œë³´ë“œ MVP | 2ì£¼ | í”„ë¡ íŠ¸íŒ€ |
| ë„¤ì˜¤ìº£ íŒŒì¼ëŸ¿ | 2ì£¼ | ì˜ì—…íŒ€ |

---

## ğŸ“š ì°¸ê³  ìë£Œ

### GitHub ë ˆí¬ì§€í† ë¦¬

| í”„ë¡œì íŠ¸ | Stars | ìš©ë„ | URL |
|---------|-------|------|-----|
| **rapidfuzz** | 17.8k | ê³ ì† Fuzzy ë§¤ì¹­ | https://github.com/rapidfuzz/rapidfuzz |
| **thefuzz** | 12.5k | ë¬¸ìì—´ ìœ ì‚¬ë„ | https://github.com/seatgeek/thefuzz |
| **student-admission-predictor** | - | ì…í•™ ì˜ˆì¸¡ ëª¨ë¸ | https://github.com/shivamr021/student-admission-predictor |
| **student_admission_prediction** | - | ML ë¹„êµ ì˜ˆì œ | https://github.com/alicevillar/student_admission_prediction |

### ë…¼ë¬¸ ë° ë¬¸ì„œ

| ì œëª© | ë‚´ìš© | ë§í¬ |
|------|------|------|
| Precision-Recall Curve ìµœì í™” | threshold ì¡°ì • ê¸°ë²• | GeeksforGeeks |
| Class-wise Calibration | í´ë˜ìŠ¤ë³„ ë³´ì • | arXiv:2210.03702 |
| Temperature Scaling | í™•ë¥  ë³´ì • | arXiv:1706.04599 |

### ì„¤ì¹˜ ëª…ë ¹

```bash
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install rapidfuzz>=3.0.0
pip install thefuzz>=0.20.0
pip install python-Levenshtein>=0.20.0  # thefuzz ì†ë„ í–¥ìƒ

# í•œêµ­ì–´ NLP (ì„ íƒ)
pip install konlpy>=0.6.0

# ML ê´€ë ¨ (ì¥ê¸°)
pip install scikit-learn>=1.3.0
pip install xgboost>=2.0.0
pip install shap>=0.43.0
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### P0 ì™„ë£Œ ê¸°ì¤€ (6ì‹œê°„ í›„)

- [ ] INDEX ìš°íšŒ ë¡œì§ êµ¬í˜„ ì™„ë£Œ
- [ ] RAWSCORE íƒêµ¬ê³¼ëª© ë§¤ì¹­ 90%+ ë‹¬ì„±
- [ ] ëŒ€í•™ëª… Alias ì‹œìŠ¤í…œ ë™ì‘ í™•ì¸
- [ ] Golden Case 5ê±´ í†µê³¼
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ 95%+ í†µê³¼

### P1 ì™„ë£Œ ê¸°ì¤€ (1ì£¼ í›„)

- [ ] INDEX ì¸ì½”ë”© íŒ¨í„´ ë¶„ì„ ì™„ë£Œ
- [ ] Golden Case 20ê±´ í†µê³¼
- [ ] CI/CD ìë™ í…ŒìŠ¤íŠ¸ êµ¬ì¶•
- [ ] ê¸°ìˆ  ë¬¸ì„œ ì—…ë°ì´íŠ¸

### P2 ì™„ë£Œ ê¸°ì¤€ (1ê°œì›” í›„)

- [ ] Vertex AI A/B ê°­ ë³´ì • ëª¨ë¸ ë°°í¬
- [ ] LLM í”¼ë“œë°± ìƒì„± ê¸°ëŠ¥ ì™„ì„±
- [ ] ì›¹ ëŒ€ì‹œë³´ë“œ MVP ì™„ì„±
- [ ] ë„¤ì˜¤ìº£ íŒŒì¼ëŸ¿ ì‹œì‘

---

## ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

### ì •ëŸ‰ì  ëª©í‘œ

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ë‹¬ì„± ì‹œì  |
|------|------|------|----------|
| **ì „ì²´ ì‘ë™ë¥ ** | 58% | 95%+ | 6ì‹œê°„ í›„ |
| **RAWSCORE ì„±ê³µë¥ ** | 40% | 90%+ | 2ì‹œê°„ í›„ |
| **INDEX ì„±ê³µë¥ ** | 0% | 95%+ | 1ì‹œê°„ í›„ |
| **ì»¤íŠ¸ë¼ì¸ ì„±ê³µë¥ ** | 67% | 95%+ | 3ì‹œê°„ í›„ |
| **Golden Case í†µê³¼** | 0/5 | 5/5 | 6ì‹œê°„ í›„ |

### ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜

| ê°€ì¹˜ | í˜„ì¬ | 6ì‹œê°„ í›„ |
|------|------|---------|
| **ë„¤ì˜¤ìº£ íŒŒì¼ëŸ¿** | âŒ ë¶ˆê°€ | âœ… ê°€ëŠ¥ |
| **Theory Engine API** | ğŸŸ¡ ë¶€ë¶„ | âœ… ì™„ì „ |
| **VC í”¼ì¹­ ì¤€ë¹„** | 40% | 75% |
| **ì›” ë§¤ì¶œ ì ì¬ë ¥** | 0ì› | 400ë§Œì›+ |

---

**ì‘ì„±ì¼**: 2026-01-18  
**ë‹´ë‹¹**: Theory Engine ê°œë°œíŒ€  
**ê²€í† **: í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €  
**ìŠ¹ì¸**: -

**END OF IMPROVEMENT PLAN**
