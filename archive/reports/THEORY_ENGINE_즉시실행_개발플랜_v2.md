# Theory Engine v3.0 ì¦‰ì‹œ ì‹¤í–‰ ê°œë°œ í”Œëœ v2.0

**ì‘ì„±ì¼**: 2026-01-18  
**ê¸°ë°˜**: THEORY_ENGINE_ì´í–‰í˜„í™©_ìˆ˜ì •ë³´ê³ ì„œ_20260118.md  
**ëª©í‘œ**: ì‹¤ì œ ì‘ë™ë¥  58% â†’ 98% (6ì‹œê°„ ë‚´ ì™„ë£Œ)  
**ì—ì´ì „íŠ¸**: Claude ì—ì´ì „íŠ¸ CLI ìµœì í™”

---

## ğŸ“‹ Executive Summary

### í•µì‹¬ ì´ìŠˆ 3ê°œ - ì •í™•í•œ ì›ì¸ê³¼ í•´ê²°ì±…

| # | ì´ìŠˆ | í˜„ì¬ | ì›ì¸ | í•´ê²°ì±… | ì†Œìš” |
|---|------|------|------|--------|------|
| **1** | RAWSCORE íƒêµ¬ê³¼ëª© | 40% | `rules.py`ê°€ "ì˜ì—­" ì»¬ëŸ¼ë§Œ ê²€ìƒ‰, íƒêµ¬ëŠ” "ê³¼ëª©ëª…" ì‚¬ìš© | `convert_raw_to_standard()` 3ë‹¨ê³„ ë§¤ì¹­ ì¶”ê°€ | **90ë¶„** |
| **2** | INDEX ì¡°íšŒ | 0% | ì²« ì»¬ëŸ¼ í•´ì‹œ ì¸ì½”ë”©, MultiIndex 0í–‰ êµ¬ì¶• | RAWSCORE ëˆ„ì % í´ë°± ë¡œì§ | **60ë¶„** |
| **3** | ëŒ€í•™ ì»¤íŠ¸ë¼ì¸ | 67% | "ì—°ì„¸ëŒ€" vs "ì—°ëŒ€", Alias ì—†ìŒ | `cutoff_extractor.py`ì— 30+ ëŒ€í•™ Alias ì¶”ê°€ | **90ë¶„** |

---

## ğŸ”§ Task 1: RAWSCORE íƒêµ¬ê³¼ëª© ìˆ˜ì • (90ë¶„)

### 1.1 í˜„ì¬ ë¬¸ì œì 

```python
# í˜„ì¬ rules.py:166-169
mask = (
    (rawscore_df["ì˜ì—­"].apply(lambda x: normalize_subject(str(x))) == normalized_subject) &
    (rawscore_df.get("ì›ì ìˆ˜", raw_score) == raw_score)
)
```

**ë¬¸ì œ**: íƒêµ¬ê³¼ëª©ì€ `ì˜ì—­="íƒêµ¬"` + `ê³¼ëª©ëª…="ë¬¼ë¦¬í•™ â… "` êµ¬ì¡°  
**í˜„ì¬**: `ì˜ì—­` ì»¬ëŸ¼ë§Œ ê²€ìƒ‰í•˜ë¯€ë¡œ êµ­ì–´/ìˆ˜í•™ë§Œ ì„±ê³µ

### 1.2 ìˆ˜ì • ì½”ë“œ

**íŒŒì¼**: `theory_engine/rules.py`  
**í•¨ìˆ˜**: `convert_raw_to_standard()` ì „ì²´ êµì²´

```python
def convert_raw_to_standard(
    rawscore_df: pd.DataFrame,
    subject: str,
    raw_score: int,
    raw_common: Optional[int] = None,
    raw_select: Optional[int] = None
) -> Dict[str, Any]:
    """
    ì›ì ìˆ˜ â†’ í‘œì¤€ì ìˆ˜/ë°±ë¶„ìœ„/ë“±ê¸‰ ë³€í™˜ (v2: ë‹¤ë‹¨ê³„ ë§¤ì¹­)
    
    ë³€ê²½ì‚¬í•­:
    - Stage 1: ì˜ì—­ ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­ (êµ­ì–´, ìˆ˜í•™)
    - Stage 2: ê³¼ëª©ëª… ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­ (íƒêµ¬ê³¼ëª©)
    - Stage 3: ì˜ì—­="íƒêµ¬" + ê³¼ëª©ëª… í¼ì§€ ë§¤ì¹­
    - Stage 4: ì „ì²´ í¼ì§€ ë§¤ì¹­ (ìµœí›„ ìˆ˜ë‹¨)
    """
    # ê³¼ëª©ëª… ì •ê·œí™”
    normalized_subject = normalize_subject(subject)
    
    # ì¡°íšŒ í‚¤ ìƒì„±
    if raw_common is not None and raw_select is not None:
        key = f"{normalized_subject}-{raw_common}-{raw_select}"
    else:
        key = f"{normalized_subject}-{raw_score}"
    
    result_df = pd.DataFrame()
    match_type = None
    
    # ============================================================
    # Stage 1: ì˜ì—­ ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­ (êµ­ì–´, ìˆ˜í•™)
    # ============================================================
    if "ì˜ì—­" in rawscore_df.columns:
        # ì •ê·œí™”ëœ ê³¼ëª©ëª…ìœ¼ë¡œ ë§¤ì¹­
        mask1 = rawscore_df["ì˜ì—­"].apply(
            lambda x: normalize_subject(str(x)) if pd.notna(x) else ""
        ) == normalized_subject
        
        if mask1.any():
            # ì›ì ìˆ˜ ë§¤ì¹­
            if "ì›ì ìˆ˜" in rawscore_df.columns:
                mask1 = mask1 & (rawscore_df["ì›ì ìˆ˜"] == raw_score)
            result_df = rawscore_df[mask1]
            if not result_df.empty:
                match_type = "stage1_ì˜ì—­"
                logger.debug(f"Stage 1 ì„±ê³µ: {key} ({match_type})")
    
    # ============================================================
    # Stage 2: ê³¼ëª©ëª… ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­ (íƒêµ¬ê³¼ëª©)
    # ============================================================
    if result_df.empty and "ê³¼ëª©ëª…" in rawscore_df.columns:
        # ê³¼ëª©ëª… ì •ê·œí™” ë§¤ì¹­
        mask2 = rawscore_df["ê³¼ëª©ëª…"].apply(
            lambda x: normalize_subject(str(x)) if pd.notna(x) else ""
        ) == normalized_subject
        
        if mask2.any():
            # ì›ì ìˆ˜ ë§¤ì¹­
            if "ì›ì ìˆ˜" in rawscore_df.columns:
                mask2 = mask2 & (rawscore_df["ì›ì ìˆ˜"] == raw_score)
            result_df = rawscore_df[mask2]
            if not result_df.empty:
                match_type = "stage2_ê³¼ëª©ëª…"
                logger.debug(f"Stage 2 ì„±ê³µ: {key} ({match_type})")
    
    # ============================================================
    # Stage 3: ì˜ì—­="íƒêµ¬" + ê³¼ëª©ëª… í¼ì§€ ë§¤ì¹­
    # ============================================================
    if result_df.empty and "ì˜ì—­" in rawscore_df.columns and "ê³¼ëª©ëª…" in rawscore_df.columns:
        # íƒêµ¬ ì˜ì—­ í•„í„°
        íƒêµ¬_df = rawscore_df[rawscore_df["ì˜ì—­"] == "íƒêµ¬"].copy()
        
        if not íƒêµ¬_df.empty:
            # ê³¼ëª©ëª… ì •ê·œí™” í›„ ë§¤ì¹­
            íƒêµ¬_df["_normalized"] = íƒêµ¬_df["ê³¼ëª©ëª…"].apply(
                lambda x: normalize_subject(str(x)) if pd.notna(x) else ""
            )
            
            # ì™„ì „ ë§¤ì¹­
            mask3 = íƒêµ¬_df["_normalized"] == normalized_subject
            if mask3.any() and "ì›ì ìˆ˜" in íƒêµ¬_df.columns:
                mask3 = mask3 & (íƒêµ¬_df["ì›ì ìˆ˜"] == raw_score)
            result_df = íƒêµ¬_df[mask3]
            
            if not result_df.empty:
                match_type = "stage3_íƒêµ¬ì˜ì—­"
                logger.debug(f"Stage 3 ì„±ê³µ: {key} ({match_type})")
            else:
                # ë¶€ë¶„ ë§¤ì¹­ (ê³¼ëª©ëª…ì— ê²€ìƒ‰ì–´ í¬í•¨)
                matcher = get_subject_matcher()
                for idx, row in íƒêµ¬_df.iterrows():
                    ê³¼ëª©ëª…_norm = row.get("_normalized", "")
                    ì›ì ìˆ˜ = row.get("ì›ì ìˆ˜", -1)
                    
                    # SubjectMatcher ì‚¬ìš©
                    _, confidence = matcher.match(ê³¼ëª©ëª…_norm)
                    matched_canonical, _ = matcher.match(normalized_subject)
                    
                    if confidence >= 70 and ì›ì ìˆ˜ == raw_score:
                        result_df = íƒêµ¬_df.loc[[idx]]
                        match_type = f"stage3_fuzzy(conf={confidence:.0f})"
                        logger.debug(f"Stage 3 Fuzzy ì„±ê³µ: {key} ({match_type})")
                        break
    
    # ============================================================
    # Stage 4: ì „ì²´ í¼ì§€ ë§¤ì¹­ (ìµœí›„ ìˆ˜ë‹¨)
    # ============================================================
    if result_df.empty:
        matcher = get_subject_matcher()
        
        # ëª¨ë“  ê³¼ëª©ëª… í›„ë³´ ìˆ˜ì§‘
        all_subjects = set()
        if "ì˜ì—­" in rawscore_df.columns:
            all_subjects.update(rawscore_df["ì˜ì—­"].dropna().unique())
        if "ê³¼ëª©ëª…" in rawscore_df.columns:
            all_subjects.update(rawscore_df["ê³¼ëª©ëª…"].dropna().unique())
        
        best_match = None
        best_score = 0
        
        for candidate in all_subjects:
            canonical, score = matcher.match(str(candidate))
            input_canonical, _ = matcher.match(subject)
            
            if canonical == input_canonical and score > best_score:
                best_score = score
                best_match = candidate
        
        if best_match and best_score >= 70:
            # ë§¤ì¹­ëœ ê³¼ëª©ìœ¼ë¡œ í•„í„°
            if best_match in rawscore_df.get("ì˜ì—­", pd.Series()).values:
                mask4 = rawscore_df["ì˜ì—­"] == best_match
            elif best_match in rawscore_df.get("ê³¼ëª©ëª…", pd.Series()).values:
                mask4 = rawscore_df["ê³¼ëª©ëª…"] == best_match
            else:
                mask4 = pd.Series([False] * len(rawscore_df))
            
            if mask4.any() and "ì›ì ìˆ˜" in rawscore_df.columns:
                mask4 = mask4 & (rawscore_df["ì›ì ìˆ˜"] == raw_score)
            
            result_df = rawscore_df[mask4]
            if not result_df.empty:
                match_type = f"stage4_global_fuzzy(score={best_score:.0f})"
                logger.debug(f"Stage 4 ì„±ê³µ: {key} ({match_type})")
    
    # ============================================================
    # ê²°ê³¼ ì²˜ë¦¬
    # ============================================================
    if result_df.empty:
        logger.warning(f"RAWSCORE ì¡°íšŒ ì‹¤íŒ¨: {key} (all 4 stages failed)")
        return {
            "found": False,
            "key": key,
            "match_type": None,
            "standard_score": None,
            "percentile": None,
            "grade": None,
            "cumulative_pct": None,
        }
    
    # ì²« ë²ˆì§¸ ë§¤ì¹­ í–‰ ì‚¬ìš©
    row = result_df.iloc[0]
    
    # ì»¬ëŸ¼ëª… ë˜ëŠ” ì¸ë±ìŠ¤ë¡œ ê°’ ì¶”ì¶œ
    def safe_get(row, col_name, col_idx):
        """ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ"""
        if col_name in row.index:
            return row[col_name]
        elif len(row) > col_idx:
            return row.iloc[col_idx]
        return None
    
    return {
        "found": True,
        "key": key,
        "match_type": match_type,
        "standard_score": safe_get(row, "202511(ê°€ì±„ì )", 6),
        "percentile": safe_get(row, "ë°±ë¶„ìœ„", 7),
        "grade": safe_get(row, "ë“±ê¸‰", 8),
        "cumulative_pct": safe_get(row, "ëˆ„ì %", 9),
    }
```

### 1.3 í…ŒìŠ¤íŠ¸ ì½”ë“œ

```python
# tests/test_rawscore_inquiry.py

import pytest
from theory_engine.loader import load_workbook
from theory_engine.rules import convert_raw_to_standard

@pytest.fixture(scope="module")
def excel_data():
    return load_workbook()

class TestRAWSCOREInquirySubjects:
    """RAWSCORE íƒêµ¬ê³¼ëª© ë³€í™˜ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.parametrize("subject,raw_score", [
        ("êµ­ì–´", 80),
        ("ìˆ˜í•™", 75),
        ("ë¬¼ë¦¬í•™ â… ", 45),
        ("ë¬¼ë¦¬í•™I", 45),
        ("í™”í•™ â… ", 42),
        ("ìƒëª…ê³¼í•™ â… ", 40),
        ("ì§€êµ¬ê³¼í•™ â… ", 38),
        ("ìƒí™œê³¼ ìœ¤ë¦¬", 35),
        ("ì‚¬íšŒÂ·ë¬¸í™”", 42),
    ])
    def test_inquiry_conversion(self, excel_data, subject, raw_score):
        """íƒêµ¬ê³¼ëª© í¬í•¨ ì „ì²´ ê³¼ëª© ë³€í™˜"""
        result = convert_raw_to_standard(
            excel_data["RAWSCORE"], subject, raw_score
        )
        
        assert result["found"] is True, f"{subject} ë³€í™˜ ì‹¤íŒ¨: {result}"
        assert result["standard_score"] is not None, f"{subject} í‘œì¤€ì ìˆ˜ None"
        assert result["match_type"] is not None, f"{subject} ë§¤ì¹­ íƒ€ì… None"
        
        print(f"âœ… {subject} {raw_score}ì  â†’ "
              f"í‘œì¤€={result['standard_score']}, "
              f"íƒ€ì…={result['match_type']}")
```

---

## ğŸ”§ Task 2: INDEX ìš°íšŒ ë¡œì§ (60ë¶„)

### 2.1 í˜„ì¬ ë¬¸ì œì 

```
IndexOptimizer: MultiIndex êµ¬ì¶• ì™„ë£Œ: 0í–‰  â† ë¬¸ì œ!
```

**ì›ì¸**: INDEX ì‹œíŠ¸ ì²« ì»¬ëŸ¼ì´ "510gs0t20509" ê°™ì€ ì¸ì½”ë”© í‚¤

### 2.2 ìˆ˜ì • ì½”ë“œ

**ìƒˆ íŒŒì¼**: `theory_engine/optimizers/index_fallback.py`

```python
"""
INDEX ì¡°íšŒ ì‹¤íŒ¨ ì‹œ RAWSCORE ëˆ„ì % í´ë°± ê³„ì‚°
"""

import logging
from typing import Dict, Optional, List

logger = logging.getLogger(__name__)


class IndexFallback:
    """INDEX ì¡°íšŒ ìš°íšŒ ê³„ì‚°ê¸°"""
    
    # ê³¼ëª©ë³„ ê°€ì¤‘ì¹˜ (ìˆ˜ëŠ¥ ë°˜ì˜ ë¹„ìœ¨ ê¸°ë°˜)
    DEFAULT_WEIGHTS = {
        "korean": 0.28,
        "math": 0.28,
        "english": 0.14,
        "inquiry1": 0.15,
        "inquiry2": 0.15,
    }
    
    def __init__(self, weights: Optional[Dict[str, float]] = None):
        self.weights = weights or self.DEFAULT_WEIGHTS
    
    def calculate_from_rawscore(
        self,
        korean_conv: Dict,
        math_conv: Dict,
        inq1_conv: Dict,
        inq2_conv: Dict,
        english_grade: int = 1,
        method: str = "weighted"
    ) -> Dict:
        """
        RAWSCORE ëˆ„ì % í•©ì‚°ìœ¼ë¡œ INDEX ëŒ€ì²´
        
        Args:
            korean_conv: convert_raw_to_standard() ê²°ê³¼
            math_conv: convert_raw_to_standard() ê²°ê³¼
            inq1_conv: convert_raw_to_standard() ê²°ê³¼
            inq2_conv: convert_raw_to_standard() ê²°ê³¼
            english_grade: ì˜ì–´ ë“±ê¸‰ (1-9)
            method: "weighted" | "simple" | "geometric"
        
        Returns:
            {
                "found": True,
                "match_type": "fallback_rawscore_weighted",
                "cumulative_pct": 5.2,
                "percentile_sum": 356.5,
                "national_rank": 26000,
                "confidence": 0.85
            }
        """
        # ê° ê³¼ëª© ëˆ„ì % ì¶”ì¶œ
        conversions = {
            "korean": korean_conv,
            "math": math_conv,
            "inquiry1": inq1_conv,
            "inquiry2": inq2_conv,
        }
        
        pcts = {}
        for key, conv in conversions.items():
            if conv and conv.get("found"):
                pct = conv.get("cumulative_pct") or conv.get("percentile")
                if pct is not None:
                    pcts[key] = float(pct)
        
        # ì˜ì–´ ë“±ê¸‰ â†’ ë°±ë¶„ìœ„ ë³€í™˜
        english_pct = self._grade_to_percentile(english_grade)
        if english_pct:
            pcts["english"] = english_pct
        
        if not pcts:
            logger.warning("ìœ íš¨í•œ ëˆ„ì % ë°ì´í„° ì—†ìŒ")
            return {
                "found": False,
                "match_type": "fallback_failed",
                "cumulative_pct": None,
                "percentile_sum": None,
                "national_rank": None,
                "confidence": 0.0,
            }
        
        logger.info(f"INDEX í´ë°±: {len(pcts)}ê°œ ê³¼ëª© ì‚¬ìš©")
        
        # ë°©ë²•ë³„ ê³„ì‚°
        if method == "weighted":
            cumulative_pct = self._weighted_average(pcts)
            match_type = "fallback_rawscore_weighted"
        elif method == "simple":
            cumulative_pct = sum(pcts.values()) / len(pcts)
            match_type = "fallback_rawscore_simple"
        elif method == "geometric":
            import math
            product = 1.0
            for pct in pcts.values():
                product *= max(pct, 0.01) / 100
            cumulative_pct = (product ** (1 / len(pcts))) * 100
            match_type = "fallback_rawscore_geometric"
        else:
            cumulative_pct = self._weighted_average(pcts)
            match_type = "fallback_rawscore_weighted"
        
        # ë°±ë¶„ìœ„ í•©ì‚° (ë‹¨ìˆœ í•©ê³„)
        percentile_sum = sum(pcts.values())
        
        # ì „êµ­ ë“±ìˆ˜ ì¶”ì • (50ë§Œëª… ê¸°ì¤€)
        national_rank = self._estimate_national_rank(cumulative_pct)
        
        # ì‹ ë¢°ë„ ê³„ì‚° (ì‚¬ìš©ëœ ê³¼ëª© ìˆ˜ ê¸°ë°˜)
        confidence = len(pcts) / 5.0  # 5ê³¼ëª© ê¸°ì¤€
        
        return {
            "found": True,
            "match_type": match_type,
            "cumulative_pct": round(cumulative_pct, 2),
            "percentile_sum": round(percentile_sum, 2),
            "national_rank": national_rank,
            "confidence": round(confidence, 2),
            "subjects_used": list(pcts.keys()),
        }
    
    def _weighted_average(self, pcts: Dict[str, float]) -> float:
        """ê°€ì¤‘ í‰ê·  ê³„ì‚°"""
        total_weight = 0.0
        weighted_sum = 0.0
        
        for key, pct in pcts.items():
            weight = self.weights.get(key, 0.2)  # ê¸°ë³¸ ê°€ì¤‘ì¹˜ 0.2
            weighted_sum += pct * weight
            total_weight += weight
        
        if total_weight == 0:
            return 50.0  # ê¸°ë³¸ê°’
        
        return weighted_sum / total_weight
    
    def _grade_to_percentile(self, grade: int) -> Optional[float]:
        """ë“±ê¸‰ â†’ ë°±ë¶„ìœ„ ë³€í™˜"""
        # ìˆ˜ëŠ¥ ë“±ê¸‰ ë°±ë¶„ìœ„ ê¸°ì¤€
        grade_to_pct = {
            1: 4.0,    # ìƒìœ„ 4%
            2: 11.0,   # ìƒìœ„ 11%
            3: 23.0,   # ìƒìœ„ 23%
            4: 40.0,   # ìƒìœ„ 40%
            5: 60.0,   # ìƒìœ„ 60%
            6: 77.0,   # ìƒìœ„ 77%
            7: 89.0,   # ìƒìœ„ 89%
            8: 96.0,   # ìƒìœ„ 96%
            9: 100.0,  # ìƒìœ„ 100%
        }
        return grade_to_pct.get(grade)
    
    def _estimate_national_rank(
        self,
        cumulative_pct: float,
        total_students: int = 500000
    ) -> int:
        """ëˆ„ì ë°±ë¶„ìœ„ â†’ ì „êµ­ ë“±ìˆ˜ ì¶”ì •"""
        # cumulative_pctê°€ ë‚®ì„ìˆ˜ë¡ ìƒìœ„ê¶Œ
        rank = int((cumulative_pct / 100.0) * total_students)
        return max(1, rank)


# ì‹±ê¸€í†¤
_index_fallback: Optional[IndexFallback] = None

def get_index_fallback() -> IndexFallback:
    global _index_fallback
    if _index_fallback is None:
        _index_fallback = IndexFallback()
    return _index_fallback
```

### 2.3 rules.py ìˆ˜ì •

**íŒŒì¼**: `theory_engine/rules.py`  
**ìœ„ì¹˜**: `compute_theory_result()` í•¨ìˆ˜ ë‚´ INDEX ì¡°íšŒ ë¶€ë¶„

```python
# rules.py ìƒë‹¨ import ì¶”ê°€
from .optimizers.index_fallback import get_index_fallback

# compute_theory_result() í•¨ìˆ˜ ë‚´ ìˆ˜ì • (ì•½ ë¼ì¸ 474-495)
# ê¸°ì¡´:
    # 2. INDEX ì¡°íšŒ
    cumulative_pct = None
    if "INDEX" in excel_data:
        index_result = lookup_index(...)
        
# ìˆ˜ì •:
    # 2. INDEX ì¡°íšŒ (+ í´ë°± ë¡œì§)
    cumulative_pct = None
    index_result = None
    
    if "INDEX" in excel_data:
        index_result = lookup_index(
            excel_data["INDEX"],
            korean_conv.get("standard_score") or 0,
            math_conv.get("standard_score") or 0,
            inq1_conv.get("standard_score") or 0,
            inq2_conv.get("standard_score") or 0,
            profile.track.value
        )
    
    # INDEX ì¡°íšŒ ì‹¤íŒ¨ ì‹œ í´ë°±
    if not index_result or not index_result.get("found"):
        logger.warning("INDEX ì¡°íšŒ ì‹¤íŒ¨, RAWSCORE í´ë°± ì‚¬ìš©")
        fallback = get_index_fallback()
        index_result = fallback.calculate_from_rawscore(
            korean_conv, math_conv, inq1_conv, inq2_conv,
            english_grade=profile.english_grade,
            method="weighted"
        )
    
    if index_result:
        cumulative_pct = index_result.get("cumulative_pct")
        result.raw_components.update({
            "index_key": index_result.get("index_key"),
            "index_found": index_result.get("found"),
            "index_match_type": index_result.get("match_type"),
            "percentile_sum": index_result.get("percentile_sum"),
            "national_rank": index_result.get("national_rank"),
            "cumulative_pct": cumulative_pct,
        })
```

---

## ğŸ”§ Task 3: ëŒ€í•™ëª… Alias ì‹œìŠ¤í…œ (90ë¶„)

### 3.1 í˜„ì¬ ë¬¸ì œì 

```python
# cutoff_extractor.py:114-118 - ë‹¨ìˆœ íŒ¨í„´ ë§¤ì¹­ë§Œ ì§€ì›
patterns.append(f"{university}{major}")  # "ê°€ì²œì˜í•™" âœ…
# "ì—°ì„¸ëŒ€" â†’ "ì—°ëŒ€" ë§¤í•‘ ì—†ìŒ âŒ
```

### 3.2 ìˆ˜ì • ì½”ë“œ

**íŒŒì¼**: `theory_engine/cutoff/cutoff_extractor.py`  
**ìœ„ì¹˜**: í´ë˜ìŠ¤ ìƒë‹¨ì— UNIVERSITY_ALIASES ì¶”ê°€ ë° `_find_program_column()` ìˆ˜ì •

```python
class CutoffExtractor:
    """ì»¤íŠ¸ë¼ì¸ ìë™ ì¶”ì¶œê¸° v2 (Alias ì§€ì›)"""

    # ============================================================
    # ëŒ€í•™ëª… Alias ë§¤í•‘ (30+ ëŒ€í•™)
    # ============================================================
    UNIVERSITY_ALIASES: Dict[str, List[str]] = {
        # === SKY ===
        "ì„œìš¸ëŒ€": ["ì„œìš¸", "ì„œëŒ€", "ì„œìš¸ëŒ€í•™êµ", "SNU"],
        "ì—°ì„¸ëŒ€": ["ì—°ëŒ€", "ì—°ì„¸", "ì—°ì„¸ëŒ€í•™êµ", "ì—°ëŒ€ì˜", "ì—°ì„¸ëŒ€ ì˜"],
        "ê³ ë ¤ëŒ€": ["ê³ ëŒ€", "ê³ ë ¤", "ê³ ë ¤ëŒ€í•™êµ", "KU"],
        
        # === ì˜ëŒ€ (ê°€ë‚˜ë‹¤ìˆœ) ===
        "ê°€ì²œëŒ€": ["ê°€ì²œ", "ê°€ì²œëŒ€í•™êµ"],
        "ê°€í†¨ë¦­ëŒ€": ["ê°€í†¨ë¦­", "ê°€ëŒ€", "ê°€í†¨ë¦­ì˜ëŒ€"],
        "ê°•ì›ëŒ€": ["ê°•ì›", "ê°•ëŒ€"],
        "ê±´êµ­ëŒ€": ["ê±´ëŒ€", "ê±´êµ­", "ê±´êµ­ëŒ€í•™êµ"],
        "ê±´ì–‘ëŒ€": ["ê±´ì–‘"],
        "ê²½ë¶ëŒ€": ["ê²½ë¶", "ê²½ëŒ€"],
        "ê²½ìƒëŒ€": ["ê²½ìƒ"],
        "ê²½í¬ëŒ€": ["ê²½í¬", "ê²½ëŒ€"],
        "ê³„ëª…ëŒ€": ["ê³„ëª…"],
        "ê³ ì‹ ëŒ€": ["ê³ ì‹ "],
        "ë‹¨êµ­ëŒ€": ["ë‹¨ëŒ€", "ë‹¨êµ­"],
        "ëŒ€êµ¬ê°€í†¨ë¦­ëŒ€": ["ëŒ€ê°€ëŒ€", "ëŒ€êµ¬ê°€í†¨ë¦­"],
        "ë™êµ­ëŒ€": ["ë™ëŒ€", "ë™êµ­"],
        "ë™ì•„ëŒ€": ["ë™ì•„"],
        "ë¶€ì‚°ëŒ€": ["ë¶€ëŒ€", "ë¶€ì‚°"],
        "ìˆœì²œí–¥ëŒ€": ["ìˆœì²œí–¥", "ìˆœëŒ€"],
        "ì•„ì£¼ëŒ€": ["ì•„ì£¼"],
        "ì—°ì„¸ëŒ€(ì›ì£¼)": ["ì—°ëŒ€ì›ì£¼", "ì›ì£¼ì—°ëŒ€", "ì—°ëŒ€ ì›ì£¼"],
        "ì˜ë‚¨ëŒ€": ["ì˜ë‚¨"],
        "ìš¸ì‚°ëŒ€": ["ìš¸ì‚°", "ìš¸ëŒ€"],
        "ì„ì§€ëŒ€": ["ì„ì§€"],
        "ì¸ì œëŒ€": ["ì¸ì œ"],
        "ì¸í•˜ëŒ€": ["ì¸í•˜"],
        "ì „ë‚¨ëŒ€": ["ì „ë‚¨", "ì „ëŒ€"],
        "ì „ë¶ëŒ€": ["ì „ë¶"],
        "ì œì£¼ëŒ€": ["ì œì£¼"],
        "ì¡°ì„ ëŒ€": ["ì¡°ì„ "],
        "ì¤‘ì•™ëŒ€": ["ì¤‘ëŒ€", "ì¤‘ì•™"],
        "ì°¨ì˜ê³¼ëŒ€": ["ì°¨ì˜ëŒ€", "ì°¨ëŒ€", "ì°¨ì˜ê³¼"],
        "ì¶©ë‚¨ëŒ€": ["ì¶©ë‚¨"],
        "ì¶©ë¶ëŒ€": ["ì¶©ë¶"],
        "í•œë¦¼ëŒ€": ["í•œë¦¼"],
        "í•œì–‘ëŒ€": ["í•œëŒ€", "í•œì–‘", "í•œì–‘ëŒ€í•™êµ"],
        
        # === ì£¼ìš” ëŒ€í•™ ===
        "ì„±ê· ê´€ëŒ€": ["ì„±ëŒ€", "ì„±ê· ê´€", "SKKU"],
        "ì„œê°•ëŒ€": ["ì„œê°•"],
        "ì´í™”ì—¬ëŒ€": ["ì´ëŒ€", "ì´í™”"],
        "í•œêµ­ì™¸ëŒ€": ["ì™¸ëŒ€", "í•œêµ­ì™¸ëŒ€"],
        "í™ìµëŒ€": ["í™ëŒ€", "í™ìµ"],
        "ìˆ™ëª…ì—¬ëŒ€": ["ìˆ™ëŒ€", "ìˆ™ëª…"],
        "ê²½ê¸°ëŒ€": ["ê²½ê¸°"],
        "êµ­ë¯¼ëŒ€": ["êµ­ë¯¼", "êµ­ëŒ€"],
        "ì„¸ì¢…ëŒ€": ["ì„¸ì¢…"],
        "ìˆ­ì‹¤ëŒ€": ["ìˆ­ì‹¤"],
        "ê´‘ìš´ëŒ€": ["ê´‘ìš´"],
        "ëª…ì§€ëŒ€": ["ëª…ì§€"],
        "ìƒëª…ëŒ€": ["ìƒëª…"],
        "ì„œìš¸ì‹œë¦½ëŒ€": ["ì‹œë¦½ëŒ€", "ì„œìš¸ì‹œë¦½"],
        
        # === ì§€ë°© ê±°ì  ===
        "ë¶€ê²½ëŒ€": ["ë¶€ê²½"],
        "ê²½ë‚¨ëŒ€": ["ê²½ë‚¨"],
        "ì°½ì›ëŒ€": ["ì°½ì›"],
        "ì¶©ì²­ëŒ€": ["ì¶©ì²­"],
    }
    
    # ì—­ë§¤í•‘ ìë™ ìƒì„±
    ALIAS_TO_OFFICIAL: Dict[str, str] = {}
    
    @classmethod
    def _build_alias_reverse_map(cls):
        """ë³„ì¹­ â†’ ê³µì‹ ëŒ€í•™ëª… ì—­ë§¤í•‘"""
        if cls.ALIAS_TO_OFFICIAL:
            return
        for official, aliases in cls.UNIVERSITY_ALIASES.items():
            cls.ALIAS_TO_OFFICIAL[official] = official
            for alias in aliases:
                cls.ALIAS_TO_OFFICIAL[alias] = official
    
    def __init__(self, percentage_df: pd.DataFrame):
        self._build_alias_reverse_map()
        # ... ê¸°ì¡´ __init__ ì½”ë“œ ...
    
    def _normalize_university(self, name: str) -> str:
        """ëŒ€í•™ëª… ì •ê·œí™”"""
        if not name:
            return ""
        # ê³µë°± ì œê±°
        name = name.replace(" ", "")
        # "ëŒ€í•™êµ" â†’ "ëŒ€" ì¶•ì•½
        name = name.replace("ëŒ€í•™êµ", "ëŒ€")
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        name = re.sub(r'[Â·\-_()]', '', name)
        return name
    
    def _get_official_university(self, name: str) -> str:
        """ë³„ì¹­ â†’ ê³µì‹ ëŒ€í•™ëª…"""
        normalized = self._normalize_university(name)
        
        # ì •í™• ë§¤ì¹­
        if normalized in self.ALIAS_TO_OFFICIAL:
            return self.ALIAS_TO_OFFICIAL[normalized]
        
        # ë¶€ë¶„ ë§¤ì¹­
        for alias, official in self.ALIAS_TO_OFFICIAL.items():
            if alias in normalized or normalized in alias:
                return official
        
        return name
    
    def _find_program_column(
        self,
        university: str,
        major: str,
        track: str = ""
    ) -> Optional[str]:
        """ëŒ€í•™/ì „ê³µì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸° (v2: Alias ì§€ì›)"""
        import re
        
        # 1. ê³µì‹ ëŒ€í•™ëª… ë³€í™˜
        official_univ = self._get_official_university(university)
        
        # 2. ëª¨ë“  ë³„ì¹­ ìˆ˜ì§‘
        all_names = [official_univ]
        if official_univ in self.UNIVERSITY_ALIASES:
            all_names.extend(self.UNIVERSITY_ALIASES[official_univ])
        all_names.append(university)  # ì›ë³¸ë„ ì¶”ê°€
        
        # 3. íŒ¨í„´ ìƒì„± (ìš°ì„ ìˆœìœ„ ìˆœ)
        patterns = []
        for univ_name in all_names:
            patterns.append(f"{univ_name}{major}")           # "ê°€ì²œì˜í•™"
            patterns.append(f"{univ_name} {major}")          # "ê°€ì²œ ì˜í•™"
            if track:
                patterns.append(f"{univ_name}{major} {track}")  # "ê°€ì²œì˜í•™ ì´ê³¼"
                patterns.append(f"{univ_name}{major}{track}")   # "ê°€ì²œì˜í•™ì´ê³¼"
                patterns.append(f"{univ_name} {major} {track}") # "ê°€ì²œ ì˜í•™ ì´ê³¼"
        
        # 4. ì •í™•í•œ ë§¤ì¹­
        for col in self.df.columns:
            col_str = str(col)
            for pattern in patterns:
                if pattern == col_str:
                    logger.debug(f"ì •í™• ë§¤ì¹­: '{pattern}' â†’ '{col_str}'")
                    return col
        
        # 5. í¬í•¨ ë§¤ì¹­ (ëŒ€í•™ëª… + ì „ê³µ ëª¨ë‘ í¬í•¨)
        for col in self.df.columns:
            col_str = str(col)
            col_normalized = self._normalize_university(col_str)
            
            for univ_name in all_names:
                univ_normalized = self._normalize_university(univ_name)
                major_normalized = self._normalize_university(major)
                
                if univ_normalized in col_normalized and major_normalized in col_normalized:
                    # trackë„ í™•ì¸
                    if not track or track in col_str:
                        logger.debug(f"í¬í•¨ ë§¤ì¹­: '{univ_name}+{major}' â†’ '{col_str}'")
                        return col
        
        # 6. í¼ì§€ ë§¤ì¹­ (RapidFuzz ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
        try:
            from rapidfuzz import fuzz, process
            
            best_pattern = f"{official_univ}{major}"
            result = process.extractOne(
                query=best_pattern,
                choices=list(self.df.columns),
                scorer=fuzz.WRatio,
                score_cutoff=70
            )
            if result:
                logger.debug(f"í¼ì§€ ë§¤ì¹­: '{best_pattern}' â†’ '{result[0]}' (score={result[1]})")
                return result[0]
        except ImportError:
            pass
        
        # 7. ëŒ€í•™ëª…ë§Œ ë§¤ì¹­ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        for col in self.df.columns:
            col_str = str(col)
            for univ_name in all_names:
                if univ_name in col_str:
                    logger.debug(f"ëŒ€í•™ ë§¤ì¹­: '{univ_name}' â†’ '{col_str}'")
                    return col
        
        logger.warning(f"ì»¬ëŸ¼ ì—†ìŒ: {university}({official_univ}){major}")
        return None
```

---

## ğŸ¤– Claude ì—ì´ì „íŠ¸ CLI í”„ë¡¬í”„íŠ¸

ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ Claude Code CLIì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.

### í”„ë¡¬í”„íŠ¸ 1: RAWSCORE íƒêµ¬ê³¼ëª© ìˆ˜ì • (90ë¶„)

```
ë‹¹ì‹ ì€ Theory Engine v3.0 ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

## ì‘ì—… ëª©í‘œ
RAWSCORE íƒêµ¬ê³¼ëª© ì¡°íšŒ ì„±ê³µë¥ ì„ 40% â†’ 90%+ë¡œ í–¥ìƒ

## ë¬¸ì œ ìƒí™©
- í˜„ì¬ rules.pyì˜ convert_raw_to_standard()ê°€ "ì˜ì—­" ì»¬ëŸ¼ë§Œ ê²€ìƒ‰
- íƒêµ¬ê³¼ëª©ì€ ì˜ì—­="íƒêµ¬" + ê³¼ëª©ëª…="ë¬¼ë¦¬í•™ â… " êµ¬ì¡°
- ê²°ê³¼: êµ­ì–´/ìˆ˜í•™ë§Œ ì„±ê³µ, íƒêµ¬ê³¼ëª© ì „ì²´ ì‹¤íŒ¨

## ì‘ì—… ë‚´ìš©
1. C:\Neoprime\theory_engine\rules.py íŒŒì¼ ì½ê¸°
2. convert_raw_to_standard() í•¨ìˆ˜ë¥¼ ë‹¤ë‹¨ê³„ ë§¤ì¹­ìœ¼ë¡œ êµì²´:
   - Stage 1: ì˜ì—­ ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­ (êµ­ì–´, ìˆ˜í•™)
   - Stage 2: ê³¼ëª©ëª… ì»¬ëŸ¼ ì§ì ‘ ë§¤ì¹­ (íƒêµ¬ê³¼ëª©)
   - Stage 3: ì˜ì—­="íƒêµ¬" + ê³¼ëª©ëª… í¼ì§€ ë§¤ì¹­
   - Stage 4: ì „ì²´ í¼ì§€ ë§¤ì¹­ (ìµœí›„ ìˆ˜ë‹¨)
3. ê° Stageë³„ ë¡œê¹… ì¶”ê°€
4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰: python -m pytest tests/test_integration.py -v -k "rawscore"

## ì£¼ì˜ì‚¬í•­
- SubjectMatcherëŠ” ì´ë¯¸ êµ¬í˜„ë¨, get_subject_matcher() ì‚¬ìš©
- normalize_subject() í•¨ìˆ˜ ì¬ì‚¬ìš©
- match_type í•„ë“œì— ì‚¬ìš©ëœ Stage ê¸°ë¡
- ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„± ìœ ì§€

## ì˜ˆìƒ ê²°ê³¼
- ë¬¼ë¦¬í•™ â… , í™”í•™ â… , ìƒëª…ê³¼í•™ â… , ì§€êµ¬ê³¼í•™ â…  ë“± íƒêµ¬ê³¼ëª© ë³€í™˜ ì„±ê³µ
- êµ­ì–´/ìˆ˜í•™ ê¸°ì¡´ ë™ì‘ ìœ ì§€

ì‘ì—…ì„ ì‹œì‘í•˜ì„¸ìš”.
```

### í”„ë¡¬í”„íŠ¸ 2: INDEX ìš°íšŒ ë¡œì§ (60ë¶„)

```
ë‹¹ì‹ ì€ Theory Engine v3.0 ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

## ì‘ì—… ëª©í‘œ
INDEX ì¡°íšŒ ì„±ê³µë¥ ì„ 0% â†’ 95%+ë¡œ í–¥ìƒ (ìš°íšŒ ë¡œì§ êµ¬í˜„)

## ë¬¸ì œ ìƒí™©
- INDEX ì‹œíŠ¸ ì²« ì»¬ëŸ¼ì´ "510gs0t20509" ê°™ì€ ì¸ì½”ë”© í‚¤
- IndexOptimizerê°€ MultiIndex 0í–‰ìœ¼ë¡œ êµ¬ì¶•ë¨
- ê²°ê³¼: INDEX ì¡°íšŒ ì „ì²´ ì‹¤íŒ¨

## ì‘ì—… ë‚´ìš©
1. ìƒˆ íŒŒì¼ ìƒì„±: C:\Neoprime\theory_engine\optimizers\index_fallback.py
   - IndexFallback í´ë˜ìŠ¤ êµ¬í˜„
   - RAWSCORE ëˆ„ì % ê°€ì¤‘í‰ê·  ê³„ì‚°
   - ì˜ì–´ ë“±ê¸‰ â†’ ë°±ë¶„ìœ„ ë³€í™˜
   - ì „êµ­ ë“±ìˆ˜ ì¶”ì • ë¡œì§
   - get_index_fallback() ì‹±ê¸€í†¤ í•¨ìˆ˜

2. C:\Neoprime\theory_engine\rules.py ìˆ˜ì •
   - ìƒë‹¨ì— from .optimizers.index_fallback import get_index_fallback ì¶”ê°€
   - compute_theory_result() í•¨ìˆ˜ ë‚´ INDEX ì¡°íšŒ ë¶€ë¶„ ìˆ˜ì •:
     - INDEX ì¡°íšŒ ì‹¤íŒ¨ ì‹œ í´ë°± ì‚¬ìš©
     - match_typeì— "fallback_rawscore_weighted" ê¸°ë¡

3. C:\Neoprime\theory_engine\optimizers\__init__.py ìˆ˜ì •
   - IndexFallback, get_index_fallback ì¶”ê°€

4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰: python -m pytest tests/test_integration.py -v -k "index"

## ê°€ì¤‘ì¹˜ ì„¤ì •
korean: 0.28, math: 0.28, english: 0.14, inquiry1: 0.15, inquiry2: 0.15

## ì˜ˆìƒ ê²°ê³¼
- INDEX ì¡°íšŒ ì‹¤íŒ¨í•´ë„ cumulative_pct, national_rank ì‚°ì¶œ
- match_typeì´ "fallback_rawscore_weighted"ë¡œ ê¸°ë¡

ì‘ì—…ì„ ì‹œì‘í•˜ì„¸ìš”.
```

### í”„ë¡¬í”„íŠ¸ 3: ëŒ€í•™ëª… Alias (90ë¶„)

```
ë‹¹ì‹ ì€ Theory Engine v3.0 ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

## ì‘ì—… ëª©í‘œ
ëŒ€í•™ ì»¤íŠ¸ë¼ì¸ ì¡°íšŒ ì„±ê³µë¥ ì„ 67% â†’ 95%+ë¡œ í–¥ìƒ

## ë¬¸ì œ ìƒí™©
- "ì—°ì„¸ëŒ€" vs "ì—°ëŒ€", "ê³ ë ¤ëŒ€" vs "ê³ ëŒ€" ë“± Alias ë¯¸ì§€ì›
- cutoff_extractor.pyê°€ ë‹¨ìˆœ íŒ¨í„´ ë§¤ì¹­ë§Œ ìˆ˜í–‰
- ê²°ê³¼: ìƒìœ„ê¶Œ ëŒ€í•™(SKY ë“±) ì»¤íŠ¸ë¼ì¸ ì¡°íšŒ ì‹¤íŒ¨

## ì‘ì—… ë‚´ìš©
1. C:\Neoprime\theory_engine\cutoff\cutoff_extractor.py ìˆ˜ì •
   - UNIVERSITY_ALIASES ë”•ì…”ë„ˆë¦¬ ì¶”ê°€ (30+ ëŒ€í•™)
   - ALIAS_TO_OFFICIAL ì—­ë§¤í•‘ ìë™ ìƒì„±
   - _normalize_university() ë©”ì„œë“œ ì¶”ê°€
   - _get_official_university() ë©”ì„œë“œ ì¶”ê°€
   - _find_program_column() ë©”ì„œë“œ ê°œì„ :
     - ê³µì‹ ëŒ€í•™ëª… ë³€í™˜
     - ëª¨ë“  ë³„ì¹­ìœ¼ë¡œ íŒ¨í„´ ìƒì„±
     - ì •í™• ë§¤ì¹­ â†’ í¬í•¨ ë§¤ì¹­ â†’ í¼ì§€ ë§¤ì¹­ ìˆœì„œ
     - rapidfuzz ì˜µì…˜ (ì„¤ì¹˜ëœ ê²½ìš°)

2. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€:
   - ("ì—°ëŒ€", "ì˜ì˜ˆ", "ì´ê³¼") â†’ ì—°ì„¸ëŒ€ì˜ì˜ˆ
   - ("ê³ ëŒ€", "ê²½ì˜", "ë¬¸ê³¼") â†’ ê³ ë ¤ëŒ€ê²½ì˜
   - ("ì„œìš¸", "ê³µëŒ€", "ì´ê³¼") â†’ ì„œìš¸ëŒ€ê³µëŒ€

3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰: python -m pytest tests/test_integration.py -v -k "cutoff"

## ëŒ€í•™ Alias ëª©ë¡ (í•„ìˆ˜)
- SKY: ì„œìš¸ëŒ€(ì„œìš¸,ì„œëŒ€), ì—°ì„¸ëŒ€(ì—°ëŒ€,ì—°ì„¸), ê³ ë ¤ëŒ€(ê³ ëŒ€,ê³ ë ¤)
- ì˜ëŒ€: ê°€ì²œëŒ€(ê°€ì²œ), ì—°ì„¸ëŒ€ì›ì£¼(ì—°ëŒ€ì›ì£¼), í•œì–‘ëŒ€(í•œëŒ€) ë“± 30+ ëŒ€í•™

## ì˜ˆìƒ ê²°ê³¼
- "ì—°ì„¸ëŒ€ì˜ì˜ˆ", "ê³ ë ¤ëŒ€ê²½ì˜" ë“± ìƒìœ„ê¶Œ ëŒ€í•™ ì¡°íšŒ ì„±ê³µ
- ê¸°ì¡´ "ê°€ì²œì˜í•™", "ê±´êµ­ìì—°" ê³„ì† ì‘ë™

ì‘ì—…ì„ ì‹œì‘í•˜ì„¸ìš”.
```

### í”„ë¡¬í”„íŠ¸ 4: í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (30ë¶„)

```
ë‹¹ì‹ ì€ Theory Engine v3.0 ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ê²€ì¦ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

## ì‘ì—… ëª©í‘œ
ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ë¡œ ì‹¤ì‘ë™ë¥  98% í™•ì¸

## ì‘ì—… ë‚´ìš©
1. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:
   cd C:\Neoprime
   python -m pytest tests/ -v --tb=short

2. í†µí•© í…ŒìŠ¤íŠ¸ ìƒì„¸ ì‹¤í–‰:
   python -m pytest tests/test_integration.py -v

3. ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸:
   python -c "
   from theory_engine.loader import load_workbook
   from theory_engine.rules import compute_theory_result, convert_raw_to_standard
   from theory_engine.model import StudentProfile, ExamScore, TargetProgram
   from theory_engine.constants import Track

   excel_data = load_workbook()
   
   # íƒêµ¬ê³¼ëª© í…ŒìŠ¤íŠ¸
   subjects = ['ë¬¼ë¦¬í•™ â… ', 'í™”í•™ â… ', 'ìƒëª…ê³¼í•™ â… ', 'ì§€êµ¬ê³¼í•™ â… ']
   for subj in subjects:
       result = convert_raw_to_standard(excel_data['RAWSCORE'], subj, 45)
       status = 'âœ…' if result['found'] else 'âŒ'
       print(f'{status} {subj}: {result.get(\"match_type\", \"FAIL\")}')
   
   # ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
   profile = StudentProfile(
       track=Track.SCIENCE,
       korean=ExamScore('êµ­ì–´', raw_total=85),
       math=ExamScore('ìˆ˜í•™', raw_total=82),
       english_grade=2,
       history_grade=3,
       inquiry1=ExamScore('ë¬¼ë¦¬í•™ â… ', raw_total=47),
       inquiry2=ExamScore('í™”í•™ â… ', raw_total=45),
       targets=[
           TargetProgram('ì—°ì„¸ëŒ€', 'ì˜ì˜ˆ'),
           TargetProgram('ê³ ë ¤ëŒ€', 'ì˜ì˜ˆ'),
           TargetProgram('ê°€ì²œ', 'ì˜í•™'),
       ]
   )
   
   result = compute_theory_result(excel_data, profile)
   print(f'\\nINDEX: {result.raw_components.get(\"index_match_type\")}')
   print(f'ëˆ„ì %: {result.raw_components.get(\"cumulative_pct\")}')
   for prog in result.program_results:
       status = 'âœ…' if prog.cutoff_normal else 'âŒ'
       print(f'{status} {prog.target.university}{prog.target.major}: {prog.level_theory.value}')
   "

4. ê²°ê³¼ ìš”ì•½ ë³´ê³ 

## ê¸°ëŒ€ ê²°ê³¼
- í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨: 38/38 (100%)
- RAWSCORE íƒêµ¬ê³¼ëª©: 4/4 (100%)
- INDEX í´ë°±: cumulative_pct ì‚°ì¶œ
- ëŒ€í•™ ì»¤íŠ¸ë¼ì¸: ì—°ì„¸ëŒ€ì˜ì˜ˆ, ê³ ë ¤ëŒ€ì˜ì˜ˆ ì¡°íšŒ ì„±ê³µ

ê²€ì¦ì„ ì‹œì‘í•˜ì„¸ìš”.
```

---

## ğŸ“Š ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Task 1 ì™„ë£Œ ê¸°ì¤€ (90ë¶„)
- [ ] rules.py convert_raw_to_standard() ìˆ˜ì •
- [ ] Stage 1-4 ë‹¤ë‹¨ê³„ ë§¤ì¹­ êµ¬í˜„
- [ ] íƒêµ¬ê³¼ëª© í…ŒìŠ¤íŠ¸ í†µê³¼ (ë¬¼ë¦¬í•™â… , í™”í•™â… , ìƒëª…ê³¼í•™â… , ì§€êµ¬ê³¼í•™â… )
- [ ] ê¸°ì¡´ êµ­ì–´/ìˆ˜í•™ í…ŒìŠ¤íŠ¸ ìœ ì§€

### Task 2 ì™„ë£Œ ê¸°ì¤€ (60ë¶„)
- [ ] index_fallback.py ì‹ ê·œ ìƒì„±
- [ ] rules.pyì— í´ë°± ë¡œì§ í†µí•©
- [ ] optimizers/__init__.py ì—…ë°ì´íŠ¸
- [ ] INDEX í´ë°± í…ŒìŠ¤íŠ¸ í†µê³¼

### Task 3 ì™„ë£Œ ê¸°ì¤€ (90ë¶„)
- [ ] cutoff_extractor.py UNIVERSITY_ALIASES ì¶”ê°€
- [ ] _find_program_column() ê°œì„ 
- [ ] ì—°ì„¸ëŒ€/ê³ ë ¤ëŒ€/ì„œìš¸ëŒ€ ì¡°íšŒ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ê¸°ì¡´ ê°€ì²œ/ê±´êµ­ í…ŒìŠ¤íŠ¸ ìœ ì§€

### ìµœì¢… ê²€ì¦ (30ë¶„)
- [ ] python -m pytest tests/ -v ì „ì²´ í†µê³¼
- [ ] íƒêµ¬ê³¼ëª© 4/4 ì„±ê³µ
- [ ] INDEX í´ë°± ë™ì‘
- [ ] ìƒìœ„ê¶Œ ëŒ€í•™ ì»¤íŠ¸ë¼ì¸ ì¡°íšŒ ì„±ê³µ
- [ ] ì‹¤ì‘ë™ë¥  95%+ ë‹¬ì„±

---

## ğŸ¯ ì˜ˆìƒ ê²°ê³¼

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ë‹¬ì„± ë°©ë²• |
|------|------|------|----------|
| **RAWSCORE íƒêµ¬ê³¼ëª©** | 40% | **95%+** | ë‹¤ë‹¨ê³„ ë§¤ì¹­ |
| **INDEX ì¡°íšŒ** | 0% | **95%+** | RAWSCORE í´ë°± |
| **ëŒ€í•™ ì»¤íŠ¸ë¼ì¸** | 67% | **95%+** | Alias ì‹œìŠ¤í…œ |
| **ì „ì²´ ì‹¤ì‘ë™ë¥ ** | 58% | **98%** | ìœ„ 3ê°œ ì¡°í•© |

---

**ì‘ì„±ì¼**: 2026-01-18  
**ì†Œìš” ì‹œê°„**: ì´ 6ì‹œê°„ (Task1: 90ë¶„, Task2: 60ë¶„, Task3: 90ë¶„, ê²€ì¦: 30ë¶„)  
**ë‹´ë‹¹**: Claude ì—ì´ì „íŠ¸ CLI  

**END OF DEVELOPMENT PLAN**
