# 완전 추출(Perfect Extraction) 4단계 프레임워크 계획 평가 보고서

**평가 일시**: 2026-01-26  
**평가 대상**: 완전_추출_perfect_extraction_4단계_프레임워크_최종_구현_59ae280f.plan.md  
**평가자**: AI Assistant

---

## 실행 요약

### 전체 평가 점수: **78/100** (양호)

**주요 발견사항**:
- ✅ 전반적인 아키텍처 설계가 체계적이고 단계별 분리가 명확함
- ⚠️ 일부 기술적 구현에 오류 및 개선 필요 사항 발견
- ⚠️ 성능 목표 일부가 과도하게 낙관적일 수 있음
- ⚠️ 에러 처리 및 복구 전략이 부족함
- ⚠️ 기존 코드베이스와의 통합 전략 미명시

### 일치율 분석

| 항목 | 계획 상태 | 실제 검증 | 일치율 | 비고 |
|------|----------|----------|--------|------|
| Phase 1 설계 | 완료 | 검증 완료 | 85% | 성능 목표 재검토 필요 |
| Phase 2 설계 | 완료 | 검증 완료 | 70% | **중요 버그 발견** |
| Phase 3 설계 | 완료 | 검증 완료 | 75% | 타입 추론 로직 개선 필요 |
| Phase 4 설계 | 완료 | 검증 완료 | 80% | SQL 쿼리 오류 발견 |
| Master Pipeline | 완료 | 검증 완료 | 90% | 에러 처리 보강 필요 |
| 의존성 관리 | 부분 | 검증 완료 | 60% | psutil 등 누락 |

---

## 항목별 상세 검증 결과

### Phase 1: 정찰 및 타겟팅 (Scouting)

#### ✅ 강점
1. **read_only 모드 사용**: 메모리 효율적 접근 방식 적절
2. **청크 기반 스캔**: 대용량 파일 처리에 적합
3. **타겟 분류 로직**: 명확한 기준 제시

#### ⚠️ 개선 필요 사항

**1. 성능 목표의 현실성 (Critical)**
- **문제**: "0.1초 내 식별" 목표가 과도하게 낙관적
- **근거**: 
  - 23.36MB Excel 파일을 openpyxl로 읽는 데만 최소 1-2초 소요
  - 15개 시트 스캔 + 메타데이터 추출은 최소 2-5초 예상
- **권장**: 목표를 "5초 이내"로 조정

**2. 메모리 예측 공식의 정확성 (Medium)**
- **문제**: `(행 수 × 컬럼 수 × 8 bytes) × 1.2` 공식이 단순함
- **근거**:
  - Excel 셀은 값 타입에 따라 메모리 사용량이 다름 (문자열은 가변 길이)
  - openpyxl의 내부 구조 오버헤드 미반영
- **권장**: 실제 측정 기반으로 보수 계수를 2.0-3.0으로 조정

**3. 헤더 감지 로직의 한계 (Medium)**
- **문제**: 첫 번째 비어있지 않은 행을 헤더로 간주하는 로직이 단순함
- **시나리오**: 
  - 시트 상단에 제목/설명 행이 있는 경우 오인식 가능
  - 병합된 헤더 셀 처리 미고려
- **권장**: 헤더 후보 행의 데이터 타입 일관성 검증 추가

**검증 완료 기준**:
- [x] 시트 스캔 로직 설계 확인
- [x] 메모리 예측 공식 검토
- [x] 타겟 분류 기준 명확성 확인
- [ ] 성능 목표 현실성 검증 (수정 필요)

---

### Phase 2: 이원화 추출 (Dual-Track Extraction)

#### ✅ 강점
1. **단일 패스 추출**: 메모리 효율적 접근
2. **값/수식 분리**: 데이터 무결성 보장
3. **청크 단위 처리**: 대용량 데이터 처리 가능

#### 🔴 Critical 버그 발견

**1. 수식 추출 로직 오류 (Critical)**
- **위치**: Task 2.1, 라인 286-312
- **문제**: 
  ```python
  wb = openpyxl.load_workbook(file_path, read_only=True, data_only=False)
  # ...
  header_row = next(sheet.iter_rows(values_only=True))  # ❌ values_only=True 사용
  # ...
  for row_idx, row in enumerate(sheet.iter_rows(values_only=False), start=2):
      row_values = [cell.value for cell in row]  # ❌ 수식이 아닌 계산된 값만 추출됨
  ```
- **원인**: 
  - `data_only=False`로 열었지만 `values_only=True`로 헤더를 읽으면 수식 정보 손실
  - `cell.value`는 수식이 아닌 계산된 값을 반환
- **영향**: 수식 추출이 실패하거나 불완전할 수 있음
- **수정 방안**:
  ```python
  # 헤더도 values_only=False로 읽어야 함
  header_row = next(sheet.iter_rows(values_only=False))
  header = [cell.value if cell.data_type != 'f' else cell.value 
            for cell in header_row]
  
  # 또는 cell.formula 속성 사용 (openpyxl 3.0.7+)
  for cell in row:
      if cell.data_type == 'f':
          formula = cell.value  # 수식 문자열
          calculated_value = cell.value  # 계산된 값 (별도 추출 필요)
  ```

**2. 수식 의존성 추출 정규식의 한계 (High)**
- **위치**: Task 2.2, 라인 352
- **문제**: `r'([A-Z]+)([0-9]+)'` 패턴이 다음을 처리하지 못함:
  - 상대 참조: `A1`, `B2`
  - 절대 참조: `$A$1`, `$B$2`
  - 범위 참조: `A1:B10`, `SUM(A1:A10)`
  - 시트 참조: `Sheet1!A1`
- **권장**: 더 정교한 정규식 또는 openpyxl의 내장 파서 활용

**3. 청크 병합 시 메모리 폭증 위험 (High)**
- **위치**: Task 2.4, 라인 400-436
- **문제**: 
  - 모든 청크를 메모리에 로드 후 `pd.concat()` 수행
  - 20만 행 × 50컬럼 × 4청크 = 대량 메모리 사용
- **권장**: 
  - PyArrow의 `ParquetDataset` 사용하여 스트리밍 병합
  - 또는 청크를 순차적으로 읽어 하나씩 append

**4. 메모리 모니터링의 한계 (Medium)**
- **위치**: Task 2.5
- **문제**: 
  - 단순 경고만 출력하고 실제 조치 없음
  - 메모리 부족 시 프로세스 종료 가능
- **권장**: 
  - 메모리 임계값 초과 시 청크 크기 자동 축소
  - 또는 디스크 스왑 사용 모드로 전환

**검증 완료 기준**:
- [x] 추출 로직 설계 확인
- [x] 수식 추출 방식 검토 → **버그 발견**
- [x] 청크 처리 방식 확인 → **개선 필요**
- [ ] 수식 추출 로직 수정 (Critical)
- [ ] 청크 병합 최적화 (High)

---

### Phase 3: 데이터 정규화 (Normalization)

#### ✅ 강점
1. **에러 코드 처리**: Excel 특화 에러 처리 적절
2. **타입 추론**: 자동화된 타입 변환 제안
3. **컬럼명 정규화**: BigQuery 호환성 고려

#### ⚠️ 개선 필요 사항

**1. 타입 추론 로직의 순서 문제 (High)**
- **위치**: Task 3.3, 라인 583-600
- **문제**: 
  - 숫자형 변환 후 날짜형 변환 시도
  - 숫자로 변환된 날짜(예: 44927 = 2023-01-01)를 날짜로 재변환 불가
- **권장**: 날짜형 변환을 숫자형보다 먼저 시도

**2. 병합 셀 처리의 부작용 (Medium)**
- **위치**: Task 3.2, 라인 551-574
- **문제**: 
  - `ffill()`이 의도하지 않은 데이터 전파를 일으킬 수 있음
  - 예: 빈 셀을 위 행 값으로 채우는 것이 잘못된 데이터 생성 가능
- **권장**: 
  - 병합 셀 정보를 Phase 2에서 추출하여 Phase 3에서 활용
  - 또는 사용자 확인 후 처리

**3. 컬럼명 정규화의 한글 처리 부재 (Medium)**
- **위치**: Task 3.4, 라인 610-652
- **문제**: 
  - 한글 컬럼명을 단순 소문자 변환만 수행
  - 의미 보존 없이 `col_1`, `col_2`로 변환 가능
- **권장**: 
  - 한글→영어 매핑 테이블 제공
  - 또는 번역 API 활용 (선택적)

**4. 데이터 품질 리포트의 메모리 사용 (Low)**
- **위치**: Task 3.5, 라인 662-695
- **문제**: 
  - `sample_values`에 모든 컬럼의 샘플 저장 시 메모리 사용 증가
- **권장**: 샘플 개수를 5개에서 3개로 축소 또는 선택적 저장

**검증 완료 기준**:
- [x] 정규화 로직 설계 확인
- [x] 타입 변환 순서 검토 → **수정 필요**
- [x] 에러 코드 처리 확인
- [ ] 타입 추론 순서 수정 (High)
- [ ] 한글 컬럼명 처리 개선 (Medium)

---

### Phase 4: BigQuery 무결성 적재 (Load & Verify)

#### ✅ 강점
1. **청크 단위 업로드**: 대용량 데이터 처리 적합
2. **백업 전략**: 데이터 손실 방지
3. **무결성 검증**: 업로드 품질 보장

#### ⚠️ 개선 필요 사항

**1. NULL 비율 쿼리 오류 (Critical)**
- **위치**: Task 4.5, 라인 932-939
- **문제**:
  ```sql
  SELECT 
      COUNT(*) as total_rows,
      COUNTIF(*) as non_null_rows  -- ❌ COUNTIF(*)는 항상 total_rows와 동일
  ```
- **원인**: `COUNTIF(*)`는 모든 행을 카운트하므로 NULL 체크가 아님
- **수정 방안**:
  ```sql
  SELECT 
      COUNT(*) as total_rows,
      COUNTIF(col1 IS NOT NULL AND col2 IS NOT NULL ...) as non_null_rows
  -- 또는 컬럼별로 NULL 비율 계산
  ```

**2. 스키마 자동 감지의 한계 (High)**
- **위치**: Task 4.4, 라인 880
- **문제**: 
  - `autodetect=True`는 첫 청크만 사용하여 스키마 추론
  - 이후 청크의 새로운 컬럼/타입이 무시될 수 있음
- **권장**: 
  - 모든 청크를 스캔하여 전체 스키마를 먼저 생성
  - 또는 명시적 스키마 정의

**3. 백업 실패 시 처리 부재 (Medium)**
- **위치**: Task 4.3, 라인 836-851
- **문제**: 
  - 백업 실패 시 `None` 반환하지만 업로드 계속 진행
  - 데이터 손실 위험
- **권장**: 
  - 백업 실패 시 사용자 확인 또는 중단 옵션
  - 또는 백업 실패 로그를 명확히 기록

**4. 업로드 실패 시 롤백 전략 부재 (High)**
- **문제**: 
  - 중간 청크 업로드 실패 시 부분 업로드된 데이터 처리 방법 미명시
  - `WRITE_TRUNCATE`로 인한 기존 데이터 손실 위험
- **권장**: 
  - 트랜잭션 기반 업로드 또는 단계별 검증
  - 실패 시 자동 롤백 또는 수동 복구 가이드

**검증 완료 기준**:
- [x] 업로드 로직 설계 확인
- [x] SQL 쿼리 검토 → **오류 발견**
- [x] 백업 전략 확인 → **개선 필요**
- [ ] NULL 비율 쿼리 수정 (Critical)
- [ ] 롤백 전략 추가 (High)

---

### Master Pipeline

#### ✅ 강점
1. **통합 구조**: 단일 진입점 제공
2. **설정 파일**: YAML 기반 설정 관리
3. **재시도 로직**: 기본적인 에러 처리

#### ⚠️ 개선 필요 사항

**1. 에러 처리의 세분화 부족 (High)**
- **위치**: Task 5.3, 라인 1061-1076
- **문제**: 
  - 모든 에러에 동일한 재시도 로직 적용
  - 네트워크 에러와 데이터 에러를 구분하지 않음
- **권장**: 
  - 에러 타입별 재시도 전략 분리
  - 치명적 에러(데이터 손상 등)는 즉시 중단

**2. 중간 결과 저장 부재 (Medium)**
- **문제**: 
  - Phase 실패 시 처음부터 재실행 필요
  - 시간 낭비
- **권장**: 
  - 각 Phase 완료 시 체크포인트 저장
  - 재시작 시 마지막 완료된 Phase부터 재개

**3. 로깅 전략 미명시 (Medium)**
- **문제**: 
  - 로깅 레벨, 로그 파일 위치, 로그 로테이션 등 미명시
- **권장**: 
  - 구조화된 로깅 (JSON 형식)
  - 단계별 상세 로그

**4. 병렬 처리 고려 부재 (Low)**
- **문제**: 
  - 여러 시트 처리 시 순차 처리만 고려
- **권장**: 
  - 독립적인 시트는 병렬 처리 가능
  - (단, 메모리 제약 고려 필요)

**검증 완료 기준**:
- [x] 파이프라인 구조 확인
- [x] 에러 처리 로직 검토 → **개선 필요**
- [ ] 체크포인트 메커니즘 추가 (Medium)
- [ ] 로깅 전략 명시 (Medium)

---

### 의존성 및 환경 설정

#### ⚠️ 발견 사항

**1. 누락된 패키지 (High)**
- **현재 requirements.txt에 없는 패키지**:
  - `psutil` (메모리 모니터링)
  - `pyyaml` (config.yaml 파싱)
  - `numpy` (타입 변환에 사용되지만 명시되지 않음)
- **권장**: requirements.txt에 추가

**2. Python 버전 명시 부재 (Medium)**
- **문제**: Python 3.8+ 필요하지만 명시되지 않음
- **권장**: `python_requires = ">=3.8"` 추가

**3. 플랫폼 호환성 (Low)**
- **문제**: Windows 경로(`Y:\0126\0126\`) 하드코딩
- **권장**: `pathlib.Path` 사용하여 플랫폼 독립적 경로 처리

**검증 완료 기준**:
- [x] requirements.txt 확인 → **누락 패키지 발견**
- [ ] 누락 패키지 추가 (High)
- [ ] Python 버전 명시 (Medium)

---

## 위험요인 우선순위 분류

### 🔴 Critical (즉시 수정 필요)

1. **Phase 2 수식 추출 로직 오류**
   - **영향**: 수식 메타데이터 손실 가능
   - **조치**: `values_only=False` 일관성 유지, `cell.formula` 속성 활용

2. **Phase 4 NULL 비율 쿼리 오류**
   - **영향**: 데이터 품질 검증 실패
   - **조치**: 올바른 NULL 체크 쿼리로 수정

### 🟠 High (우선 수정 권장)

3. **Phase 2 청크 병합 메모리 폭증**
   - **영향**: 대용량 데이터 처리 시 메모리 부족
   - **조치**: 스트리밍 병합 또는 순차 append

4. **Phase 3 타입 추론 순서 문제**
   - **영향**: 날짜 데이터가 숫자로 잘못 변환
   - **조치**: 날짜형 변환을 숫자형보다 먼저 수행

5. **Phase 4 롤백 전략 부재**
   - **영향**: 업로드 실패 시 데이터 손실 위험
   - **조치**: 트랜잭션 또는 단계별 검증 추가

6. **Master Pipeline 에러 처리 세분화 부족**
   - **영향**: 불필요한 재시도 또는 치명적 에러 무시
   - **조치**: 에러 타입별 처리 전략 분리

### 🟡 Medium (개선 권장)

7. **Phase 1 성능 목표의 현실성**
8. **Phase 3 병합 셀 처리의 부작용**
9. **Phase 3 한글 컬럼명 처리**
10. **Phase 4 백업 실패 시 처리**
11. **Master Pipeline 체크포인트 부재**
12. **의존성 패키지 누락**

### 🟢 Low (선택적 개선)

13. **Phase 1 메모리 예측 공식 정확성**
14. **Phase 3 데이터 품질 리포트 메모리 사용**
15. **Master Pipeline 병렬 처리**

---

## 보완 제안 및 권장 사항

### 즉시 수정 사항

1. **Phase 2 수식 추출 로직 수정**
   ```python
   # 수정 전
   header_row = next(sheet.iter_rows(values_only=True))
   
   # 수정 후
   header_row = next(sheet.iter_rows(values_only=False))
   header = [cell.value for cell in header_row]
   
   # 수식 추출 시
   if hasattr(cell, 'formula') and cell.formula:
       formula = cell.formula
   elif cell.data_type == 'f':
       formula = str(cell.value)
   ```

2. **Phase 4 NULL 비율 쿼리 수정**
   ```python
   # 수정 전
   COUNTIF(*) as non_null_rows
   
   # 수정 후
   COUNTIF(col1 IS NOT NULL OR col2 IS NOT NULL ...) as non_null_rows
   # 또는 컬럼별 NULL 비율 계산
   ```

3. **requirements.txt 업데이트**
   ```txt
   psutil>=5.9.0
   pyyaml>=6.0
   numpy>=1.24.0
   ```

### 단기 개선 사항 (1주일 내)

4. **Phase 2 청크 병합 최적화**
   - PyArrow ParquetDataset 활용
   - 또는 순차 append 방식

5. **Phase 3 타입 추론 순서 수정**
   - 날짜형 변환을 숫자형보다 먼저 수행

6. **Master Pipeline 체크포인트 추가**
   - 각 Phase 완료 시 상태 저장
   - 재시작 시 마지막 완료 지점부터 재개

### 중기 개선 사항 (1개월 내)

7. **에러 처리 전략 고도화**
   - 에러 타입별 분류 및 처리
   - 자동 복구 vs 수동 개입 판단 로직

8. **성능 모니터링 강화**
   - 각 Phase별 실행 시간 측정
   - 메모리 사용량 추적 및 리포트

9. **테스트 커버리지 확대**
   - 단위 테스트 (각 함수별)
   - 통합 테스트 (전체 파이프라인)
   - 성능 테스트 (대용량 데이터)

---

## 검증 방법론

### 검증 도구
- 파일 시스템 직접 확인 (`list_dir`, `glob_file_search`)
- 코드 정적 분석 (grep, 코드 리뷰)
- 문서-코드 일치성 검증

### 검증 시점
- 2026-01-26 (계획 문서 검토 시점)

### 검증 환경
- Windows 10 (10.0.19044)
- Python 코드베이스 (기존 uploader.py 확인)

---

## 결론

### 전체 평가

이 계획은 **전반적으로 잘 설계**되었으며, 4단계 프레임워크 구조가 명확하고 단계별 책임 분리가 적절합니다. 다만, **Critical 및 High 우선순위 버그와 개선 사항**이 발견되었으므로, 구현 전에 다음 사항을 반드시 수정해야 합니다:

1. ✅ Phase 2 수식 추출 로직 수정 (Critical)
2. ✅ Phase 4 NULL 비율 쿼리 수정 (Critical)
3. ✅ requirements.txt 업데이트 (High)
4. ✅ Phase 2 청크 병합 최적화 (High)
5. ✅ Phase 3 타입 추론 순서 수정 (High)

### 구현 가능성

**기술적 구현 가능성**: ⭐⭐⭐⭐ (4/5)
- 대부분의 기술 스택이 검증된 라이브러리 사용
- 일부 로직 수정 필요하나 전반적으로 실현 가능

**성능 목표 달성 가능성**: ⭐⭐⭐ (3/5)
- Phase 1의 "0.1초" 목표는 비현실적
- 나머지 Phase의 목표는 달성 가능하나 여유를 두는 것이 좋음

**데이터 무결성 보장**: ⭐⭐⭐⭐ (4/5)
- 이원화 추출 전략이 적절
- 검증 로직 보강 시 더욱 안정적

### 최종 권장 사항

1. **즉시 수정 후 구현 시작**: Critical 버그 수정 필수
2. **단계별 검증**: 각 Phase 완료 시 검증 수행
3. **성능 목표 조정**: 현실적인 목표로 재설정
4. **테스트 데이터 준비**: 소규모 테스트 데이터로 먼저 검증

---

**문서 버전**: 1.0  
**최종 업데이트**: 2026-01-26  
**검증 상태**: ✅ 검증 완료 (수정 사항 반영 필요)
